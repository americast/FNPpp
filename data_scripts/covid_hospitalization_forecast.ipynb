{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata sources:\\n1. google mobility: https://www.google.com/covid19/mobility/\\n2. apple mobilty: https://covid19.apple.com/mobility\\n6a. positiveIncrease: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\\n6b. negaiveResults, totalRes: https://healthdata.gov/dataset/COVID-19-Diagnostic-Laboratory-Testing-PCR-Testing/j8mb-icvb\\n7. jhu deaths: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\\n9. excess deaths: https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm\\n13. vaccine doses: https://github.com/govex/COVID-19/blob/master/data_tables/vaccine_data/us_data/time_series/vaccine_data_us_timeline.csv\\n5. fb-google survey: deplhi api\\n\\nDATA PROVIDED BY ALEX\\n11. covidnet: original cdc, processed data to use given by ALEX [https://gis.cdc.gov/grasp/covidnet/COVID19_3.html] \\n12. CDC hospitalized: https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-state-timeseries\\n\\nDATA OBSOLETE-- NOT COLLECTING ANYMORE\\n3. Covid ExposureIndex dex: https://github.com/COVIDExposureIndices/COVIDExposureIndices\\n4. kinsa: kinsa_pull.ipynb \\n6. hospitalization: https://covidtracking.com/api\\n8. iqvia: Alex from Jimeng\\n10. Emergency visits (less priority: region level): \\n#https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/09042020/covid-like-illness.html\\nhttps://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/10092020/outpatient-emergency-visits.html\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data sources:\n",
    "1. google mobility: https://www.google.com/covid19/mobility/\n",
    "2. apple mobilty: https://covid19.apple.com/mobility\n",
    "6a. positiveIncrease: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "6b. negaiveResults, totalRes: https://healthdata.gov/dataset/COVID-19-Diagnostic-Laboratory-Testing-PCR-Testing/j8mb-icvb\n",
    "7. jhu deaths: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "9. excess deaths: https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm\n",
    "13. vaccine doses: https://github.com/govex/COVID-19/blob/master/data_tables/vaccine_data/us_data/time_series/vaccine_data_us_timeline.csv\n",
    "5. fb-google survey: deplhi api\n",
    "\n",
    "DATA PROVIDED BY ALEX\n",
    "11. covidnet: original cdc, processed data to use given by ALEX [https://gis.cdc.gov/grasp/covidnet/COVID19_3.html] \n",
    "12. CDC hospitalized: https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-state-timeseries\n",
    "\n",
    "DATA OBSOLETE-- NOT COLLECTING ANYMORE\n",
    "3. Covid ExposureIndex dex: https://github.com/COVIDExposureIndices/COVIDExposureIndices\n",
    "4. kinsa: kinsa_pull.ipynb \n",
    "6. hospitalization: https://covidtracking.com/api\n",
    "8. iqvia: Alex from Jimeng\n",
    "10. Emergency visits (less priority: region level): \n",
    "#https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/09042020/covid-like-illness.html\n",
    "https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/10092020/outpatient-emergency-visits.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "from epiweeks import Week, Year\n",
    "from delphi_epidata import Epidata\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the output file for each column\n",
    "def unit_test(data_dic,cols,epiweek_date,state_index,outfile):\n",
    "    state_names=list(state_index.keys())\n",
    "    all_cols=['date','region']+cols\n",
    "    out_data=pd.DataFrame(columns=all_cols)\n",
    "    for st in range(len(state_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['region']=[state_names[st]]*len(epiweek_date)\n",
    "        for c in cols:\n",
    "            temp_data[c]=data_dic[c][st][:]\n",
    "        out_data=out_data.append(temp_data,ignore_index=True)\n",
    "    out_data=out_data[all_cols]\n",
    "    print(out_data.shape)\n",
    "    out_data.to_csv(outfile,index=False)\n",
    "    print('output file written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the delphi data and processes the data\n",
    "def read_survey_epidata(col_name,epidata,state_index,state_names,epiweek_date):   \n",
    "    week_cases=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    total_sample=0\n",
    "    for ix in range(len(epidata)):\n",
    "        row=epidata[ix]\n",
    "        name=row['geo_value'].upper()\n",
    "        w_idx=find_week_index(epiweek_date,str(row['time_value']))\n",
    "        if name == 'US' and w_idx !=-1: \n",
    "            if np.isnan(week_cases[0][w_idx]): \n",
    "                week_cases[0][w_idx] = 0\n",
    "            week_cases[0][w_idx] += row['value']/7\n",
    "        elif name in state_names and w_idx!=-1:\n",
    "            state_id=state_index[name]\n",
    "            if np.isnan(week_cases[state_id][w_idx]):\n",
    "                week_cases[state_id][w_idx] = 0\n",
    "            week_cases[state_id][w_idx]+=row['value']/7\n",
    "    return week_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delphi_vaccine_test_two(state_index,epiweek_date,start_week,end_week):\n",
    "    #'''\n",
    "    # The \n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210208, Epidata.range(20210208, 20210301)],'*')\n",
    "    ##vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    ##vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc11_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210208, Epidata.range(20210208, 20210301)],'*')\n",
    "    ##vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    ##vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc18=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc12_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc18_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220301, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc27=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc28=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc22_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc23_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc24_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc25_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc26_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc27_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc28_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    \n",
    "    vacc32=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc33=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc34=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc35=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc36=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc37=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc38=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc32_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc33_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc34_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc35_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc36_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc37_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc38_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    \n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc43=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc44=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc45=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc46=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    #vacc47=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc43_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc44_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc45_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc46_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    #vacc47_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc53=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc54=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc55=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc56=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc57=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc53_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc54_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc55_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc56_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc57_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    ##vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    ##vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    #vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    #vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']+vacc17['epidata']+vacc18['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']+vacc26['epidata']+vacc27['epidata']+vacc28['epidata']\n",
    "    vacc3=vacc31['epidata']+vacc32['epidata']+vacc33['epidata']+vacc34['epidata']+vacc35['epidata']+vacc36['epidata']+vacc37['epidata']+vacc38['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']+vacc43['epidata']+vacc44['epidata']+vacc45['epidata']+vacc46['epidata']#+vacc47['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']+vacc53['epidata']+vacc54['epidata']+vacc55['epidata']+vacc56['epidata']+vacc57['epidata']\n",
    "    \n",
    "    vacc1_us=vacc11_us['epidata']+vacc12_us['epidata']+vacc13_us['epidata']+vacc14_us['epidata']+vacc15_us['epidata']+vacc16_us['epidata']+vacc17_us['epidata']+vacc18_us['epidata']\n",
    "    vacc2_us=vacc21_us['epidata']+vacc22_us['epidata']+vacc23_us['epidata']+vacc24_us['epidata']+vacc25_us['epidata']+vacc26_us['epidata']+vacc27_us['epidata']+vacc28_us['epidata']\n",
    "    vacc3_us=vacc31_us['epidata']+vacc32_us['epidata']+vacc33_us['epidata']+vacc34_us['epidata']+vacc35_us['epidata']+vacc36_us['epidata']+vacc37_us['epidata']+vacc38_us['epidata']\n",
    "    vacc4_us=vacc41_us['epidata']+vacc42_us['epidata']+vacc43_us['epidata']+vacc44_us['epidata']+vacc45_us['epidata']+vacc46_us['epidata']#+vacc47_us['epidata']\n",
    "    vacc5_us=vacc51_us['epidata']+vacc52_us['epidata']+vacc53_us['epidata']+vacc54_us['epidata']+vacc55_us['epidata']+vacc56_us['epidata']+vacc57_us['epidata']\n",
    "    \n",
    "    vacc1_final = vacc1 + vacc1_us\n",
    "    vacc2_final = vacc2 + vacc2_us\n",
    "    vacc3_final = vacc3 + vacc3_us\n",
    "    vacc4_final = vacc4 + vacc4_us\n",
    "    vacc5_final = vacc5 + vacc5_us\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc18['result'], vacc18['message'], len(vacc18['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc28['result'], vacc28['message'], len(vacc28['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc38['result'], vacc38['message'], len(vacc38['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc46['result'], vacc46['message'], len(vacc46['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc57['result'], vacc57['message'], len(vacc57['epidata']))\n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask_7d',\n",
    "          'smoothed_wtravel_outside_state_7d','smoothed_wspent_time_indoors_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5_final,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the delphi vaccine data from delphi api\n",
    "def read_delphi_vaccine(state_index,epiweek_date,start_week,end_week):\n",
    "    #'''\n",
    "    # The \n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask','day','state',[start_week, Epidata.range(start_week, end_week)],'*')\n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc11_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask','day','nation',[start_week, Epidata.range(start_week, end_week)],'*')\n",
    "    vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc12_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']+vacc17['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']+vacc26['epidata']\n",
    "    vacc3=vacc31['epidata']#+vacc32['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']\n",
    "    \n",
    "    vacc1_us=vacc11_us['epidata']+vacc12_us['epidata']+vacc13_us['epidata']+vacc14_us['epidata']+vacc15_us['epidata']+vacc16_us['epidata']+vacc17_us['epidata']\n",
    "    vacc2_us=vacc21_us['epidata']+vacc22_us['epidata']+vacc23_us['epidata']+vacc24_us['epidata']+vacc25_us['epidata']+vacc26_us['epidata']\n",
    "    vacc3_us=vacc31_us['epidata']#+vacc32['epidata']\n",
    "    vacc4_us=vacc41_us['epidata']+vacc42_us['epidata']\n",
    "    vacc5_us=vacc51_us['epidata']+vacc52_us['epidata']\n",
    "    \n",
    "    vacc1_final = vacc1 + vacc1_us\n",
    "    vacc2_final = vacc2 + vacc2_us\n",
    "    vacc3_final = vacc3 + vacc3_us\n",
    "    vacc4_final = vacc4 + vacc4_us\n",
    "    vacc5_final = vacc5 + vacc5_us\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc17['result'], vacc17['message'], len(vacc17['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc26['result'], vacc26['message'], len(vacc26['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc31['result'], vacc31['message'], len(vacc31['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc42['result'], vacc42['message'], len(vacc42['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc52['result'], vacc52['message'], len(vacc52['epidata']))\n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask',\n",
    "          'smoothed_wtravel_outside_state_5d','smoothed_wspent_time_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5_final,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the delphi vaccine data from delphi api\n",
    "def read_delphi_vaccine_test(state_index,epiweek_date,start_week,end_week):\n",
    "    #'''\n",
    "    # The \n",
    "    \n",
    "    vacc1 = []\n",
    "    vacc2 = []\n",
    "    vacc3 = []\n",
    "    vacc4 = []\n",
    "    vacc5 = []\n",
    "    vacc1.append(Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc2.append(Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc3.append(Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[start_week, Epidata.range(start_week, end_week)],'*'))\n",
    "    \n",
    "    vacc4.append(Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc5.append(Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    \n",
    "    start_date = date(2021, 3, 1)\n",
    "    while start_date < date.today() + relativedelta(months=-2): \n",
    "        start = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        start_date = start_date + relativedelta(months=+2)\n",
    "        end = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        start = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        start_date = start_date + relativedelta(months=+2)\n",
    "        end = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        print(start)\n",
    "        print(end)\n",
    "        vacc1.append(Epidata.covidcast('fb-survey', 'smoothed_wcovid_vaccinated', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc1_us.append(Epidata.covidcast('fb-survey', 'smoothed_wtested_positive_14d', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_res_wli.append(Epidata.covidcast('fb-survey', 'smoothed_wwearing_mask_7d', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_res_wli_us.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "    \n",
    "    for i in range(1, len(fb_res_cli)): \n",
    "        fb_cli += fb_res_cli[i]['epidata']\n",
    "        fb_cli_us += fb_res_cli_us[i]['epidata']\n",
    "    \n",
    "    \n",
    "    \"\"\"vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask','day','state',[start_week, Epidata.range(start_week, end_week)],'*')\n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "\n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']+vacc17['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']+vacc26['epidata']\n",
    "    vacc3=vacc31['epidata']#+vacc32['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc17['result'], vacc17['message'], len(vacc17['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc26['result'], vacc26['message'], len(vacc26['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc31['result'], vacc31['message'], len(vacc31['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc42['result'], vacc42['message'], len(vacc42['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc52['result'], vacc52['message'], len(vacc52['epidata']))\"\"\"\n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask',\n",
    "          'smoothed_wtravel_outside_state_5d','smoothed_wspent_time_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delphi_fb_google_survey(state_index,epiweek_date,start_week,end_week):\n",
    "    #fb_res_cli = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    fb_res_cli = []\n",
    "    fb_res_cli_us = []\n",
    "    fb_res_wli = []\n",
    "    fb_res_wli_us = []\n",
    "    fb_res_cli.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*'))\n",
    "    fb_res_cli.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    fb_res_cli_us.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*'))\n",
    "    fb_res_cli_us.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    fb_res_wli.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*'))\n",
    "    fb_res_wli.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    fb_res_wli_us.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*'))\n",
    "    fb_res_wli_us.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    start_date = date(2020, 7, 1)\n",
    "    while start_date < date.today() + relativedelta(months=-2): \n",
    "        start = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        start_date = start_date + relativedelta(months=+2)\n",
    "        end = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        print(start)\n",
    "        print(end)\n",
    "        fb_res_cli.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_res_cli_us.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_res_wli.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_res_wli_us.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "    \n",
    "    fb_res_cli.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_res_cli_us.append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_res_wli.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_res_wli_us.append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_cli = fb_res_cli[0]['epidata']\n",
    "    fb_cli_us = fb_res_cli_us[0]['epidata']\n",
    "    fb_wli = fb_res_wli[0]['epidata']\n",
    "    fb_wli_us = fb_res_wli_us[0]['epidata']\n",
    "    for i in range(1, len(fb_res_cli)): \n",
    "        fb_cli += fb_res_cli[i]['epidata']\n",
    "        fb_cli_us += fb_res_cli_us[i]['epidata']\n",
    "    for i in range(1, len(fb_res_wli)):\n",
    "        fb_wli += fb_res_wli[i]['epidata']\n",
    "        fb_wli_us += fb_res_wli_us[i]['epidata']\n",
    "    fb_res_cli_final = fb_cli + fb_cli_us\n",
    "    fb_res_wli_final = fb_wli + fb_wli_us\n",
    "    \"\"\"fb_res_cli1 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220101, Epidata.range(20220101, end_week)], '*')\n",
    "\n",
    "    fb_res_cli1_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20220101, Epidata.range(20220101, end_week)], '*')\n",
    "    \n",
    "\n",
    "    #'''\n",
    "    fb_cli1=fb_res_cli1['epidata']+fb_res_cli2['epidata']\n",
    "    fb_cli2=fb_cli1+fb_res_cli3['epidata']\n",
    "    fb_cli3=fb_cli2+fb_res_cli4['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4=fb_cli3+fb_res_cli5['epidata'] \n",
    "    fb_cli5=fb_cli4+fb_res_cli6['epidata']\n",
    "    fb_cli6=fb_cli5+fb_res_cli7['epidata']\n",
    "    fb_cli7=fb_cli6+fb_res_cli8['epidata']\n",
    "    fb_cli8 = fb_cli7 + fb_res_cli9['epidata']\n",
    "    fb_cli9=fb_cli8 + fb_res_cli10['epidata']\n",
    "    fb_res_cli=fb_cli9+fb_res_cli11['epidata']+fb_res_cli12['epidata']\n",
    "    \n",
    "    fb_cli1_us = fb_res_cli1_us['epidata'] + fb_res_cli2_us['epidata']\n",
    "    fb_cli2_us=fb_cli1_us+fb_res_cli3_us['epidata']\n",
    "    fb_cli3_us=fb_cli2_us+fb_res_cli4_us['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4_us=fb_cli3_us+fb_res_cli5_us['epidata'] \n",
    "    fb_cli5_us=fb_cli4_us+fb_res_cli6_us['epidata']\n",
    "    fb_cli6_us=fb_cli5_us+fb_res_cli7_us['epidata']\n",
    "    fb_cli7_us=fb_cli6_us+fb_res_cli8_us['epidata']\n",
    "    fb_cli8_us = fb_cli7_us + fb_res_cli9_us['epidata']\n",
    "    fb_cli9_us=fb_cli8_us + fb_res_cli10_us['epidata']\n",
    "    fb_res_cli_us=fb_cli9_us+fb_res_cli11_us['epidata']+fb_res_cli12_us['epidata']\n",
    "    \n",
    "    fb_res_cli_final = fb_res_cli + fb_res_cli_us\n",
    "    #print(fb_res1['epidata'][0])\"\"\"\n",
    "    #'''\n",
    "    google_res_cli = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    #google_res_cli_us = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'nation', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #fb_res_wli = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_wli1 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220101, Epidata.range(20220101, end_week)], '*')\n",
    "    \n",
    "    fb_res_wli1_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20220101, Epidata.range(20220101, end_week)], '*')\n",
    "    \n",
    "    #'''\n",
    "    fb_wli1=fb_res_wli1['epidata']+fb_res_wli2['epidata']\n",
    "    fb_wli2=fb_wli1+fb_res_wli3['epidata']\n",
    "    fb_wli3=fb_wli2+fb_res_wli4['epidata']\n",
    "    fb_wli4=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_wli5=fb_wli4+fb_res_wli6['epidata']\n",
    "    fb_wli6=fb_wli5+fb_res_wli7['epidata']\n",
    "    fb_wli7=fb_wli6+fb_res_wli8['epidata']\n",
    "    fb_wli8=fb_wli7+fb_res_wli9['epidata']\n",
    "    fb_wli9=fb_wli8+fb_res_wli10['epidata']\n",
    "    #fb_res_wli=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_res_wli=fb_wli9+fb_res_wli11['epidata']+fb_res_wli12['epidata']\n",
    "    \n",
    "    fb_wli1_us=fb_res_wli1_us['epidata']+fb_res_wli2_us['epidata']\n",
    "    fb_wli2_us=fb_wli1_us+fb_res_wli3_us['epidata']\n",
    "    fb_wli3_us=fb_wli2_us+fb_res_wli4_us['epidata']\n",
    "    fb_wli4_us=fb_wli3_us+fb_res_wli5_us['epidata']\n",
    "    fb_wli5_us=fb_wli4_us+fb_res_wli6_us['epidata']\n",
    "    fb_wli6_us=fb_wli5_us+fb_res_wli7_us['epidata']\n",
    "    fb_wli7_us=fb_wli6_us+fb_res_wli8_us['epidata']\n",
    "    fb_wli8_us=fb_wli7_us+fb_res_wli9_us['epidata']\n",
    "    fb_wli9_us=fb_wli8_us+fb_res_wli10_us['epidata']\n",
    "    #fb_res_wli=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_res_wli_us=fb_wli9_us+fb_res_wli11_us['epidata']+fb_res_wli12_us['epidata']\n",
    "    \n",
    "    fb_res_wli_final = fb_res_wli + fb_res_wli_us\n",
    "    \n",
    "    #google_res_wli = Epidata.covidcast('google-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #print('fb_cli1',fb_res_cli1['result'], fb_res_cli1['message'], len(fb_res_cli1['epidata']))\n",
    "    #print('fb_cli2',fb_res_cli2['result'], fb_res_cli2['message'], len(fb_res_cli2['epidata']))\n",
    "    #print('fb_cli3',fb_res_cli3['result'], fb_res_cli3['message'], len(fb_res_cli3['epidata']))\n",
    "    print('fb_wcli4',fb_res_cli4['result'], fb_res_cli4['message'], len(fb_res_cli4['epidata']))\n",
    "    print('fb_wcli5',fb_res_cli9['result'], fb_res_cli9['message'], len(fb_res_cli9['epidata']))\n",
    "    print('fb_wcli6',fb_res_cli10['result'], fb_res_cli10['message'], len(fb_res_cli10['epidata']))\n",
    "    print('fb_wcli8',fb_res_cli11['result'], fb_res_cli11['message'], len(fb_res_cli11['epidata']))\n",
    "    print('fb_wcli9',fb_res_cli12['result'], fb_res_cli12['message'], len(fb_res_cli12['epidata']))\n",
    "    \n",
    "    print('google_cli',google_res_cli['result'], google_res_cli['message'], len(google_res_cli['epidata']))\n",
    "    \n",
    "    #print(fb_res_wli['result'], fb_res_wli['message'], len(fb_res_wli['epidata']))\n",
    "    \n",
    "    #print('fb_wili1',fb_res_wli1['result'], fb_res_wli1['message'], len(fb_res_wli1['epidata']))\n",
    "    #print('fb_wili2',fb_res_wli2['result'], fb_res_wli2['message'], len(fb_res_wli2['epidata']))\n",
    "    #print('fb_wili3',fb_res_wli3['result'], fb_res_wli3['message'], len(fb_res_wli3['epidata']))\n",
    "    print('fb_wili4',fb_res_wli4['result'], fb_res_wli4['message'], len(fb_res_wli4['epidata']))\n",
    "    print('fb_wili5',fb_res_wli5['result'], fb_res_wli5['message'], len(fb_res_wli5['epidata']))\n",
    "    print('fb_wili10',fb_res_wli10['result'], fb_res_wli10['message'], len(fb_res_wli10['epidata']))\n",
    "    print('fb_wili11',fb_res_wli11['result'], fb_res_wli11['message'], len(fb_res_wli11['epidata']))\n",
    "    print('fb_wili12',fb_res_wli12['result'], fb_res_wli12['message'], len(fb_res_wli12['epidata']))\n",
    "    \n",
    "    print('fb_wcli len',len(fb_res_cli))\n",
    "    print('fb_wli len',len(fb_res_wli))\"\"\"\n",
    "    #'''\n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['fb_survey_wcli','google_survey_cli','fb_survey_wili']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    #week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],google_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli_final,state_index,state_names,epiweek_date)\n",
    "    #'''\n",
    "\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/fb-google-survey.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delphi_fb_google_survey_test(state_index,epiweek_date,start_week,end_week):\n",
    "    #fb_res_cli = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    fb_res_cli1 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_cli13 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220301, Epidata.range(20220301, end_week)], '*')\n",
    "\n",
    "    fb_res_cli1_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_cli13_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20220301, Epidata.range(20220301, end_week)], '*')\n",
    "\n",
    "    #'''\n",
    "    fb_cli1=fb_res_cli1['epidata']+fb_res_cli2['epidata']\n",
    "    fb_cli2=fb_cli1+fb_res_cli3['epidata']\n",
    "    fb_cli3=fb_cli2+fb_res_cli4['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4=fb_cli3+fb_res_cli5['epidata'] \n",
    "    fb_cli5=fb_cli4+fb_res_cli6['epidata']\n",
    "    fb_cli6=fb_cli5+fb_res_cli7['epidata']\n",
    "    fb_cli7=fb_cli6+fb_res_cli8['epidata']\n",
    "    fb_cli8 = fb_cli7 + fb_res_cli9['epidata']\n",
    "    fb_cli9=fb_cli8 + fb_res_cli10['epidata']\n",
    "    fb_res_cli=fb_cli9+fb_res_cli11['epidata']+fb_res_cli12['epidata']+fb_res_cli13['epidata']\n",
    "    \n",
    "    fb_cli1_us = fb_res_cli1_us['epidata'] + fb_res_cli2_us['epidata']\n",
    "    fb_cli2_us=fb_cli1_us+fb_res_cli3_us['epidata']\n",
    "    fb_cli3_us=fb_cli2_us+fb_res_cli4_us['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4_us=fb_cli3_us+fb_res_cli5_us['epidata'] \n",
    "    fb_cli5_us=fb_cli4_us+fb_res_cli6_us['epidata']\n",
    "    fb_cli6_us=fb_cli5_us+fb_res_cli7_us['epidata']\n",
    "    fb_cli7_us=fb_cli6_us+fb_res_cli8_us['epidata']\n",
    "    fb_cli8_us = fb_cli7_us + fb_res_cli9_us['epidata']\n",
    "    fb_cli9_us=fb_cli8_us + fb_res_cli10_us['epidata']\n",
    "    fb_res_cli_us=fb_cli9_us+fb_res_cli11_us['epidata']+fb_res_cli12_us['epidata']+fb_res_cli13_us['epidata']\n",
    "    \n",
    "    fb_res_cli_final = fb_res_cli + fb_res_cli_us\n",
    "    #print(fb_res1['epidata'][0])\n",
    "    #'''\n",
    "    #google_res_cli = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    #google_res_cli_us = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'nation', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #fb_res_wli = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_wli1 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_wli13 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220301, Epidata.range(20220301, end_week)], '*')\n",
    "    \n",
    "    fb_res_wli1_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_wli13_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20220301, Epidata.range(20220101, end_week)], '*')\n",
    "    #'''\n",
    "    fb_wli1=fb_res_wli1['epidata']+fb_res_wli2['epidata']\n",
    "    fb_wli2=fb_wli1+fb_res_wli3['epidata']\n",
    "    fb_wli3=fb_wli2+fb_res_wli4['epidata']\n",
    "    fb_wli4=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_wli5=fb_wli4+fb_res_wli6['epidata']\n",
    "    fb_wli6=fb_wli5+fb_res_wli7['epidata']\n",
    "    fb_wli7=fb_wli6+fb_res_wli8['epidata']\n",
    "    fb_wli8=fb_wli7+fb_res_wli9['epidata']\n",
    "    fb_wli9=fb_wli8+fb_res_wli10['epidata']\n",
    "    #fb_res_wli=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_res_wli=fb_wli9+fb_res_wli11['epidata']+fb_res_wli12['epidata']+fb_res_wli13['epidata']\n",
    "    \n",
    "    fb_wli1_us=fb_res_wli1_us['epidata']+fb_res_wli2_us['epidata']\n",
    "    fb_wli2_us=fb_wli1_us+fb_res_wli3_us['epidata']\n",
    "    fb_wli3_us=fb_wli2_us+fb_res_wli4_us['epidata']\n",
    "    fb_wli4_us=fb_wli3_us+fb_res_wli5_us['epidata']\n",
    "    fb_wli5_us=fb_wli4_us+fb_res_wli6_us['epidata']\n",
    "    fb_wli6_us=fb_wli5_us+fb_res_wli7_us['epidata']\n",
    "    fb_wli7_us=fb_wli6_us+fb_res_wli8_us['epidata']\n",
    "    fb_wli8_us=fb_wli7_us+fb_res_wli9_us['epidata']\n",
    "    fb_wli9_us=fb_wli8_us+fb_res_wli10_us['epidata']\n",
    "    #fb_res_wli=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_res_wli_us=fb_wli9_us+fb_res_wli11_us['epidata']+fb_res_wli12_us['epidata']+fb_res_wli13_us['epidata']\n",
    "    \n",
    "    fb_res_wli_final = fb_res_wli + fb_res_wli_us\n",
    "    \n",
    "    #google_res_wli = Epidata.covidcast('google-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #print('fb_cli1',fb_res_cli1['result'], fb_res_cli1['message'], len(fb_res_cli1['epidata']))\n",
    "    #print('fb_cli2',fb_res_cli2['result'], fb_res_cli2['message'], len(fb_res_cli2['epidata']))\n",
    "    #print('fb_cli3',fb_res_cli3['result'], fb_res_cli3['message'], len(fb_res_cli3['epidata']))\n",
    "    print('fb_wcli4',fb_res_cli4['result'], fb_res_cli4['message'], len(fb_res_cli4['epidata']))\n",
    "    print('fb_wcli5',fb_res_cli9['result'], fb_res_cli9['message'], len(fb_res_cli9['epidata']))\n",
    "    print('fb_wcli6',fb_res_cli10['result'], fb_res_cli10['message'], len(fb_res_cli10['epidata']))\n",
    "    print('fb_wcli8',fb_res_cli11['result'], fb_res_cli11['message'], len(fb_res_cli11['epidata']))\n",
    "    print('fb_wcli9',fb_res_cli12['result'], fb_res_cli12['message'], len(fb_res_cli12['epidata']))\n",
    "    \n",
    "    #print('google_cli',google_res_cli['result'], google_res_cli['message'], len(google_res_cli['epidata']))\n",
    "    \n",
    "    #print(fb_res_wli['result'], fb_res_wli['message'], len(fb_res_wli['epidata']))\n",
    "    \n",
    "    #print('fb_wili1',fb_res_wli1['result'], fb_res_wli1['message'], len(fb_res_wli1['epidata']))\n",
    "    #print('fb_wili2',fb_res_wli2['result'], fb_res_wli2['message'], len(fb_res_wli2['epidata']))\n",
    "    #print('fb_wili3',fb_res_wli3['result'], fb_res_wli3['message'], len(fb_res_wli3['epidata']))\n",
    "    print('fb_wili4',fb_res_wli4['result'], fb_res_wli4['message'], len(fb_res_wli4['epidata']))\n",
    "    print('fb_wili5',fb_res_wli5['result'], fb_res_wli5['message'], len(fb_res_wli5['epidata']))\n",
    "    print('fb_wili10',fb_res_wli10['result'], fb_res_wli10['message'], len(fb_res_wli10['epidata']))\n",
    "    print('fb_wili11',fb_res_wli11['result'], fb_res_wli11['message'], len(fb_res_wli11['epidata']))\n",
    "    print('fb_wili12',fb_res_wli12['result'], fb_res_wli12['message'], len(fb_res_wli12['epidata']))\n",
    "    \n",
    "    print('fb_wcli len',len(fb_res_cli))\n",
    "    print('fb_wli len',len(fb_res_wli))\n",
    "    #'''\n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['fb_survey_wcli','fb_survey_wili']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    #week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli_final,state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[1]]=read_survey_epidata(cols[1],google_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],fb_res_wli_final,state_index,state_names,epiweek_date)\n",
    "    #'''\n",
    "\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/fb-google-survey.csv\")\n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \n",
    "def read_fips_code(state_names,fips_path,abbv_to_code=True):\n",
    "    #if abbv_to_code=True; read fips with given state code (state_names)\n",
    "    #if abbv_to_code=False; read state code with given state name (state_names)\n",
    "    \n",
    "    fips=pd.read_csv(fips_path+\"other_data/fips_codes.csv\",delimiter=',',dtype={'state_code':str})\n",
    "    if abbv_to_code:\n",
    "        fips=fips[['state','state_code']].drop_duplicates().reset_index()\n",
    "    else:\n",
    "        fips=fips[['state','state_name']].drop_duplicates().reset_index()\n",
    "    \n",
    "    state_fips={}\n",
    "    for name in state_names:\n",
    "        if abbv_to_code:\n",
    "            if name=='X':\n",
    "                row='US'\n",
    "            else:\n",
    "                row= str(fips.loc[fips['state'] == name,'state_code'].iloc[0])   \n",
    "        else:\n",
    "            if name=='X':\n",
    "                row='X'\n",
    "            else:\n",
    "                row= fips.loc[fips['state_name'] == name,'state'].iloc[0]   \n",
    "        \n",
    "        state_fips[name]=row\n",
    "    \n",
    "    #print(state_fips)\n",
    "    return state_fips\n",
    "'''\n",
    "def read_covidnet(data_covidnet,week_len,start,end,step,weekly_rate,region): \n",
    "    covid=np.empty(week_len)\n",
    "    covid[:]=np.nan\n",
    "    data_f=data_covidnet.loc[data_covidnet['CATCHMENT']==region]\n",
    "    #data_f=data[data['AGE CATEGORY']=='Overall'].reset_index()\n",
    "    for index,row in data_f.iterrows():\n",
    "        mmr_week=int(row['MMWR-WEEK'])\n",
    "        year=int(row['MMWR-YEAR'])\n",
    "        if row['AGE CATEGORY']=='Overall' and row['SEX']=='Overall' and row['RACE']=='Overall':\n",
    "            if year==2020:\n",
    "                if mmr_week>=start and mmr_week<=53:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "            elif year==2021:\n",
    "                if mmr_week<=end:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "    return covid\n",
    "'''\n",
    "def get_current_week(week,cur_date,last_date,strsplit='/'):\n",
    "    if strsplit=='/':\n",
    "        month,date,year=cur_date.split('/')\n",
    "    elif strsplit=='-':\n",
    "        year,month,date=cur_date.split('-')\n",
    "    cdate=int(date)\n",
    "    cmonth=int(month)\n",
    "    year=int(year)\n",
    "    \n",
    "    #print(cdate,cmonth,year)\n",
    "    if year==20 or year==21 or year == 22:\n",
    "        stryear='20'+str(year)\n",
    "        year=int(stryear)\n",
    "        \n",
    "    for id in range(0,len(week)):\n",
    "        y,m,d=week[id].split('-')\n",
    "        wd,wm,wy=int(d),int(m),int(y)\n",
    "        if wm==cmonth and wd==cdate and wy==year:\n",
    "              return id\n",
    "    if strsplit=='/':\n",
    "        m,d,y=last_date.split('/')\n",
    "    elif strsplit=='-':\n",
    "        y,m,d=last_date.split('-')\n",
    "    \n",
    "    wd,wm,wy=int(d),int(m),int(y)\n",
    "    if wm==cmonth and cdate==wd and wy==year:\n",
    "        return len(week)-1\n",
    "    #print('week index not found:'+cur_date)\n",
    "    return -1\n",
    "\n",
    "def find_same_week(week,cur_date,last_date,date_string=True):\n",
    "    #date,month,year=cur_date.split('-')\n",
    "    tmp_week=week\n",
    "    #tmp_week[-1]=last_date\n",
    "    if date_string:\n",
    "        year,month,date=cur_date[:4],cur_date[4:6],cur_date[6:8]\n",
    "        ly,lm,ld=last_date[:4],last_date[4:6],last_date[6:8]\n",
    "    else:\n",
    "        year,month,date=cur_date.split('-')\n",
    "        ly,lm,ld=last_date.split('-')\n",
    "        \n",
    "    cdate=int(date)\n",
    "    cmonth=int(month)\n",
    "    year=int(year)\n",
    "    \n",
    "    if year==20 or year==21 or year == 22:\n",
    "        stryear='20'+str(year)\n",
    "        year=int(stryear)\n",
    "\n",
    "    for id in range(0,len(tmp_week)):\n",
    "        y,m,d=tmp_week[id].split('-')\n",
    "        wd,wm,wy=int(d),int(m),int(y)\n",
    "        if wm==cmonth and cdate==wd and wy==year:\n",
    "            return id\n",
    "    \n",
    "    ldd,lmm,lyy=int(ld),int(lm),int(ly)\n",
    "    if lmm==cmonth and cdate==ldd and lyy==year:\n",
    "        return len(week)-1\n",
    "    #print('week index not found:'+cur_date)\n",
    "    return -1\n",
    "\n",
    "def find_week_index(week,cur_date,date_string=True,strsplit='-'):\n",
    "    if date_string:\n",
    "        year,month,date=cur_date[:4],cur_date[4:6],cur_date[6:8]\n",
    "    else:\n",
    "        if strsplit=='-':\n",
    "            year,month,date=cur_date.split(strsplit)\n",
    "        elif strsplit=='/':\n",
    "            month,date,year=cur_date.split(strsplit)\n",
    "    \n",
    "    cdate=int(date)\n",
    "    cmonth=int(month)\n",
    "    year=int(year)\n",
    "    \n",
    "    if year==20 or year==21 or year == 22:\n",
    "        stryear='20'+str(year)\n",
    "        year=int(stryear)\n",
    "        \n",
    "    for id in range(0,len(week)):\n",
    "        y,m,d=week[id].split('-')\n",
    "        wd,wm,wy=int(d),int(m),int(y)\n",
    "        if wm==cmonth:\n",
    "          #if wm==12:\n",
    "           #   print(wm,wd,wy,id+1,len(week))\n",
    "          if cdate>wd and wy==year and (id+1)<len(week):\n",
    "              yn,mn,dn=week[id+1].split('-')\n",
    "              wmn=int(mn)\n",
    "              if wmn==(cmonth%12)+1:\n",
    "                  return id+1\n",
    "          elif cdate<=wd and wy==year:\n",
    "              return id\n",
    "    print('week index not found:'+cur_date)\n",
    "    print(cdate,cmonth,year)\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_apple_mobility_per_date(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week):\n",
    "    data=pd.read_csv(inputdir+\"applemobilitytrends.csv\",low_memory=False)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates=list(data.columns)\n",
    "    dates=dates[6:]\n",
    "    data = data.loc[data['region'].isin(state_names)]\n",
    "    data=data.fillna(0)\n",
    "    #print(data.shape)\n",
    "    date_dic={dates[i]: i for i in range(len(dates))} \n",
    "    week_cases=np.zeros((len(state_names),len(dates)))\n",
    "    for ix,row in data.iterrows():\n",
    "        if row['transportation_type']=='driving':\n",
    "            if row['region'] in state_names:\n",
    "                state_id=state_index[dic_names_to_abbv[row['region']]] \n",
    "                for d in dates:\n",
    "                    #w_idx=find_week_index(epiweek_date,d,date_string=False)\n",
    "                    #if w_idx!=-1:\n",
    "                    week_cases[state_id][date_dic[d]]+=float(row[d])\n",
    "    apple_dic={}\n",
    "    apple_dic['mobility']=week_cases    \n",
    "    \n",
    "    unit_test(apple_dic,['mobility'],dates,state_index,\"unit_test/mobility-sampled-data.csv\")\n",
    "    \n",
    "    return apple_dic,['apple_mobility']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek_list(week_start,week_end,year):\n",
    "    def convert(x):\n",
    "        return Week.fromstring(str(x))\n",
    "    \n",
    "    wstart=convert(week_start)\n",
    "    wend=convert(week_end)\n",
    "    #print(wstart,wend)\n",
    "    week_edate_list=[]\n",
    "    week_list=[]\n",
    "    for week in Year(year).iterweeks():\n",
    "        date_time = week.enddate().strftime(\"%Y-%m-%d\")\n",
    "        #print(week,date_time)\n",
    "        if week>=wstart and week<=wend:\n",
    "            week_edate_list.append(date_time)\n",
    "            week_list.append(str(week))\n",
    "     \n",
    "    return week_list,week_edate_list  \n",
    "\n",
    "def convert_to_epiweek(x):\n",
    "    return Week.fromdate(x)\n",
    "def read_mobility(inputdir,epiweek_date,end_week,MISSING_TOKEN=0):\n",
    "    data=pd.read_csv(inputdir+\"Global_Mobility_Report.csv\",low_memory=False)\n",
    "    data=data[data['country_region_code']=='US']\n",
    "    data=data.drop(data[data['sub_region_1'] == 'Hawaii'].index)\n",
    "    data= data[pd.isnull(data['sub_region_2'])]\n",
    "    data=data.drop(columns=['sub_region_2'])\n",
    "    \n",
    "    state_names=data['sub_region_1'].drop_duplicates().values\n",
    "    state_names[0]='X' #changing nan to US national X\n",
    "    cols=data.columns\n",
    "    print(cols)\n",
    "    cols=list(cols[8:])\n",
    "    print(cols)\n",
    "    \n",
    "    data['sub_region_1'] = data['sub_region_1'].fillna('X')\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['epiweek'] = data['date'].dt.date.apply(convert_to_epiweek)\n",
    "    epiweek_data = data.groupby(['epiweek', 'sub_region_1'], as_index=False).mean()\n",
    "    dic_names_to_abbv=read_fips_code(state_names,inputdir,abbv_to_code=False)\n",
    "    print(dic_names_to_abbv)\n",
    "    \n",
    "    state_index = {dic_names_to_abbv[state_names[i]]: i for i in range(len(state_names))} \n",
    "    print(state_index)\n",
    "    \n",
    "    #data[cols] = data[cols].fillna(MISSING_TOKEN)\n",
    "    num_states=len(state_names)\n",
    "    #print(cols)\n",
    "    week_cases={}\n",
    "    week_cases_check = {}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((num_states,len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        week_cases_check[c] = np.full((num_states,len(epiweek_date)), False)\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((num_states,len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_week)!=0:\n",
    "            week_cases[c][:][end_week]=np.nan\n",
    "        '''\n",
    "    print(cols)\n",
    "    \n",
    "    #'''\n",
    "    for ix,row in data.iterrows():\n",
    "        state_id=state_index[dic_names_to_abbv[row['sub_region_1']]]\n",
    "        week_id=find_week_index(epiweek_date,str(row['date'].date()),date_string=False)\n",
    "        if week_id!=-1:\n",
    "            for c in cols:\n",
    "                if not pd.isnull(row[c]) and not week_cases_check[c][state_id][week_id]: \n",
    "                    value = epiweek_data[epiweek_data['epiweek'] == convert_to_epiweek(row['date'])] \n",
    "                    value = value[value['sub_region_1'] == row['sub_region_1']]\n",
    "                    for i in value[c]: \n",
    "                        week_cases[c][state_id][week_id] = i\n",
    "                    week_cases_check[c][state_id][week_id] = True\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/google-mobility.csv\")\n",
    "    #'''\n",
    "    \n",
    "    return week_cases,cols,state_index,dic_names_to_abbv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vaccine_doses(inputdir,epiweek_date,state_index,dic_names_to_abbv,last_date):\n",
    "    data=pd.read_csv(inputdir+\"vaccine_data_us_state_timeline.csv\",low_memory=False)\n",
    "    #data=data.fillna(0)\n",
    "    #state_names=list(state_index.keys())\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    #cols=['people_total','people_total_2nd_dose']\n",
    "    cols=['Stage_One_Doses','Stage_Two_Doses']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "\n",
    "    \n",
    "    for ix,row in data.iterrows():\n",
    "        #print(len(epiweek_date),row['Date'],last_date)\n",
    "        w_idx=get_current_week(epiweek_date,row['Date'],last_date,strsplit='-')\n",
    "        if row['Province_State'] in state_names and w_idx!=-1 and row['Vaccine_Type']=='All':\n",
    "            #state_id=state_index[row['stabbr']] \n",
    "            state_id=state_index[dic_names_to_abbv[row['Province_State']]] \n",
    "            for c in cols:\n",
    "                val=None\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    val=float(row[c])\n",
    "                elif w_idx>0:\n",
    "                    val=week_cases[c][state_id][w_idx-1] \n",
    "                if np.isnan(week_cases[c][0][w_idx]): \n",
    "                    week_cases[c][0][w_idx] = 0\n",
    "                week_cases[c][state_id][w_idx]=val\n",
    "                week_cases[c][0][w_idx]+=val\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine.csv\")\n",
    "    \n",
    "    return week_cases,cols\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_apple_mobility(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week):\n",
    "    data=pd.read_csv(inputdir+\"applemobilitytrends.csv\",low_memory=False)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates=list(data.columns)\n",
    "    dates=dates[6:]\n",
    "    data = data.loc[data['region'].isin(state_names)]\n",
    "    #data=data.fillna(0)\n",
    "    #print(data.shape)\n",
    "    #week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    week_cases=np.empty((len(state_names),len(epiweek_date)))\n",
    "    week_cases[:][:]=np.nan\n",
    "    for ix,row in data.iterrows():\n",
    "        if row['transportation_type']=='driving':\n",
    "            if row['region'] in state_names:\n",
    "                state_id=state_index[dic_names_to_abbv[row['region']]] \n",
    "                for d in dates:\n",
    "                    w_idx=find_week_index(epiweek_date,d,date_string=False)\n",
    "                    if w_idx!=-1 and pd.isnull(row[d])==False:\n",
    "                        if np.isnan(week_cases[state_id][w_idx]):\n",
    "                            week_cases[state_id][w_idx]=0\n",
    "                        week_cases[state_id][w_idx]+=float(row[d])/7\n",
    "    apple_dic={}\n",
    "    apple_dic['apple_mobility']=week_cases    \n",
    "    \n",
    "    unit_test(apple_dic,['apple_mobility'],epiweek_date,state_index,\"unit_test/apple.csv\")\n",
    "    \n",
    "    return apple_dic,['apple_mobility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dex(inputdir,epiweek_date,state_index,start_week,end_week):\n",
    "    data=pd.read_csv(inputdir+\"state_dex.csv\",low_memory=False)\n",
    "    cols=[]\n",
    "    state_names=list(state_index.keys())\n",
    "    for c in data.columns:\n",
    "        if 'dex' in c:\n",
    "            cols.append(c)\n",
    "    \n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        week_cases[c][0][:]=0\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "        if (end_week-len(epiweek_date))!=0:\n",
    "            week_cases[c][:][-1]=np.nan\n",
    "        '''\n",
    "    \n",
    "    for ix,row in data.iterrows():\n",
    "        w_idx=find_week_index(epiweek_date,row['date'],date_string=False)\n",
    "        if row['state'] in state_names and w_idx!=-1:\n",
    "            state_id=state_index[row['state']]\n",
    "            for c in cols:\n",
    "                if not math.isnan(row[c]):\n",
    "                    if np.isnan(week_cases[c][state_id][w_idx]):\n",
    "                        week_cases[c][state_id][w_idx]=0\n",
    "                    week_cases[c][state_id][w_idx]+=float(row[c])\n",
    "                    week_cases[c][0][w_idx]+=float(row[c])\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/dex.csv\")\n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_emergency(inputdir,epiweek_date,state_index,start_week,end_week):\n",
    "    #data=pd.read_csv(inputdir+\"emergency-visits.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"covid-like-illness.csv\")\n",
    "    data=pd.read_csv(inputdir+\"covid-like-illness-v202040.csv\")\n",
    "    cols=['Number of Facilities Reporting','CLI Percent of Total Visits']\n",
    "    print(data.columns)\n",
    "    data=data[data['week']>=start_week]\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    \n",
    "    \n",
    "    region_map={'X':0,'Region 1':1,'Region 2':2, 'Region 3':3,'Region 4':4,'Region 5':5,'Region 6':6,\n",
    "               'Region 7':7,'Region 8':8,'Region 9':9,'Region 10':10}\n",
    "\n",
    "    file = open(inputdir+\"other_data/hhs_regions_abbv.txt\", 'r') \n",
    "    Lines = file.readlines() \n",
    "    state_hhs_map={}\n",
    "    #### mapping each state to a hhs region ###\n",
    "    state_hhs_map[0]=0 # setting national value\n",
    "    for line in Lines:\n",
    "        regions=line.strip().split(',')\n",
    "        reg_id=int(regions[0])\n",
    "        for j in range(1,len(regions)):\n",
    "            if state_index.get(regions[j],-1)!=-1:\n",
    "                state_id=state_index[regions[j]]\n",
    "                state_hhs_map[state_id]=reg_id\n",
    "            else:\n",
    "                print('state not found '+regions[j])\n",
    "    print(state_index)\n",
    "    list1 = state_hhs_map.keys()\n",
    "    list2 = sorted(list1)\n",
    "    print(list2)\n",
    "    for ix,row in data.iterrows():\n",
    "        reg_id=region_map[row['region']]\n",
    "        week=str(row['week'])\n",
    "        w_idx=int(week[4:])-1\n",
    "        year=int(week[:4])\n",
    "        if year>2020:\n",
    "            w_idx+=53*(year-2020)\n",
    "        for st in range(len(state_names)):\n",
    "            if state_hhs_map[st]==reg_id:\n",
    "                for c in cols:\n",
    "                    reporting=row[c]\n",
    "                    if c=='Number of Facilities Reporting':\n",
    "                        reporting=int(reporting.replace(',',''))\n",
    "                    #print(state_names[st],w_idx,reporting)\n",
    "                    week_cases[c][st][w_idx]=reporting\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/emergency.csv\")\n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kinsa(inputdir,epiweek_date,state_index,start_week,end_week,isregion=False):\n",
    "    if isregion:\n",
    "        data=pd.read_csv(inputdir+\"kinsa_observedili_region_avg.csv\")\n",
    "    else:\n",
    "        data=pd.read_csv(inputdir+\"kinsa_observedili_state_avg.csv\")\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    grouped_kinsa= data.groupby(['region'])\n",
    "    \n",
    "    for name, group in grouped_kinsa:\n",
    "        state_id=state_index[name]\n",
    "        #print(name)\n",
    "        #print(group)\n",
    "        week_cases[state_id][:end_week]=group['cases'][start_week-1:end_week]\n",
    "    kinsa_dic={}\n",
    "    kinsa_dic['kinsa_cases']=week_cases\n",
    "    unit_test(kinsa_dic,['kinsa_cases'],epiweek_date,state_index,\"unit_test/kinsa.csv\")\n",
    "    return kinsa_dic,['kinsa_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iqvia(inputdir,epiweek_date,state_index,start_week,end_week):\n",
    "    data=pd.read_csv(inputdir+\"iqvia_Processed.csv\")\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    grouped_iqvia= data.groupby(['region'])\n",
    "    cols=list(data.columns)\n",
    "    cols=cols[4:]\n",
    "    print(cols)\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    \n",
    "    for name, group in grouped_iqvia:\n",
    "        state_id=state_index[name]\n",
    "        for c in cols:\n",
    "            #week_cases[c][state_id][start_week-10:end_week-start_week]=group[c]\n",
    "            week_cases[c][state_id][:end_week]=group[c][start_week-1:end_week]\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/iqvia.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cdc_hosp(inputdir,epiweek_date,state_index,end_week):\n",
    "    data=pd.read_csv(inputdir+\"COVID-19_Reported_Timeseries.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"reported_hospital_timeseries.csv\")\n",
    "    \n",
    "    #data=data.fillna(0)\n",
    "    state_index['PR'] = 51\n",
    "    state_index['VI'] = 52\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    flu_week_cases={}\n",
    "    #cols_d=list(data.columns)\n",
    "    #print(cols_d)\n",
    "    #cols=cols[2:]\n",
    "    cols=['cdc_hospitalized']\n",
    "    flu_cols=['cdc_flu_hosp']\n",
    "    \n",
    "    cols_to_check=['previous_day_admission_adult_covid_confirmed', 'previous_day_admission_pediatric_covid_confirmed']\n",
    "    flu_cols_to_check=['previous_day_admission_influenza_confirmed']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "    week_cases[c][:][:]=np.nan\n",
    "    week_cases[c][0][:]=0\n",
    "    for c in flu_cols:\n",
    "        flu_week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "    flu_week_cases[c][:][:]=np.nan\n",
    "    flu_week_cases[c][0][:]=0\n",
    "    \n",
    "    # shift one up\n",
    "    data['datetime'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values(by=['datetime'])\n",
    "    data['previous_day_admission_influenza_confirmed'] = data.groupby('state')['previous_day_admission_influenza_confirmed'].shift(-1)\n",
    "    data.reset_index()\n",
    "    \n",
    "    # data['previous_day_admission_influenza_confirmed'] = data.groupby('state')['previous_day_admission_influenza_confirmed'].shift(-1)\n",
    "    # data['previous_day_admission_influenza_confirmed'] = data['previous_day_admission_influenza_confirmed'].shift(-1)\n",
    "\n",
    "    for index,row in data.iterrows():\n",
    "        if row['state'] in state_index.keys():\n",
    "            state_id=state_index[row['state']]\n",
    "        else:\n",
    "            continue\n",
    "        date=str(row['date'])\n",
    "        week_id=find_week_index(epiweek_date,date.replace('/','-'),date_string=False)\n",
    "        # flu_date = str(datetime.strptime(date.replace('/','-'), '%Y-%m-%d') - timedelta(days=1))\n",
    "        # flu_date = flu_date[:10]\n",
    "        # flu_week_id = find_week_index(epiweek_date, flu_date, date_string=False)\n",
    "        if week_id!=-1:\n",
    "            ttl=0\n",
    "            flag_is_not_nan=False\n",
    "            for c in cols_to_check: \n",
    "                if pd.isnull(row[c])==False:\n",
    "                    ttl+=float(row[c])\n",
    "                    flag_is_not_nan=True\n",
    "            if flag_is_not_nan:\n",
    "                if np.isnan(week_cases[cols[0]][state_id][week_id]):\n",
    "                    week_cases[cols[0]][state_id][week_id]=0\n",
    "                week_cases[cols[0]][state_id][week_id]+=ttl\n",
    "                week_cases[cols[0]][0][week_id]+=ttl\n",
    "            else:\n",
    "                week_cases[cols[0]][state_id][week_id]=np.nan\n",
    "                \n",
    "            # same for flu hosp\n",
    "            ttl=0\n",
    "            flag_is_not_nan=False\n",
    "            for c in flu_cols_to_check: \n",
    "                if pd.isnull(row[c])==False:\n",
    "                    ttl+=float(row[c])\n",
    "                    flag_is_not_nan=True\n",
    "            if flag_is_not_nan:\n",
    "                if np.isnan(flu_week_cases[flu_cols[0]][state_id][week_id]):\n",
    "                    flu_week_cases[flu_cols[0]][state_id][week_id]=0\n",
    "                flu_week_cases[flu_cols[0]][state_id][week_id]+=ttl\n",
    "                flu_week_cases[flu_cols[0]][0][week_id]+=ttl\n",
    "            else:\n",
    "                flu_week_cases[flu_cols[0]][state_id][week_id]+=0\n",
    "                \n",
    "            \n",
    "                    \n",
    "    '''\n",
    "    week_cases[c][0]=np.zeros(len(epiweek_date))\n",
    "    for s in range(1,len(state_names)):\n",
    "        for c in cols:\n",
    "            week_cases[c][0]+=week_cases[c][s]\n",
    "            #week_cases[c][s][-1]=np.nan #considering data 2 weeks lag\n",
    "            #week_cases[c][s][-2]=np.nan\n",
    "    '''\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/cdc_hosp.csv\") \n",
    "    del state_index['PR']\n",
    "    del state_index['VI']\n",
    "    return week_cases,cols,flu_week_cases,flu_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_covidnet(data_covidnet,week_len,start,end,step,weekly_rate,region): #region='X'\n",
    "    print(region)\n",
    "    covid=np.empty(week_len)\n",
    "    covid[:]=np.nan\n",
    "    data_f=data_covidnet.loc[data_covidnet['CATCHMENT']==region]\n",
    "    #data_f=data[data['AGE CATEGORY']=='Overall'].reset_index()\n",
    "    for index,row in data_f.iterrows():\n",
    "        mmr_week=int(row['MMWR-WEEK'])\n",
    "        year=int(row['MMWR-YEAR'])\n",
    "        if row['AGE CATEGORY']=='Overall' and row['SEX']=='Overall' and row['RACE']=='Overall':\n",
    "            if year==2020:\n",
    "                if mmr_week>=start and mmr_week<=53:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "            elif year==2021:\n",
    "                if mmr_week<=52:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "            elif year==2022:\n",
    "                if mmr_week<=end:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[95+step+mmr_week]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[95+step+mmr_week]=float(row[weekly_rate])\n",
    "                \n",
    "    return covid\n",
    "\n",
    "def read_covidnet_data(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week,step):\n",
    "    #data_covidnet=pd.read_csv(inputdir+\"COVID-NET_Processed.csv\",delimiter=',')\n",
    "    if date.today().weekday() != 6:\n",
    "        week_num = (date.today()-timedelta(days=2)).strftime(\"%U\")\n",
    "        year_week_num = \"2022\" + week_num\n",
    "    else:\n",
    "        week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "        year_week_num = \"2022\" + week_num\n",
    "    print(year_week_num)\n",
    "    file_name = \"COVID-NET_v\"+year_week_num + \".csv\"\n",
    "    data_covidnet=pd.read_csv(inputdir+file_name,delimiter=',')\n",
    "    columns=list(data_covidnet.columns)\n",
    "    dic_names_to_abbv['Entire Network']='X'\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    #print(state_names)\n",
    "    #state_names=list(state_index.keys())\n",
    "    #print(columns)\n",
    "    weekly_rate='WEEKLY RATE'\n",
    "    if 'WEEKLY RATE' in columns:\n",
    "        data_covidnet=data_covidnet[['CATCHMENT','NETWORK','MMWR-YEAR','MMWR-WEEK','AGE CATEGORY','SEX','RACE','WEEKLY RATE']]\n",
    "    else:\n",
    "        data_covidnet=data_covidnet[['CATCHMENT','NETWORK','MMWR-YEAR','MMWR-WEEK','AGE CATEGORY','SEX','RACE','WEEKLY RATE ']]\n",
    "        weekly_rate='WEEKLY RATE '\n",
    "    \n",
    "    week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #for st in state_index.keys():\n",
    "    for state in state_names:\n",
    "        if state=='United States' or state=='X':\n",
    "            continue\n",
    "        st=dic_names_to_abbv[state]\n",
    "        #print(st,state_index[st])\n",
    "        week_cases[state_index[st]][:]=read_covidnet(data_covidnet,len(epiweek_date),start_week,end_week,step,weekly_rate,region=state)\n",
    "    \n",
    "    covidnet_dic={}\n",
    "    covidnet_dic['covidnet']=week_cases\n",
    "    unit_test(covidnet_dic,['covidnet'],epiweek_date,state_index,\"unit_test/covidnet.csv\")\n",
    "    return covidnet_dic,['covidnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hosp_negative_total_data(inputdir,epiweek_date,state_index):\n",
    "    data_hosp=pd.read_csv(inputdir+\"COVID-19_PCR_Testing_Time_Series.csv\",delimiter=',')\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    cols=['negativeIncr','total_resultsIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for index,row in data_hosp.iterrows():\n",
    "        if row['overall_outcome']=='Negative':\n",
    "            if row['state'] in state_index.keys():\n",
    "                state_id=state_index[row['state']]\n",
    "                date=row['date']\n",
    "                week_id=find_week_index(epiweek_date,date.replace('/','-'),date_string=False)\n",
    "#                 print(week_cases)[state_id][week_id]\n",
    "                week_cases[cols[0]][state_id][week_id]+=float(row['new_results_reported'])\n",
    "                week_cases[cols[1]][state_id][week_id]+=float(row['total_results_reported'])\n",
    "            \n",
    "                week_cases[cols[0]][0][week_id]+=float(row['new_results_reported'])\n",
    "                week_cases[cols[1]][0][week_id]+=float(row['total_results_reported'])\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/hosp_neg_ttl.csv\") \n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hosp_negative_total_data_test(inputdir,epiweek_date,state_index):\n",
    "    data_hosp=pd.read_csv(inputdir+\"COVID-19_PCR_Testing_Time_Series.csv\",delimiter=',')\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    cols=['cdc_negativeIncr','cdc_positiveIncr', 'cdc_total_resultsIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    \n",
    "    \n",
    "    for index,row in data_hosp.iterrows():\n",
    "        if row['state'] in state_index.keys():\n",
    "            if row['overall_outcome']=='Negative':\n",
    "                test_type = cols[0]\n",
    "            elif row['overall_outcome'] == 'Positive': \n",
    "                test_type = cols[1]\n",
    "            else:\n",
    "                test_type = \"NA\"\n",
    "            state_id=state_index[row['state']]\n",
    "            date=row['date']\n",
    "            week_id=find_week_index(epiweek_date,date.replace('/','-'),date_string=False)\n",
    "            if test_type != \"NA\": \n",
    "#                 print(week_cases)[state_id][week_id]\n",
    "                if np.isnan(week_cases[test_type][state_id][week_id]): \n",
    "                    week_cases[test_type][state_id][week_id] = 0\n",
    "                if np.isnan(week_cases[test_type][0][week_id]): \n",
    "                    week_cases[test_type][0][week_id] = 0\n",
    "                week_cases[test_type][state_id][week_id]+=float(row['new_results_reported'])\n",
    "                week_cases[test_type][0][week_id]+=float(row['new_results_reported'])\n",
    "            if np.isnan(week_cases[cols[2]][state_id][week_id]): \n",
    "                week_cases[cols[2]][state_id][week_id] = 0\n",
    "            if np.isnan(week_cases[cols[2]][0][week_id]): \n",
    "                week_cases[cols[2]][0][week_id] = 0\n",
    "            week_cases[cols[2]][state_id][week_id]+=float(row['new_results_reported'])\n",
    "            week_cases[cols[2]][0][week_id]+=float(row['new_results_reported'])\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/hosp_neg_ttl.csv\") \n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_columns(orig_col,epiweek_date):\n",
    "    d_len=len(epiweek_date)-3\n",
    "    imputed_col=np.empty(len(epiweek_date))\n",
    "    imputed_col[-2:]=orig_col[-2:]\n",
    "    while d_len>=0:\n",
    "        if orig_col[d_len]==0 or orig_col[d_len]==np.nan:     \n",
    "            if orig_col[d_len+2]!=0: #geometric mean a,b,c a=0,c!=0\n",
    "                imputed_col[d_len]=np.square(orig_col[d_len+1])/orig_col[d_len+2]\n",
    "            #else orig_col[d_len+1]!=0:: #arithmetic mean a=0, c==0\n",
    "             #   imputed_col[d_len]=2*orig_col[d_len+1]-orig_col[d_len+2]\n",
    "        d_len-=1\n",
    "    return imputed_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hosp_cases_nat_state(data_national,data_state,epiweek_date,week_save,state_index,cols,state_error,last_date):\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    #processing national cases\n",
    "    nat_id=state_index['X']\n",
    "    nat_hosp_incr=np.zeros(len(epiweek_date))\n",
    "    for index,row in data_national.iterrows():\n",
    "        week_id=find_week_index(week_save,str(row['date']))\n",
    "        for c in range(len(cols)): #if next1,next2 consider then do cols-4\n",
    "            week_cases[cols[c]][nat_id][week_id]+=row[cols[c]]\n",
    "    \n",
    "    #processing state cases\n",
    "    for index,row in data_state.iterrows():\n",
    "        state_id=state_index[row['states']]\n",
    "        week_id=find_week_index(week_save,str(row['date']))\n",
    "        if week_id!=-1:\n",
    "            for c in range(len(cols)): #if next1,next2 consider then do cols-4\n",
    "                if cols[c]=='hospitalizedIncrease':\n",
    "                    if row['states'] in state_error:\n",
    "                        week_id_for_hsp=find_same_week(epiweek_date,str(row['date']),last_date)\n",
    "                        if week_id_for_hsp!=-1:\n",
    "                            week_cases[cols[c]][state_id][week_id_for_hsp]=max(0,row['hospitalizedCurrently'])\n",
    "                    else:\n",
    "                        week_cases[cols[c]][state_id][week_id]+=max(0,row[cols[c]])\n",
    "                        nat_hosp_incr[week_id]+=max(0,row[cols[c]])\n",
    "                    #week_id_for_hsp=find_same_week(epiweek_date,str(row['date']),last_date)\n",
    "                    #if week_id_for_hsp!=-1:\n",
    "                     #   week_cases[cols[c]][state_id][week_id_for_hsp]=max(0,row['hospitalizedCurrently'])\n",
    "                elif cols[c]=='recovered':\n",
    "                    week_id_for_rec=find_same_week(epiweek_date,str(row['date']),last_date)\n",
    "                    if week_id_for_rec!=-1:\n",
    "                        week_cases[cols[c]][state_id][week_id_for_rec]=max(0,row[cols[c]])                           \n",
    "                else:\n",
    "                    week_cases[cols[c]][state_id][week_id]+=max(0,row[cols[c]])\n",
    "    \n",
    "    #for states with no hospitalze cumulative using formula week[t]=hosp_cur[t]-(week[t-1]/2)\n",
    "    \n",
    "    c='hospitalizedIncrease'\n",
    "    for s in state_error:\n",
    "    #for s in state_names:\n",
    "        st_idx=state_index[s]\n",
    "        hsp_incr=np.zeros(len(epiweek_date))\n",
    "        hsp_incr[0]=week_cases[c][st_idx][0]\n",
    "        nat_hosp_incr[0]+=week_cases[c][st_idx][0]\n",
    "        for w in range(1,len(epiweek_date)):\n",
    "            hsp_incr[w]=max(0,week_cases[c][st_idx][w]-float(hsp_incr[w-1]/2))\n",
    "            nat_hosp_incr[w]+=hsp_incr[w]\n",
    "            #if s=='CA':\n",
    "             #   print(w,week_cases[c][st_idx][w],hsp_incr[w-1],hsp_incr[w])\n",
    "        week_cases[c][st_idx]=hsp_incr\n",
    "    \n",
    "    c='recovered'\n",
    "    rec_nat=np.zeros(len(epiweek_date))\n",
    "    for s in state_names:\n",
    "        st_idx=state_index[s]\n",
    "        rec_incr=np.zeros(len(epiweek_date))\n",
    "        rec_incr[0]=week_cases[c][st_idx][0]\n",
    "        for w in range(1,len(epiweek_date)):\n",
    "            rec_incr[w]=week_cases[c][st_idx][w]-week_cases[c][st_idx][w-1]\n",
    "            rec_nat[w]+=max(rec_incr[w],0)\n",
    "        week_cases[c][st_idx]=rec_incr\n",
    "    \n",
    "    week_cases[c][nat_id]=rec_nat\n",
    "    \n",
    "    '''    \n",
    "    #for data imputation\n",
    "    for st in range(len(state_names)):\n",
    "        for c in range(0,len(cols)):#if next1,next2 consider then do cols-4\n",
    "            if c<3 or c>4: #avoiding inVentilation, inICU for imputation\n",
    "                imputed_week=impute_columns(week_cases[cols[c]][st],epiweek_date)\n",
    "                week_cases[cols[c]][st]=imputed_week\n",
    "    '''\n",
    "    '''\n",
    "    #filling up next1,next2 values\n",
    "    h_next1=np.empty((len(state_names),len(epiweek_date)))\n",
    "    h_next2=np.empty((len(state_names),len(epiweek_date)))\n",
    "    d_next1=np.empty((len(state_names),len(epiweek_date)))\n",
    "    d_next2=np.empty((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    h_next1[:,:]=np.nan\n",
    "    h_next2[:,:]=np.nan\n",
    "    d_next1[:,:]=np.nan\n",
    "    d_next2[:,:]=np.nan     \n",
    "    for st in range(len(state_names)):\n",
    "        for widx in range(0,len(epiweek_date)-1):\n",
    "            h_next1[st][widx]=week_cases['hospitalizedIncrease'][st][widx+1]\n",
    "            d_next1[st][widx]=week_cases['deathIncrease'][st][widx+1]\n",
    "            if widx+2<len(epiweek_date):\n",
    "                h_next2[st][widx]=week_cases['hospitalizedIncrease'][st][widx+2]\n",
    "                d_next2[st][widx]=week_cases['deathIncrease'][st][widx+2]\n",
    "        week_cases['h_next1'][st]=h_next1[st]\n",
    "        week_cases['h_next2'][st]=h_next2[st]\n",
    "        week_cases['d_next1'][st]=d_next1[st]\n",
    "        week_cases['d_next2'][st]=d_next2[st]\n",
    "    '''\n",
    "    '''\n",
    "    out=pd.DataFrame(columns=['date','states']+cols)\n",
    "    for st in state_index.keys():\n",
    "        tmp_out=pd.DataFrame(columns=['date','states']+cols)\n",
    "        tmp_out['date']=week_save\n",
    "        tmp_out['states']=[st]*len(epiweek_date)\n",
    "        for c in cols:\n",
    "            tmp_out[c]=week_cases[c][state_index[st]]\n",
    "        out=out.append(tmp_out,ignore_index=True)\n",
    "    \n",
    "    out.to_csv(\"/Users/anikat/Downloads/covid-hospitalization-data/hosp_check.csv\",index=False)\n",
    "    '''\n",
    "    np.savetxt(\"unit_test/hos_nat_aggregated.csv\", nat_hosp_incr, fmt='%.4f')\n",
    "    return week_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hospitalization(input_national,input_state,epiweek_date,week_save,state_index,\n",
    "                         last_date,state_error):\n",
    "    nat_data_path=\"us-daily-hospitalizations.csv\"\n",
    "    state_data_path=\"states-daily-hospitalizations.csv\"\n",
    "    nat_data=pd.read_csv(input_national+nat_data_path,delimiter=',')\n",
    "    state_data=pd.read_csv(input_state+state_data_path,delimiter=',')\n",
    "    state_data=state_data.rename(columns={\"state\": \"states\"})\n",
    "    \n",
    "    columns=['date','states','hospitalizedCurrently','onVentilatorCurrently','positiveIncrease','negativeIncrease',\n",
    "             'totalTestResultsIncrease','inIcuCurrently','recovered','deathIncrease','hospitalizedIncrease']\n",
    "    rows_to_drop=['GU','AS','HI','PR', 'MP','VI']\n",
    "    \n",
    "    nat_data_filter=nat_data[columns]\n",
    "    state_data_filter=state_data[columns]\n",
    "    \n",
    "    nat_data_filter=nat_data_filter.fillna(0)\n",
    "    state_data_filter=state_data_filter.fillna(0)\n",
    "    \n",
    "    index_to_remove=[]\n",
    "    for index, row in state_data_filter.iterrows():\n",
    "        #print(row['Province/State'])\n",
    "        if row['states'] in rows_to_drop:\n",
    "            index_to_remove.append(index)\n",
    "\n",
    "    state_data_filter=state_data_filter.drop(index=index_to_remove).reset_index()\n",
    "    #print(state_data_filter['states'].drop_duplicates())\n",
    "    #cols_for_hosp=['positiveIncrease','negativeIncrease','totalTestResultsIncrease','onVentilatorCurrently',\n",
    "     #              'inIcuCurrently','deathIncrease','recovered','hospitalizedIncrease','h_next1','h_next2',\n",
    "      #             'd_next1','d_next2']\n",
    "    cols_for_hosp=['positiveIncrease','negativeIncrease','totalTestResultsIncrease','onVentilatorCurrently',\n",
    "                   'inIcuCurrently','deathIncrease','recovered','hospitalizedIncrease']\n",
    "    \n",
    "    week_cases=hosp_cases_nat_state(nat_data_filter,state_data_filter,epiweek_date,week_save,state_index,cols_for_hosp,state_error,last_date)\n",
    "    \n",
    "    unit_test(week_cases,cols_for_hosp,epiweek_date,state_index,\"unit_test/hospitalization.csv\")\n",
    "    return week_cases,cols_for_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excess_death(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week,this_month,last_date):\n",
    "    data=pd.read_csv(inputdir+\"Excess_Deaths_COVID-19.csv\")\n",
    "#     cols_death=['Observed Number','Excess Higher Estimate']\n",
    "    cols_death = ['Observed Number','Excess Estimate']\n",
    "#     out_cols = ['Observed Numberv2','Excess Estimatev2']\n",
    "    cols=['Week Ending Date','State']+cols_death\n",
    "    data=data[cols]\n",
    "    data[cols]=data[cols].fillna(0)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    week_cases={}\n",
    "    for c in cols_death:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        week=row['Week Ending Date']\n",
    "        y,m,d=week.split('-')\n",
    "        cm,cd,cy=int(m),int(d),int(y)\n",
    "        name=row['State']\n",
    "        if name in state_names and cy>=2020: #and cm<=this_month:\n",
    "            #print(name)\n",
    "            #print(group)\n",
    "            cur_date=y+'-'+m+'-'+d\n",
    "            w_idx=find_same_week(epiweek_date,cur_date,last_date,date_string=False)\n",
    "            if w_idx!=-1:\n",
    "                state_id=state_index[dic_names_to_abbv[name]]\n",
    "                for c in cols_death:\n",
    "                    #if name=='Alabama':\n",
    "                     #   print(name,cur_date,w_idx,row[c])\n",
    "                    week_cases[c][state_id][w_idx]+=int(row[c])\n",
    "                    week_cases[c][0][w_idx]+=int(row[c])\n",
    "    \n",
    "    \n",
    "    ##ADD NAN VALUES TO THE LAST 2 WEEK\n",
    "    for s in range(len(state_names)):\n",
    "        for c in cols_death:\n",
    "            week_cases[c][s]/=3\n",
    "            week_cases[c][s][-1]=np.nan\n",
    "            week_cases[c][s][-2]=np.nan\n",
    "    \n",
    "    \n",
    "    unit_test(week_cases,cols_death,epiweek_date,state_index,\"unit_test/excess-death-weekly.csv\")\n",
    "    return week_cases,cols_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jhu_cases(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"time_series_covid19_confirmed_US.csv\")\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates_list=list(data.columns)\n",
    "    dates_list=dates_list[11:]\n",
    "    #print(state_names)\n",
    "    #print(dates_list)\n",
    "    #not_added_rows=['Diamond Princess','Grand Princess','Northern Mariana Islands','Guam','Hawaii',\n",
    "                   # 'Puerto Rico','Virgin Islands','American Samoa']\n",
    "    not_added_rows=[]\n",
    "    week_cases={}\n",
    "    cols=['positiveIncr_cumulative','positiveIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    \n",
    "    data2 = data.groupby(['Province_State']).sum()\n",
    "    \n",
    "    for ix, row in data2.iterrows():\n",
    "        name=ix\n",
    "        if name in state_names:\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            for date in dates_list:\n",
    "                w_idx=get_current_week(epiweek_date,date,dates_list[-1])\n",
    "                #if date==dates_list[-1]:\n",
    "                 #   print(w_idx)\n",
    "                if w_idx!=-1:\n",
    "                    #print(name,date,row[date])\n",
    "                    if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                        week_cases[cols[0]][state_id][w_idx] = 0\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]): \n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][state_id][w_idx]+=int(row[date])\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "        elif name not in not_added_rows: #if not state_names still adding them for national\n",
    "            #print('state name not added:'+name)\n",
    "            for date in dates_list:\n",
    "                w_idx=get_current_week(epiweek_date,date,dates_list[-1])\n",
    "                if w_idx!=-1:\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]): \n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "    \n",
    "    \n",
    "    #count incidence for the national+states\n",
    "    for state_id in range(len(state_names)):\n",
    "        if state_id == 51: \n",
    "            continue\n",
    "        index = 0\n",
    "        while np.isnan(week_cases[cols[0]][state_id][index]):\n",
    "            index += 1\n",
    "        week_cases[cols[1]][state_id][index]=int(week_cases[cols[0]][state_id][index])\n",
    "        for w_idx in range(index + 1,len(epiweek_date)):\n",
    "            if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                continue\n",
    "            week_cases[cols[1]][state_id][w_idx]=int(week_cases[cols[0]][state_id][w_idx])-int(week_cases[cols[0]][state_id][w_idx-1])\n",
    "             \n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/jhu-cases.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jhu_death(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week=None,end_week=None):\n",
    "    data=pd.read_csv(inputdir+\"time_series_covid19_deaths_US.csv\")\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates_list=list(data.columns)\n",
    "    dates_list=dates_list[12:]\n",
    "    #print(state_names)\n",
    "    #print(dates_list)\n",
    "    #not_added_rows=['Diamond Princess','Grand Princess','Northern Mariana Islands','Guam','Hawaii',\n",
    "                   # 'Puerto Rico','Virgin Islands','American Samoa']\n",
    "    not_added_rows=[]\n",
    "    week_cases={}\n",
    "    cols=['death_jhu_cumulative','death_jhu_incidence']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    \n",
    "    data2 = data.groupby(['Province_State']).sum()\n",
    "    for ix, row in data2.iterrows():\n",
    "        name=ix\n",
    "        if name in state_names:\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            for date in dates_list:\n",
    "                w_idx=get_current_week(epiweek_date,date,dates_list[-1])\n",
    "                #if date==dates_list[-1]:\n",
    "                 #   print(w_idx)\n",
    "                if w_idx!=-1:\n",
    "                    #print(name,date,row[date])\n",
    "                    if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                        week_cases[cols[0]][state_id][w_idx] = 0\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]): \n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][state_id][w_idx]+=int(row[date])\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "        elif name not in not_added_rows: #if not state_names still adding them for national\n",
    "            #print('state name not added:'+name)\n",
    "            for date in dates_list:\n",
    "                w_idx=get_current_week(epiweek_date,date,dates_list[-1])\n",
    "                if w_idx!=-1:\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]): \n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "    \n",
    "    \n",
    "    #count incidence for the national+states\n",
    "    for state_id in range(len(state_names)):\n",
    "        if state_id == 51 or state_id == 52: \n",
    "            continue \n",
    "        index = 0\n",
    "        while np.isnan(week_cases[cols[0]][state_id][index]):\n",
    "            index += 1\n",
    "        week_cases[cols[1]][state_id][index]=int(week_cases[cols[0]][state_id][index])\n",
    "        for w_idx in range(index + 1,len(epiweek_date)):\n",
    "            if np.isnan(week_cases[cols[0]][state_id][w_idx]) == False and np.isnan(week_cases[cols[0]][state_id][w_idx-1]) == False: \n",
    "                week_cases[cols[1]][state_id][w_idx]=int(week_cases[cols[0]][state_id][w_idx])-int(week_cases[cols[0]][state_id][w_idx-1])\n",
    "             \n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/jhu-death.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_level_cases(inputdir,week_state,state_index,epiweek_date,cols, is_covidnet=False):\n",
    "    otherdatasir=inputdir+\"other_data/\"\n",
    "    week_hhs={}\n",
    "    num_region=11\n",
    "    state_names=list(state_index.keys())\n",
    "    for c in cols:\n",
    "        week_hhs[c]=np.zeros((num_region,len(epiweek_date)))\n",
    "    \n",
    "    file = open(otherdatadir+\"hhs_regions_abbv.txt\", 'r') \n",
    "    Lines = file.readlines() \n",
    "    state_hhs_map={}\n",
    "    state_pop=np.zeros(len(state_names))\n",
    "    population=open(otherdatadir+\"state_population.csv\",'r')\n",
    "    total=0  \n",
    "    popu_region=np.zeros(num_region)   \n",
    "    \n",
    "    ######## Getting population. Need this for weighted count ###########################        \n",
    "    \n",
    "    Lines_pop=population.readlines()\n",
    "    for line in Lines_pop:\n",
    "        state,popu,abbv=line.strip().split(',')\n",
    "        if state=='ttl':\n",
    "            state_pop[0]=float(popu)\n",
    "        else:\n",
    "            if state_index.get(abbv,-1)!=-1:\n",
    "                state_id=state_index[abbv]\n",
    "                state_pop[state_id]=float(popu)\n",
    "            else:\n",
    "                print('population state not found '+state)\n",
    "    \n",
    "    #### mapping each state to a hhs region ###\n",
    "    state_hhs_map[0]=0 # setting national value\n",
    "    popu_region[0]=1\n",
    "    for line in Lines:\n",
    "        regions=line.strip().split(',')\n",
    "        reg_id=int(regions[0])\n",
    "        for j in range(1,len(regions)):\n",
    "            if state_index.get(regions[j],-1)!=-1:\n",
    "                state_id=state_index[regions[j]]\n",
    "                state_hhs_map[state_id]=reg_id\n",
    "                popu_region[reg_id]+=state_pop[state_id]\n",
    "            else:\n",
    "                print('state not found '+regions[j])\n",
    "    \n",
    "    for key in state_hhs_map.keys():\n",
    "        hhs_id=int(state_hhs_map[int(key)])\n",
    "        for j in range(len(epiweek_date)):\n",
    "            for c in cols:\n",
    "                if is_covidnet and int(key)>0:\n",
    "                    if math.isnan(week_state[c][int(key)][j])==False:\n",
    "                        #print(int(key),week_state[c][int(key)][j])\n",
    "                        week_hhs[c][hhs_id][j]+=(week_state[c][int(key)][j]*state_pop[int(key)])/100000\n",
    "                else:    \n",
    "                    week_hhs[c][hhs_id][j]+=week_state[c][int(key)][j]\n",
    "    if is_covidnet:\n",
    "        for r in range(1,num_region):\n",
    "            for c in cols:\n",
    "                week_hhs[c][r][:]/=popu_region[r]\n",
    "            \n",
    "    return week_hhs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_region(mobility,kinsadir,iqvia,covidnet,hosp,cols_m,cols_k,cols_q,cols_net,cols_hosp,epiweek,\n",
    "               epiweek_date,outputdir,otherdatadir,outfilename,state_index,kinsa_start,kinsa_end):\n",
    "    r='Region '\n",
    "    region_names=['X']\n",
    "    for i in range(1,11):\n",
    "        region_names.append(r+str(i))\n",
    "    region_index={region_names[i]:i for i in range(len(region_names))}\n",
    "    cols_common=['date','epiweek','region']\n",
    "    all_cols=cols_common+cols_m+cols_k+cols_q+cols_net+cols_hosp\n",
    "    \n",
    "    mobility_hhs=region_level_cases(otherdatadir,mobility,state_index,epiweek_date,cols_m)\n",
    "    kinsa_hhs,cols_kinsa=read_kinsa(kinsadir,epiweek_date,region_index,kinsa_start,kinsa_end,isregion=True)\n",
    "    iqvia_hhs=region_level_cases(otherdatadir,iqvia,state_index,epiweek_date,cols_q)\n",
    "    covidnet_hhs=region_level_cases(otherdatadir,covidnet,state_index,epiweek_date,cols_net,is_covidnet=True)\n",
    "    hosp_hhs=region_level_cases(otherdatadir,hosp,state_index,epiweek_date,cols_hosp)\n",
    "    \n",
    "    #print(covidnet_hhs[cols_net[0]][1:])\n",
    "    \n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility_hhs[c][reg][:]\n",
    "        for c in cols_kinsa:\n",
    "            temp_data[c]=kinsa_hhs[c][reg][:]\n",
    "        for c in cols_q:\n",
    "            temp_data[c]=iqvia_hhs[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet_hhs[c][reg][:]\n",
    "        for c in cols_hosp:\n",
    "            temp_data[c]=hosp_hhs[c][reg][:]\n",
    "        \n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produces the output file from all the columns generated\n",
    "def merge_data_state(mobility,apple,vacc,vac_delphi,cdc_hosp,flu_hosp,covidnet,excess,jhu,survey,jhu_case,hosp_new_res,\n",
    "                     cols_m,cols_a,cols_vacc,cols_vac_delphi,cols_cdc,cols_flu,cols_net,cols_excess,cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res,\n",
    "                     state_fips,epiweek,epiweek_date,region_names,outputdir,outfilename):\n",
    "    \n",
    "    cols_common=['date','epiweek','region','fips']\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_d+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_k+cols_q+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_flu+cols_d+cols_vacc+cols_vac_delphi+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_jhu_case+cols_hosp_new_res\n",
    "    all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_flu+cols_vacc+cols_vac_delphi+cols_net+cols_excess+cols_jhu+cols_survey+cols_jhu_case+cols_hosp_new_res\n",
    "    print(all_cols)\n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        temp_data['fips']=[state_fips[region_names[reg]]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility[c][reg][:]\n",
    "        for c in cols_a:\n",
    "            temp_data[c]=apple[c][reg][:]\n",
    "        for c in cols_cdc:\n",
    "            temp_data[c]=cdc_hosp[c][reg][:]\n",
    "        for c in cols_flu:\n",
    "            temp_data[c]=flu_hosp[c][reg][:]\n",
    "        #for c in cols_d:\n",
    "        #    temp_data[c]=dex[c][reg][:]\n",
    "        for c in cols_vacc:\n",
    "            temp_data[c]=vacc[c][reg][:]\n",
    "        for c in cols_vacc_delphi:\n",
    "            temp_data[c]=vacc_delphi[c][reg][:]\n",
    "        #for c in cols_k:\n",
    "         #   temp_data[c]=kinsa[c][reg][:]\n",
    "        #for c in cols_q:\n",
    "         #   temp_data[c]=iqvia[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet[c][reg][:]\n",
    "        #for c in cols_hosp:\n",
    "        #    temp_data[c]=hosp[c][reg][:]\n",
    "        for c in cols_excess:\n",
    "            temp_data[c]=excess[c][reg][:]\n",
    "        for c in cols_jhu:\n",
    "            temp_data[c]=jhu[c][reg][:]\n",
    "        for c in cols_survey:\n",
    "            temp_data[c]=survey[c][reg][:]\n",
    "        #for c in cols_v:\n",
    "        #    temp_data[c]=em_visit[c][reg][:]\n",
    "        for c in cols_jhu_case:\n",
    "            temp_data[c]=jhu_case[c][reg][:]\n",
    "        for c in cols_hosp_new_res:\n",
    "            temp_data[c]=hosp_new_res[c][reg][:]\n",
    "        \n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    \n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_state_test(mobility,cdc_hosp,flu_hosp,\n",
    "                     cols_m,cols_cdc,cols_flu,\n",
    "                     state_fips,epiweek,epiweek_date,region_names,outputdir,outfilename):\n",
    "    \n",
    "    cols_common=['date','epiweek','region','fips']\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_d+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_k+cols_q+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    all_cols=cols_common+cols_m+cols_cdc+cols_flu\n",
    "    \n",
    "    print(all_cols)\n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        temp_data['fips']=[state_fips[region_names[reg]]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility[c][reg][:]\n",
    "        \"\"\"\n",
    "        for c in cols_a:\n",
    "            temp_data[c]=apple[c][reg][:]\"\"\"\n",
    "        for c in cols_cdc:\n",
    "            if reg == 0: \n",
    "                cdc_hosp[c][reg][0:14] = np.nan\n",
    "                print(cdc_hosp[c][reg][0:14])\n",
    "            temp_data[c]=cdc_hosp[c][reg][:]\n",
    "        for c in cols_flu:\n",
    "            if reg == 0: \n",
    "                flu_hosp[c][reg][0:41] = np.nan\n",
    "                print(flu_hosp[c][reg][0:41])\n",
    "            temp_data[c]=flu_hosp[c][reg][:]\n",
    "        \"\"\"\n",
    "        for c in cols_d:\n",
    "            temp_data[c]=dex[c][reg][:]\n",
    "        for c in cols_vacc:\n",
    "            temp_data[c]=vacc[c][reg][:]\n",
    "        for c in cols_vacc_delphi:\n",
    "            temp_data[c]=vacc_delphi[c][reg][:]\n",
    "        for c in cols_k:\n",
    "            temp_data[c]=kinsa[c][reg][:]\n",
    "        #for c in cols_q:\n",
    "         #   temp_data[c]=iqvia[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet[c][reg][:]\n",
    "        for c in cols_hosp:\n",
    "            temp_data[c]=hosp[c][reg][:]\n",
    "        for c in cols_excess:\n",
    "            temp_data[c]=excess[c][reg][:]\n",
    "        for c in cols_jhu:\n",
    "            temp_data[c]=jhu[c][reg][:]\n",
    "        for c in cols_survey:\n",
    "            temp_data[c]=survey[c][reg][:]\n",
    "        #for c in cols_v:\n",
    "        #    temp_data[c]=em_visit[c][reg][:]\n",
    "        for c in cols_jhu_case:\n",
    "            temp_data[c]=jhu_case[c][reg][:]\n",
    "        for c in cols_hosp_new_res:\n",
    "            temp_data[c]=hosp_new_res[c][reg][:]\"\"\"\n",
    "        \n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    \n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202244\n",
      "['2020-01-04', '2020-01-11', '2020-01-18', '2020-01-25', '2020-02-01', '2020-02-08', '2020-02-15', '2020-02-22', '2020-02-29', '2020-03-07', '2020-03-14', '2020-03-21', '2020-03-28', '2020-04-04', '2020-04-11', '2020-04-18', '2020-04-25', '2020-05-02', '2020-05-09', '2020-05-16', '2020-05-23', '2020-05-30', '2020-06-06', '2020-06-13', '2020-06-20', '2020-06-27', '2020-07-04', '2020-07-11', '2020-07-18', '2020-07-25', '2020-08-01', '2020-08-08', '2020-08-15', '2020-08-22', '2020-08-29', '2020-09-05', '2020-09-12', '2020-09-19', '2020-09-26', '2020-10-03', '2020-10-10', '2020-10-17', '2020-10-24', '2020-10-31', '2020-11-07', '2020-11-14', '2020-11-21', '2020-11-28', '2020-12-05', '2020-12-12', '2020-12-19', '2020-12-26', '2021-01-02', '2021-01-09', '2021-01-16', '2021-01-23', '2021-01-30', '2021-02-06', '2021-02-13', '2021-02-20', '2021-02-27', '2021-03-06', '2021-03-13', '2021-03-20', '2021-03-27', '2021-04-03', '2021-04-10', '2021-04-17', '2021-04-24', '2021-05-01', '2021-05-08', '2021-05-15', '2021-05-22', '2021-05-29', '2021-06-05', '2021-06-12', '2021-06-19', '2021-06-26', '2021-07-03', '2021-07-10', '2021-07-17', '2021-07-24', '2021-07-31', '2021-08-07', '2021-08-14', '2021-08-21', '2021-08-28', '2021-09-04', '2021-09-11', '2021-09-18', '2021-09-25', '2021-10-02', '2021-10-09', '2021-10-16', '2021-10-23', '2021-10-30', '2021-11-06', '2021-11-13', '2021-11-20', '2021-11-27', '2021-12-04', '2021-12-11', '2021-12-18', '2021-12-25', '2022-01-01', '2022-01-08', '2022-01-15', '2022-01-22', '2022-01-29', '2022-02-05', '2022-02-12', '2022-02-19', '2022-02-26', '2022-03-05', '2022-03-12', '2022-03-19', '2022-03-26', '2022-04-02', '2022-04-09', '2022-04-16', '2022-04-23', '2022-04-30', '2022-05-07', '2022-05-14', '2022-05-21', '2022-05-28', '2022-06-04', '2022-06-11', '2022-06-18', '2022-06-25', '2022-07-02', '2022-07-09', '2022-07-16', '2022-07-23', '2022-07-30', '2022-08-06', '2022-08-13', '2022-08-20', '2022-08-27', '2022-09-03', '2022-09-10', '2022-09-17', '2022-09-24', '2022-10-01', '2022-10-08', '2022-10-15', '2022-10-22', '2022-10-29', '2022-11-05']\n",
      "['202001', '202002', '202003', '202004', '202005', '202006', '202007', '202008', '202009', '202010', '202011', '202012', '202013', '202014', '202015', '202016', '202017', '202018', '202019', '202020', '202021', '202022', '202023', '202024', '202025', '202026', '202027', '202028', '202029', '202030', '202031', '202032', '202033', '202034', '202035', '202036', '202037', '202038', '202039', '202040', '202041', '202042', '202043', '202044', '202045', '202046', '202047', '202048', '202049', '202050', '202051', '202052', '202053', '202101', '202102', '202103', '202104', '202105', '202106', '202107', '202108', '202109', '202110', '202111', '202112', '202113', '202114', '202115', '202116', '202117', '202118', '202119', '202120', '202121', '202122', '202123', '202124', '202125', '202126', '202127', '202128', '202129', '202130', '202131', '202132', '202133', '202134', '202135', '202136', '202137', '202138', '202139', '202140', '202141', '202142', '202143', '202144', '202145', '202146', '202147', '202148', '202149', '202150', '202151', '202152', '202201', '202202', '202203', '202204', '202205', '202206', '202207', '202208', '202209', '202210', '202211', '202212', '202213', '202214', '202215', '202216', '202217', '202218', '202219', '202220', '202221', '202222', '202223', '202224', '202225', '202226', '202227', '202228', '202229', '202230', '202231', '202232', '202233', '202234', '202235', '202236', '202237', '202238', '202239', '202240', '202241', '202242', '202243', '202244']\n",
      "google mobility\n",
      "Index(['country_region_code', 'country_region', 'sub_region_1', 'metro_area',\n",
      "       'iso_3166_2_code', 'census_fips_code', 'place_id', 'date',\n",
      "       'retail_and_recreation_percent_change_from_baseline',\n",
      "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
      "       'parks_percent_change_from_baseline',\n",
      "       'transit_stations_percent_change_from_baseline',\n",
      "       'workplaces_percent_change_from_baseline',\n",
      "       'residential_percent_change_from_baseline'],\n",
      "      dtype='object')\n",
      "['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_34856/1325990347.py:38: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  epiweek_data = data.groupby(['epiweek', 'sub_region_1'], as_index=False).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': 'X', 'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'}\n",
      "{'X': 0, 'AL': 1, 'AK': 2, 'AZ': 3, 'AR': 4, 'CA': 5, 'CO': 6, 'CT': 7, 'DE': 8, 'DC': 9, 'FL': 10, 'GA': 11, 'ID': 12, 'IL': 13, 'IN': 14, 'IA': 15, 'KS': 16, 'KY': 17, 'LA': 18, 'ME': 19, 'MD': 20, 'MA': 21, 'MI': 22, 'MN': 23, 'MS': 24, 'MO': 25, 'MT': 26, 'NE': 27, 'NV': 28, 'NH': 29, 'NJ': 30, 'NM': 31, 'NY': 32, 'NC': 33, 'ND': 34, 'OH': 35, 'OK': 36, 'OR': 37, 'PA': 38, 'RI': 39, 'SC': 40, 'SD': 41, 'TN': 42, 'TX': 43, 'UT': 44, 'VT': 45, 'VA': 46, 'WA': 47, 'WV': 48, 'WI': 49, 'WY': 50}\n",
      "['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 82>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m start_week_m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     81\u001b[0m end_week_m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(week_num) \u001b[38;5;66;03m#2021, m=epiweek since data generally have value -4 days lag for current week\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m mobility_state,cols_m,state_index,dic_names_to_abbv\u001b[38;5;241m=\u001b[39m\u001b[43mread_mobility\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepiweek_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_week_m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m dic_names_to_abbv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#print(dic_names_to_abbv)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mread_mobility\u001b[0;34m(inputdir, epiweek_date, end_week, MISSING_TOKEN)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misnull(row[c]) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m week_cases_check[c][state_id][week_id]: \n\u001b[0;32m---> 68\u001b[0m         value \u001b[38;5;241m=\u001b[39m epiweek_data[\u001b[43mepiweek_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepiweek\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconvert_to_epiweek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m] \n\u001b[1;32m     69\u001b[0m         value \u001b[38;5;241m=\u001b[39m value[value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_region_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_region_1\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m value[c]: \n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/arraylike.py:43\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/series.py:6246\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6243\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6246\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/_libs/ops.pyx:95\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/epiweeks/__init__.py:55\u001b[0m, in \u001b[0;36mWeek.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_year, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_week, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system))\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m):\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "### WHAT DATA ##\n",
    "1.To get the hospitalization data we need the following datasets:\n",
    "  a. mobility (filename:Global_Mobility_Report.csv)\n",
    "  b.kinsa (filename:kinsa_observedili_state_avg.csv)\n",
    "  c.iqvia (filename:iqvia_Processed.csv)\n",
    "  d.covidnet (filename:COVID-NET_Processed.csv)\n",
    "  e.covid-tracking (national, state)\n",
    "      datasets are collected from site: https://covidtracking.com/api\n",
    "        i. We collected US historical data (filename save: us-daily-hospitalizations.csv)\n",
    "        ii. State historical data (filename save: states-daily-hospitalizations.csv)\n",
    "  f. apple (applemobilitytrends.csv)\n",
    "  g. dex (state-dex.csv)\n",
    "  h. emergency visit (emeregency-vists.csv)\n",
    "  i. jhu deaths: time_series_covid19_deaths_US.csv\n",
    "  j. excess deaths: Excess_Deaths_COVID_19.csv\n",
    "  \n",
    "## WHERE DATA SHOULD BE KEPT AND WHAT NAME ###\n",
    "2. change all data directory as where it is kept\n",
    "3. DONT CHANGE FILENAME (keep in the same name as written above)\n",
    "4. There are some additional data like population, state-fips code etc required to process this file, \n",
    "  keep all of them in same directory as data_path/other_data\n",
    "\n",
    "### INPUT PARAMETERS TO PASS FOR PROCESSING EACH FILE ##\n",
    "5. At the beginning of every data to be processes also pass a input parameter as start_week/end_week or \n",
    "   both based on dataset. This is for consistency as not all dataset contain all epiweeks value \n",
    "\n",
    "6. change get_epiweek_list(start_week,end_week) also. These are the weeks to show in the final output file\n",
    "\n",
    "7. for hospitalization only change last_date instead of start/end_week. \n",
    "   last_date means the date which upto which data is available\n",
    "\n",
    "##OUTPUT FILE NAME AND DIRECTORY##\n",
    "8. merged_data(..) is merging all the columns. Change the filename and output directory in the fields \n",
    "   before calling the method\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import copy\n",
    "if date.today().weekday() != 6:\n",
    "    week_num = (date.today()-timedelta(2)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\"  + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() +timedelta((5-date.today().weekday()) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_date = (date.today() - timedelta(2)).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() + timedelta((5-date.today().weekday()) % 7 )).strftime('%Y%m%d')\n",
    "    week_end_string = (date.today() - timedelta(2)).strftime('%Y%m%d')\n",
    "\n",
    "else:\n",
    "    week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() -timedelta((date.today().weekday()-5) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() - timedelta((date.today().weekday()-5) % 7 )).strftime('%Y%m%d')\n",
    "### INPUT FILE DIRECTORY #####\n",
    "# data_path=\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "data_path=\"./\"\n",
    "# kinsa_path= \"/Users/anikat/Downloads/kinsahealth/\"\n",
    "kinsa_path = \"./\"\n",
    "### INPUT: EPIWEEK START, END WEEK ####\n",
    "#Both the method args will be same. This is to keep last date in the ouput file to same as epiweek\n",
    "epiweek1,epiweek_date1=get_epiweek_list('202001','202053',2020)\n",
    "epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "epiweek3,epiweek_date3=get_epiweek_list('202201',year_week_num,2022)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epiweek=epiweek1+epiweek2+epiweek3\n",
    "epiweek_date=epiweek_date1+epiweek_date2+epiweek_date3\n",
    "week_save=copy.deepcopy(epiweek_date)\n",
    "### ****NOTE: for new year 2021 add another epiweek list and append with previous**** #######\n",
    "\n",
    "print(epiweek_date)\n",
    "print(epiweek)\n",
    "# PROCESSING MOBILITY ####\n",
    "# INPUT: END_WEEK: the last epiweek this csv file contains  ####\n",
    "print('google mobility')\n",
    "start_week_m=1\n",
    "end_week_m=int(week_num) #2021, m=epiweek since data generally have value -4 days lag for current week\n",
    "mobility_state,cols_m,state_index,dic_names_to_abbv=read_mobility(data_path,epiweek_date,end_week_m)\n",
    "dic_names_to_abbv['United States']='X'\n",
    "#print(dic_names_to_abbv)\n",
    "print(len(state_index.keys()))\n",
    "#print(state_index)\n",
    "\n",
    "\"\"\"\n",
    "print('JHU-cases')\n",
    "jhu_cases,cols_jhu_case=read_jhu_cases(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "print('hosp-neg-total result')\n",
    "hosp_new_res,cols_hosp_new_res=hosp_negative_total_data_test(data_path,epiweek_date,state_index)\n",
    "\n",
    "print('Vaccine dose')\n",
    "last_date=week_end_date\n",
    "vacc,cols_vacc=read_vaccine_doses(data_path,epiweek_date,state_index,dic_names_to_abbv,last_date)\n",
    "\n",
    "print('delphi vaccine survey')\n",
    "start_week=20210101\n",
    "end_week=int(week_end_string)  #yyyymmdd\n",
    "print(end_week)\n",
    "vacc_delphi,cols_vacc_delphi=read_delphi_vaccine_test_two(state_index,epiweek_date,start_week,end_week)\n",
    "\n",
    "### PROCESSING FB-GOOGLE ####\n",
    "### INPUT: start_week, end_week; start_week does not matter as both survey starts from 20200401, \n",
    "###  but always update end_week###\n",
    "\n",
    "print('FB-GOOGLE')\n",
    "start_week=20200307\n",
    "end_week=int(week_end_string) #yyyymmdd\n",
    "survey,cols_survey=read_delphi_fb_google_survey_test(state_index,epiweek_date,start_week,end_week)\n",
    "\n",
    "\n",
    "print('CDC hospitalization')\n",
    "end_week=int(week_num) #2021\n",
    "cdc_hosp,cols_cdc,flu_hosp,cols_flu=read_cdc_hosp(data_path,epiweek_date,state_index,end_week)\n",
    "print(flu_hosp)\n",
    "\n",
    "### PROCESSING APPLE MOBILITY per date for Berkely guys####\n",
    "#read_apple_mobility_per_date(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_m,end_week_m)\n",
    "\n",
    "### PROCESSING APPLE MOBILITY ####\n",
    "### INPUT: START_WEEK:1,END_WEEK: the last epiweek this csv file contains  ####\n",
    "\n",
    "print('apple mobility')\n",
    "end_week_m=int(week_num)\n",
    "apple_mobility,cols_a=read_apple_mobility(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_m,end_week_m)\n",
    "\n",
    "### PROCESSING COVIDNET ####\n",
    "### INPUT: START, END_WEEK: have 1 weeks lag data, same as IQVIA; STEP: TILL which index covidnet starts###\n",
    "print('covidnet')\n",
    "step=9 #if epiweek starts from 10 then step=0, if epiweek starts from 1 step=9 (10-epiweek_start)\n",
    "start_week_n=10\n",
    "end_week_n=int(week_num) #0 is just for week 53, change to 1, since next week change it to epiweek-1 if data pulled after Sat\n",
    "data_covidnet,cols_net= read_covidnet_data(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_n,end_week_n,step)\n",
    "\n",
    "\n",
    "### PROCESSING excess death ####\n",
    "### INPUT: start_week, end_week, this_month: number of current month###\n",
    "print('excess death')\n",
    "start_week_e=1\n",
    "end_week_e=int(week_num) #epiweek\n",
    "this_month=1\n",
    "last_date=week_end_date #yyyy-mm-dd change to original epiweek date if pulled after Sat, else keep it as today's date\n",
    "excess_death,cols_excess=read_excess_death(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_e,end_week_e,this_month,last_date)\n",
    "\n",
    "\n",
    "### PROCESSING jhu death ####\n",
    "print('JHU')\n",
    "jhu_death,cols_jhu=read_jhu_death(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\"\"\"\n",
    "\n",
    "##DO NOT CHANGE THESE 3, they stopped update\n",
    "\n",
    "### PROCESSING Covid exposure indices on income, race,etc. ####\n",
    "### INPUT: END_WEEK: the last epiweek this csv file contains  ####\n",
    "\"\"\"\n",
    "print('covid exposure index:dex')\n",
    "end_week_dex=16\n",
    "dex,cols_d=read_dex(data_path,epiweek_date,state_index,start_week_m,end_week=end_week_dex)\n",
    "\n",
    "### PROCESSING KINSA ####\n",
    "print('kinsa')\n",
    "start_week_k=1\n",
    "end_week_k=40 #if this data is 1 week lag, then epiweek-1, else epiweek\n",
    "kinsa_state,cols_k=read_kinsa(kinsa_path,epiweek_date,state_index,start_week_k,end_week_k)\n",
    "\n",
    "## PROCESSING HOSPITALIZATION ####\n",
    "print('hospitalization')\n",
    "last_date='20210307' #yyymmdd:change to original epiweek date if pulled after Sat, else keep it as yesterday date\n",
    "#states needs hosp current  \n",
    "state_error=['CA','DC','TX','IL','LA','PA','MI','MO','NC','NV','DE'] #'NJ', 'WA', 'NE'\n",
    "data_hosp,cols_hosp=read_hospitalization(data_path,data_path,epiweek_date,week_save,state_index,\n",
    "                                      last_date,state_error)\"\"\"\n",
    "\n",
    "# ## PROCESSING IQVIA ####\n",
    "# ## INPUT: START, END_WEEK: have 2 weeks lag data###\n",
    "# print('iqvia')\n",
    "# change start, end week based on data and epiweek_date. current data has value since epiweek 10-17\n",
    "# start_week_q=1\n",
    "# end_week_q=33 #if this data is 1 week lag, then epiweek-1, else epiweek\n",
    "# iqvia_state,cols_q=read_iqvia(data_path,epiweek_date,state_index,start_week_q,end_week_q)\"\"\"\n",
    "\n",
    "## PROCESSING Emergency-visits ####\n",
    "\n",
    "\"\"\"\n",
    "print('emergency-visits')\n",
    "start_week_v=202001\n",
    "end_week_v=202105\n",
    "em_visit,cols_v=read_emergency(data_path,epiweek_date,state_index,start_week_v,end_week_v)\"\"\"\n",
    "\n",
    "\n",
    "state_names=list(state_index.keys())\n",
    "state_fips=read_fips_code(state_names,data_path)\n",
    "\n",
    "\n",
    "# #'''\n",
    "# #cdc_hosp={}\n",
    "# #cols_cdc=\"\"\n",
    "print('merging all state..')\n",
    "#Change outputdir and outfilename with the path and name of out file\n",
    "outputdir=data_path #\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "outfile=\"covid-hospitalization-all-state-merged_vEW\" + year_week_num+\".csv\"\n",
    "#merge_data_state_test(mobility_state,cdc_hosp, flu_hosp, cols_m, cols_cdc, cols_flu,state_fips,epiweek,week_save,state_names,outputdir,outfile)\n",
    "\n",
    "merge_data_state(mobility_state,apple_mobility,vacc,vacc_delphi,cdc_hosp,flu_hosp,data_covidnet,excess_death,\n",
    "                 jhu_death,survey,jhu_cases,hosp_new_res,\n",
    "                 cols_m,cols_a,cols_vacc,cols_vacc_delphi,cols_cdc,cols_flu,cols_net,cols_excess,\n",
    "                 cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res,\n",
    "                 state_fips,epiweek,week_save,state_names,outputdir,outfile)\n",
    "\"\"\"\n",
    "#merge_data_state(mobility_state,apple_mobility,vacc,vacc_delphi,cdc_hosp,flu_hosp,dex,kinsa_state,data_covidnet,data_hosp,excess_death,\n",
    "                 jhu_death,survey,jhu_cases,hosp_new_res,\n",
    "                 cols_m,cols_a,cols_vacc,cols_vacc_delphi,cols_cdc,cols_flu,cols_d,cols_k,cols_net,cols_hosp,cols_excess,\n",
    "                 cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res,\n",
    "                 state_fips,epiweek,week_save,state_names,outputdir,outfile)\"\"\"\n",
    "# #'''\n",
    "\n",
    "# kinsa_state,data_hosp, em_visit,cols_k, cols_hosp,cols_v,\n",
    "\n",
    "'''\n",
    "print('merging all region..')\n",
    "outputdir=\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "outfile=\"covid-hospitalization-all-region-merged.csv\"\n",
    "merge_data_region(mobility_state,kinsa_path,iqvia_state,data_covidnet,data_hosp,cols_m,cols_k,cols_q,cols_net,cols_hosp,epiweek,\n",
    "               week_save,outputdir,other_path,outfile,state_index,start_week_k,end_week_k)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan]\n",
      "6273\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epiweek</th>\n",
       "      <th>region</th>\n",
       "      <th>cdc_flu_hosp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202001</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202002</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202003</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202004</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202005</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202006</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202007</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202008</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202009</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202010</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202011</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202012</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>202013</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202014</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202015</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202016</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202017</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202018</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202019</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202020</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>202021</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202022</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202023</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202024</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202025</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202026</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>202027</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>202028</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>202029</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202030</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202031</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202032</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202033</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>202034</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>202035</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202036</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>202037</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>202038</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>202039</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202040</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202041</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202042</td>\n",
       "      <td>X</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202043</td>\n",
       "      <td>X</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202044</td>\n",
       "      <td>X</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202045</td>\n",
       "      <td>X</td>\n",
       "      <td>477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>202046</td>\n",
       "      <td>X</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>202047</td>\n",
       "      <td>X</td>\n",
       "      <td>548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>202048</td>\n",
       "      <td>X</td>\n",
       "      <td>590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>202049</td>\n",
       "      <td>X</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>202050</td>\n",
       "      <td>X</td>\n",
       "      <td>605.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epiweek region  cdc_flu_hosp\n",
       "0   202001      X           NaN\n",
       "1   202002      X           NaN\n",
       "2   202003      X           NaN\n",
       "3   202004      X           NaN\n",
       "4   202005      X           NaN\n",
       "5   202006      X           NaN\n",
       "6   202007      X           NaN\n",
       "7   202008      X           NaN\n",
       "8   202009      X           NaN\n",
       "9   202010      X           NaN\n",
       "10  202011      X           NaN\n",
       "11  202012      X           NaN\n",
       "12  202013      X           NaN\n",
       "13  202014      X           NaN\n",
       "14  202015      X           NaN\n",
       "15  202016      X           NaN\n",
       "16  202017      X           NaN\n",
       "17  202018      X           NaN\n",
       "18  202019      X           NaN\n",
       "19  202020      X           NaN\n",
       "20  202021      X           NaN\n",
       "21  202022      X           NaN\n",
       "22  202023      X           NaN\n",
       "23  202024      X           NaN\n",
       "24  202025      X           NaN\n",
       "25  202026      X           NaN\n",
       "26  202027      X           NaN\n",
       "27  202028      X           NaN\n",
       "28  202029      X           NaN\n",
       "29  202030      X           NaN\n",
       "30  202031      X           NaN\n",
       "31  202032      X           NaN\n",
       "32  202033      X           NaN\n",
       "33  202034      X           NaN\n",
       "34  202035      X           NaN\n",
       "35  202036      X           NaN\n",
       "36  202037      X           NaN\n",
       "37  202038      X           NaN\n",
       "38  202039      X           NaN\n",
       "39  202040      X           NaN\n",
       "40  202041      X           NaN\n",
       "41  202042      X          12.0\n",
       "42  202043      X         218.0\n",
       "43  202044      X         428.0\n",
       "44  202045      X         477.0\n",
       "45  202046      X         585.0\n",
       "46  202047      X         548.0\n",
       "47  202048      X         590.0\n",
       "48  202049      X         577.0\n",
       "49  202050      X         605.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_common=['epiweek','region']\n",
    "all_cols=cols_common+cols_flu\n",
    "final_data = pd.DataFrame(columns = all_cols)\n",
    "for reg in range(len(state_names)):\n",
    "    temp_data = pd.DataFrame(columns = all_cols)\n",
    "    temp_data['epiweek']=epiweek\n",
    "    temp_data['region']=[state_names[reg]]*len(epiweek_date)\n",
    "    for c in cols_flu:\n",
    "        if reg == 0: \n",
    "            flu_hosp[c][reg][0:41] = np.nan\n",
    "            print(flu_hosp[c][reg][0:41])\n",
    "            temp_data[c]=flu_hosp[c][reg][:]\n",
    "    temp_data=temp_data[all_cols]\n",
    "    final_data=final_data.append(temp_data,ignore_index=True)\n",
    "print(len(final_data))\n",
    "final_data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epiweek,epiweek_date=get_epiweek_list('202001','202053',2020)\n",
    "epiweek,epiweek_date=get_epiweek_list('202101','202201',2022)\n",
    "print(epiweek_date)\n",
    "print(epiweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##OPTIONAL: NO NEED TO RUN THIS FOR MERGING\n",
    "def get_jhu_deaths():\n",
    "    outputdir=\"/Users/anikat/Downloads/covid-hospitalization-data/jhu_deaths/\"\n",
    "    row_to_remove=['American Samoa','Grand Princess', 'Diamond Princess', 'Northern Mariana Islands', \n",
    "                   'Virgin Islands','Puerto Rico','Guam','Hawaii']\n",
    "    fips_path=\"/Users/anikat/Downloads/covid-hospitalization-data/other_data/\"\n",
    "    #allfiles = []\n",
    "    week='2020-05-09'\n",
    "    death_st=np.zeros(51)\n",
    "    death_nat=0\n",
    "    flag=True\n",
    "    #for file in glob.glob(outputdir+\"*.csv\"):\n",
    "    data=pd.read_csv(outputdir+\"05-09-2020.csv\",delimiter=',')\n",
    "    data=data[['Province_State','Country_Region','Deaths']]\n",
    "        \n",
    "    #if flag:\n",
    "    state_names=list(data['Province_State'].drop_duplicates().values)\n",
    "    for r in row_to_remove:\n",
    "        state_names.remove(r)\n",
    "    state_names.append('X')\n",
    "    print(state_names)\n",
    "    print(len(state_names))\n",
    "    dic_names_to_abbv=read_fips_code(state_names,fips_path,abbv_to_code=False)\n",
    "    state_index={dic_names_to_abbv[state_names[i]]:i for i in range(len(state_names))}\n",
    "    print(state_index)\n",
    "    for ix, row in data.iterrows():\n",
    "        if row['Province_State'] in row_to_remove:\n",
    "            continue\n",
    "        st_id=state_index[dic_names_to_abbv[row['Province_State']]]\n",
    "        death_st[st_id]+=int(row['Deaths'])\n",
    "        death_nat+=int(row['Deaths'])\n",
    "        \n",
    "    print('-nat-death')\n",
    "    print(death_nat)\n",
    "    flag=False\n",
    "    print(death_st)\n",
    "    outdata=pd.DataFrame(columns=['date','state','deaths'])\n",
    "    outdata['date']=[week]\n",
    "    outdata['state']=['X']\n",
    "    outdata['deaths']=[death_nat]\n",
    "    for st in state_index.keys():\n",
    "        tmpdata=pd.DataFrame(columns=['date','state','deaths'])\n",
    "        tmpdata['date']=[week]\n",
    "        tmpdata['state']=[st]\n",
    "        tmpdata['deaths']=[int(death_st[state_index[st]])]\n",
    "        outdata=outdata.append(tmpdata,ignore_index=True)\n",
    "    \n",
    "    print(outdata)\n",
    "    outdata.to_csv(fips_path+\"jhu_deaths.csv\",index=False)\n",
    "       \n",
    "    \n",
    "get_jhu_deaths()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_res1 = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [20200307, Epidata.range(20200307, 20200601)], '*')\n",
    "fb_res2 = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "fb_res3 = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [20200701, Epidata.range(20200701, 20200815)], '*')\n",
    "from datetime import date\n",
    "fb_res_wili = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20201230, Epidata.range(20210101, 20210102)], '*')\n",
    "print(fb_res1.keys())\n",
    "print(fb_res2.keys())\n",
    "print(fb_res3.keys())\n",
    "#print(fb_res1['result'],fb_res1['message']) \n",
    "#print(fb_res2['result'],fb_res2['message'])\n",
    "#print(fb_res3['result'],fb_res3['message'])\n",
    "#'''\n",
    "print(fb_res1['result'], fb_res1['message'], len(fb_res1['epidata']))\n",
    "print(fb_res2['result'], fb_res2['message'], len(fb_res2['epidata']))\n",
    "print(fb_res3['result'], fb_res3['message'], len(fb_res3['epidata']))\n",
    "print(fb_res_wili['result'], fb_res_wili['message'], len(fb_res_wili['epidata']))\n",
    "fb_res=fb_res1['epidata']+fb_res2['epidata']\n",
    "fb_cli=fb_res+fb_res3['epidata']\n",
    "#print(fb_res1['epidata'][0])\n",
    "#print(len(fb_cli))\n",
    "print(fb_res_wili)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiweek1,epiweek_date1=get_epiweek_list('202001','202053',2020)\n",
    "epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "epiweek3,epiweek_date3=get_epiweek_list('202201','202252',2022)\n",
    "\n",
    "\n",
    "epiweek=epiweek1+epiweek2+epiweek3\n",
    "epiweek_date=epiweek_date1+epiweek_date2+epiweek_date3\n",
    "\n",
    "epiweek_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('delphi vaccine survey')\n",
    "start_week=20210101\n",
    "end_week=int(year_week_num)  #yyyymmdd\n",
    "\n",
    "vacc_delphi,cols_vacc_delphi=read_delphi_vaccine(state_index,epiweek_date,start_week,end_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mobility_test(inputdir,epiweek_date,end_week,MISSING_TOKEN=0):\n",
    "    data=pd.read_csv(inputdir+\"Global_Mobility_Report.csv\",low_memory=False)\n",
    "    data=data[data['country_region_code']=='US']\n",
    "    data=data.drop(data[data['sub_region_1'] == 'Hawaii'].index)\n",
    "    data=data.drop(columns=['sub_region_2'])\n",
    "    display(data.head())\n",
    "    \n",
    "    state_names=data['sub_region_1'].drop_duplicates().values\n",
    "    state_names[0]='X' #changing nan to US national X\n",
    "    data['sub_region_1'] = data['sub_region_1'].fillna('X')\n",
    "    cols=data.columns\n",
    "    cols=list(cols[8:])\n",
    "    dic_names_to_abbv=read_fips_code(state_names,inputdir,abbv_to_code=False)\n",
    "    \n",
    "    state_index = {dic_names_to_abbv[state_names[i]]: i for i in range(len(state_names))} \n",
    "    print(state_index)\n",
    "\n",
    "    #data[cols] = data[cols].fillna(MISSING_TOKEN)\n",
    "    \"\"\"\n",
    "    num_states=len(state_names)\n",
    "    #print(cols)\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((num_states,len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((num_states,len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_week)!=0:\n",
    "            week_cases[c][:][end_week]=np.nan\n",
    "        '''\n",
    "    print(cols)\n",
    "    #'''\n",
    "    for ix,row in data.iterrows():\n",
    "        if type(row['sub_region_1']) is float:\n",
    "            state_id=0\n",
    "        else:\n",
    "            state_id=state_index[dic_names_to_abbv[row['sub_region_1']]]\n",
    "        week_id=find_week_index(epiweek_date,str(row['date']),date_string=False)\n",
    "        if week_id!=-1:\n",
    "            for c in cols:\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    if np.isnan(week_cases[c][state_id][week_id]):\n",
    "                            week_cases[c][state_id][week_id]=0\n",
    "                    week_cases[c][state_id][week_id]+=row[c]\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/google-mobility.csv\")\n",
    "    #'''\n",
    "    \n",
    "    return week_cases,cols,state_index,dic_names_to_abbv\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202211\n",
      "['2020-01-04', '2020-01-11', '2020-01-18', '2020-01-25', '2020-02-01', '2020-02-08', '2020-02-15', '2020-02-22', '2020-02-29', '2020-03-07', '2020-03-14', '2020-03-21', '2020-03-28', '2020-04-04', '2020-04-11', '2020-04-18', '2020-04-25', '2020-05-02', '2020-05-09', '2020-05-16', '2020-05-23', '2020-05-30', '2020-06-06', '2020-06-13', '2020-06-20', '2020-06-27', '2020-07-04', '2020-07-11', '2020-07-18', '2020-07-25', '2020-08-01', '2020-08-08', '2020-08-15', '2020-08-22', '2020-08-29', '2020-09-05', '2020-09-12', '2020-09-19', '2020-09-26', '2020-10-03', '2020-10-10', '2020-10-17', '2020-10-24', '2020-10-31', '2020-11-07', '2020-11-14', '2020-11-21', '2020-11-28', '2020-12-05', '2020-12-12', '2020-12-19', '2020-12-26', '2021-01-02', '2021-01-09', '2021-01-16', '2021-01-23', '2021-01-30', '2021-02-06', '2021-02-13', '2021-02-20', '2021-02-27', '2021-03-06', '2021-03-13', '2021-03-20', '2021-03-27', '2021-04-03', '2021-04-10', '2021-04-17', '2021-04-24', '2021-05-01', '2021-05-08', '2021-05-15', '2021-05-22', '2021-05-29', '2021-06-05', '2021-06-12', '2021-06-19', '2021-06-26', '2021-07-03', '2021-07-10', '2021-07-17', '2021-07-24', '2021-07-31', '2021-08-07', '2021-08-14', '2021-08-21', '2021-08-28', '2021-09-04', '2021-09-11', '2021-09-18', '2021-09-25', '2021-10-02', '2021-10-09', '2021-10-16', '2021-10-23', '2021-10-30', '2021-11-06', '2021-11-13', '2021-11-20', '2021-11-27', '2021-12-04', '2021-12-11', '2021-12-18', '2021-12-25', '2022-01-01', '2022-01-08', '2022-01-15', '2022-01-22', '2022-01-29', '2022-02-05', '2022-02-12', '2022-02-19', '2022-02-26', '2022-03-05', '2022-03-12', '2022-03-19']\n",
      "['202001', '202002', '202003', '202004', '202005', '202006', '202007', '202008', '202009', '202010', '202011', '202012', '202013', '202014', '202015', '202016', '202017', '202018', '202019', '202020', '202021', '202022', '202023', '202024', '202025', '202026', '202027', '202028', '202029', '202030', '202031', '202032', '202033', '202034', '202035', '202036', '202037', '202038', '202039', '202040', '202041', '202042', '202043', '202044', '202045', '202046', '202047', '202048', '202049', '202050', '202051', '202052', '202053', '202101', '202102', '202103', '202104', '202105', '202106', '202107', '202108', '202109', '202110', '202111', '202112', '202113', '202114', '202115', '202116', '202117', '202118', '202119', '202120', '202121', '202122', '202123', '202124', '202125', '202126', '202127', '202128', '202129', '202130', '202131', '202132', '202133', '202134', '202135', '202136', '202137', '202138', '202139', '202140', '202141', '202142', '202143', '202144', '202145', '202146', '202147', '202148', '202149', '202150', '202151', '202152', '202201', '202202', '202203', '202204', '202205', '202206', '202207', '202208', '202209', '202210', '202211']\n",
      "google mobility\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_region_code</th>\n",
       "      <th>country_region</th>\n",
       "      <th>sub_region_1</th>\n",
       "      <th>metro_area</th>\n",
       "      <th>iso_3166_2_code</th>\n",
       "      <th>census_fips_code</th>\n",
       "      <th>place_id</th>\n",
       "      <th>date</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7059895</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJCzYy5IS16lQRQrfeQ5K5Oxw</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059896</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJCzYy5IS16lQRQrfeQ5K5Oxw</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059897</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJCzYy5IS16lQRQrfeQ5K5Oxw</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059898</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJCzYy5IS16lQRQrfeQ5K5Oxw</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7059899</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChIJCzYy5IS16lQRQrfeQ5K5Oxw</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country_region_code country_region sub_region_1 metro_area  \\\n",
       "7059895                  US  United States            X        NaN   \n",
       "7059896                  US  United States            X        NaN   \n",
       "7059897                  US  United States            X        NaN   \n",
       "7059898                  US  United States            X        NaN   \n",
       "7059899                  US  United States            X        NaN   \n",
       "\n",
       "        iso_3166_2_code  census_fips_code                     place_id  \\\n",
       "7059895             NaN               NaN  ChIJCzYy5IS16lQRQrfeQ5K5Oxw   \n",
       "7059896             NaN               NaN  ChIJCzYy5IS16lQRQrfeQ5K5Oxw   \n",
       "7059897             NaN               NaN  ChIJCzYy5IS16lQRQrfeQ5K5Oxw   \n",
       "7059898             NaN               NaN  ChIJCzYy5IS16lQRQrfeQ5K5Oxw   \n",
       "7059899             NaN               NaN  ChIJCzYy5IS16lQRQrfeQ5K5Oxw   \n",
       "\n",
       "               date  retail_and_recreation_percent_change_from_baseline  \\\n",
       "7059895  2020-02-15                                                6.0    \n",
       "7059896  2020-02-16                                                7.0    \n",
       "7059897  2020-02-17                                                6.0    \n",
       "7059898  2020-02-18                                                0.0    \n",
       "7059899  2020-02-19                                                2.0    \n",
       "\n",
       "         grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "7059895                                                2.0   \n",
       "7059896                                                1.0   \n",
       "7059897                                                0.0   \n",
       "7059898                                               -1.0   \n",
       "7059899                                                0.0   \n",
       "\n",
       "         parks_percent_change_from_baseline  \\\n",
       "7059895                                15.0   \n",
       "7059896                                16.0   \n",
       "7059897                                28.0   \n",
       "7059898                                 6.0   \n",
       "7059899                                 8.0   \n",
       "\n",
       "         transit_stations_percent_change_from_baseline  \\\n",
       "7059895                                            3.0   \n",
       "7059896                                            2.0   \n",
       "7059897                                           -9.0   \n",
       "7059898                                            1.0   \n",
       "7059899                                            1.0   \n",
       "\n",
       "         workplaces_percent_change_from_baseline  \\\n",
       "7059895                                      2.0   \n",
       "7059896                                      0.0   \n",
       "7059897                                    -24.0   \n",
       "7059898                                      0.0   \n",
       "7059899                                      1.0   \n",
       "\n",
       "         residential_percent_change_from_baseline  \n",
       "7059895                                      -1.0  \n",
       "7059896                                      -1.0  \n",
       "7059897                                       5.0  \n",
       "7059898                                       1.0  \n",
       "7059899                                       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': 0, 'AL': 1, 'AK': 2, 'AZ': 3, 'AR': 4, 'CA': 5, 'CO': 6, 'CT': 7, 'DE': 8, 'DC': 9, 'FL': 10, 'GA': 11, 'ID': 12, 'IL': 13, 'IN': 14, 'IA': 15, 'KS': 16, 'KY': 17, 'LA': 18, 'ME': 19, 'MD': 20, 'MA': 21, 'MI': 22, 'MN': 23, 'MS': 24, 'MO': 25, 'MT': 26, 'NE': 27, 'NV': 28, 'NH': 29, 'NJ': 30, 'NM': 31, 'NY': 32, 'NC': 33, 'ND': 34, 'OH': 35, 'OK': 36, 'OR': 37, 'PA': 38, 'RI': 39, 'SC': 40, 'SD': 41, 'TN': 42, 'TX': 43, 'UT': 44, 'VT': 45, 'VA': 46, 'WA': 47, 'WV': 48, 'WI': 49, 'WY': 50}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from IPython.display import display \n",
    "if date.today().weekday() != 6:\n",
    "    week_num = (date.today()-timedelta(2)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\"  + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() +timedelta((5-date.today().weekday()) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_date = (date.today() - timedelta(2)).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() + timedelta((5-date.today().weekday()) % 7 )).strftime('%Y%m%d')\n",
    "    week_end_string = (date.today() - timedelta(2)).strftime('%Y%m%d')\n",
    "\n",
    "else:\n",
    "    week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() -timedelta((date.today().weekday()-5) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() - timedelta((date.today().weekday()-5) % 7 )).strftime('%Y%m%d')\n",
    "### INPUT FILE DIRECTORY #####\n",
    "# data_path=\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "data_path=\"./\"\n",
    "# kinsa_path= \"/Users/anikat/Downloads/kinsahealth/\"\n",
    "kinsa_path = \"./\"\n",
    "### INPUT: EPIWEEK START, END WEEK ####\n",
    "#Both the method args will be same. This is to keep last date in the ouput file to same as epiweek\n",
    "epiweek1,epiweek_date1=get_epiweek_list('202001','202053',2020)\n",
    "epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "epiweek3,epiweek_date3=get_epiweek_list('202201',year_week_num,2022)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epiweek=epiweek1+epiweek2+epiweek3\n",
    "epiweek_date=epiweek_date1+epiweek_date2+epiweek_date3\n",
    "week_save=copy.deepcopy(epiweek_date)\n",
    "### ****NOTE: for new year 2021 add another epiweek list and append with previous**** #######\n",
    "\n",
    "print(epiweek_date)\n",
    "print(epiweek)\n",
    "# PROCESSING MOBILITY ####\n",
    "# INPUT: END_WEEK: the last epiweek this csv file contains  ####\n",
    "print('google mobility')\n",
    "start_week_m=1\n",
    "end_week_m=int(week_num) #2021, m=epiweek since data generally have value -4 days lag for current week\n",
    "read_mobility_test(data_path,epiweek_date,end_week_m)\n",
    "#dic_names_to_abbv['United States']='X'\n",
    "#print(dic_names_to_abbv)\n",
    "#print(len(state_index.keys()))\n",
    "#print(state_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-304fa4ce4ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek_list_test(week_start,week_end,year):\n",
    "    def convert(x):\n",
    "        return Week.fromstring(str(x))\n",
    "    \n",
    "    wstart=convert(week_start)\n",
    "    wend=convert(week_end)\n",
    "    #print(wstart,wend)\n",
    "    week_edate_list=[]\n",
    "    week_list=[]\n",
    "    for week in Year(year).iterweeks():\n",
    "        date_time = week.enddate().strftime(\"%Y-%m-%d\")\n",
    "        #print(week,date_time)\n",
    "        if week>=wstart and week<=wend:\n",
    "            week_edate_list.append(date_time)\n",
    "            week_list.append(str(week))\n",
    "     \n",
    "    return week_list,week_edate_list  \n",
    "\n",
    "\n",
    "\n",
    "def convert_to_epiweek(x):\n",
    "    return Week.fromdate(x)\n",
    "def read_mobility_test(inputdir,epiweek_date,end_week,MISSING_TOKEN=0):\n",
    "    data=pd.read_csv(inputdir+\"Global_Mobility_Report.csv\",low_memory=False)\n",
    "    data=data[data['country_region_code']=='US']\n",
    "    data=data.drop(data[data['sub_region_1'] == 'Hawaii'].index)\n",
    "    data= data[pd.isnull(data['sub_region_2'])]\n",
    "    data=data.drop(columns=['sub_region_2'])\n",
    "    \n",
    "    state_names=data['sub_region_1'].drop_duplicates().values\n",
    "    state_names[0]='X' #changing nan to US national X\n",
    "    cols=data.columns\n",
    "    print(cols)\n",
    "    cols=list(cols[8:])\n",
    "    print(cols)\n",
    "    \n",
    "    data['sub_region_1'] = data['sub_region_1'].fillna('X')\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['epiweek'] = data['date'].dt.date.apply(convert_to_epiweek)\n",
    "    epiweek_data = data.groupby(['epiweek', 'sub_region_1'], as_index=False).mean()\n",
    "    dic_names_to_abbv=read_fips_code(state_names,inputdir,abbv_to_code=False)\n",
    "    print(dic_names_to_abbv)\n",
    "    \n",
    "    state_index = {dic_names_to_abbv[state_names[i]]: i for i in range(len(state_names))} \n",
    "    print(state_index)\n",
    "    \n",
    "    #data[cols] = data[cols].fillna(MISSING_TOKEN)\n",
    "    num_states=len(state_names)\n",
    "    #print(cols)\n",
    "    week_cases={}\n",
    "    week_cases_check = {}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((num_states,len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        week_cases_check[c] = np.full((num_states,len(epiweek_date)), False)\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((num_states,len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_week)!=0:\n",
    "            week_cases[c][:][end_week]=np.nan\n",
    "        '''\n",
    "    print(cols)\n",
    "    \n",
    "    #'''\n",
    "    for ix,row in data.iterrows():\n",
    "        state_id=state_index[dic_names_to_abbv[row['sub_region_1']]]\n",
    "        week_id=find_week_index(epiweek_date,str(row['date'].date()),date_string=False)\n",
    "        if week_id!=-1:\n",
    "            for c in cols:\n",
    "                if not pd.isnull(row[c]) and not week_cases_check[c][state_id][week_id]: \n",
    "                    value = epiweek_data[epiweek_data['epiweek'] == convert_to_epiweek(row['date'])] \n",
    "                    value = value[value['sub_region_1'] == row['sub_region_1']]\n",
    "                    \n",
    "                    for i in value[c]: \n",
    "                        week_cases[c][state_id][week_id] = i\n",
    "                    week_cases_check[c][state_id][week_id] = True\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/google-mobility.csv\")\n",
    "    #'''\n",
    "    \n",
    "    return week_cases,cols,state_index,dic_names_to_abbv\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202211\n",
      "['2020-01-04', '2020-01-11', '2020-01-18', '2020-01-25', '2020-02-01', '2020-02-08', '2020-02-15', '2020-02-22', '2020-02-29', '2020-03-07', '2020-03-14', '2020-03-21', '2020-03-28', '2020-04-04', '2020-04-11', '2020-04-18', '2020-04-25', '2020-05-02', '2020-05-09', '2020-05-16', '2020-05-23', '2020-05-30', '2020-06-06', '2020-06-13', '2020-06-20', '2020-06-27', '2020-07-04', '2020-07-11', '2020-07-18', '2020-07-25', '2020-08-01', '2020-08-08', '2020-08-15', '2020-08-22', '2020-08-29', '2020-09-05', '2020-09-12', '2020-09-19', '2020-09-26', '2020-10-03', '2020-10-10', '2020-10-17', '2020-10-24', '2020-10-31', '2020-11-07', '2020-11-14', '2020-11-21', '2020-11-28', '2020-12-05', '2020-12-12', '2020-12-19', '2020-12-26', '2021-01-02', '2021-01-09', '2021-01-16', '2021-01-23', '2021-01-30', '2021-02-06', '2021-02-13', '2021-02-20', '2021-02-27', '2021-03-06', '2021-03-13', '2021-03-20', '2021-03-27', '2021-04-03', '2021-04-10', '2021-04-17', '2021-04-24', '2021-05-01', '2021-05-08', '2021-05-15', '2021-05-22', '2021-05-29', '2021-06-05', '2021-06-12', '2021-06-19', '2021-06-26', '2021-07-03', '2021-07-10', '2021-07-17', '2021-07-24', '2021-07-31', '2021-08-07', '2021-08-14', '2021-08-21', '2021-08-28', '2021-09-04', '2021-09-11', '2021-09-18', '2021-09-25', '2021-10-02', '2021-10-09', '2021-10-16', '2021-10-23', '2021-10-30', '2021-11-06', '2021-11-13', '2021-11-20', '2021-11-27', '2021-12-04', '2021-12-11', '2021-12-18', '2021-12-25', '2022-01-01', '2022-01-08', '2022-01-15', '2022-01-22', '2022-01-29', '2022-02-05', '2022-02-12', '2022-02-19', '2022-02-26', '2022-03-05', '2022-03-12', '2022-03-19']\n",
      "116\n",
      "['202001', '202002', '202003', '202004', '202005', '202006', '202007', '202008', '202009', '202010', '202011', '202012', '202013', '202014', '202015', '202016', '202017', '202018', '202019', '202020', '202021', '202022', '202023', '202024', '202025', '202026', '202027', '202028', '202029', '202030', '202031', '202032', '202033', '202034', '202035', '202036', '202037', '202038', '202039', '202040', '202041', '202042', '202043', '202044', '202045', '202046', '202047', '202048', '202049', '202050', '202051', '202052', '202053', '202101', '202102', '202103', '202104', '202105', '202106', '202107', '202108', '202109', '202110', '202111', '202112', '202113', '202114', '202115', '202116', '202117', '202118', '202119', '202120', '202121', '202122', '202123', '202124', '202125', '202126', '202127', '202128', '202129', '202130', '202131', '202132', '202133', '202134', '202135', '202136', '202137', '202138', '202139', '202140', '202141', '202142', '202143', '202144', '202145', '202146', '202147', '202148', '202149', '202150', '202151', '202152', '202201', '202202', '202203', '202204', '202205', '202206', '202207', '202208', '202209', '202210', '202211']\n",
      "google mobility\n",
      "Index(['country_region_code', 'country_region', 'sub_region_1', 'metro_area',\n",
      "       'iso_3166_2_code', 'census_fips_code', 'place_id', 'date',\n",
      "       'retail_and_recreation_percent_change_from_baseline',\n",
      "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
      "       'parks_percent_change_from_baseline',\n",
      "       'transit_stations_percent_change_from_baseline',\n",
      "       'workplaces_percent_change_from_baseline',\n",
      "       'residential_percent_change_from_baseline'],\n",
      "      dtype='object')\n",
      "['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n",
      "{'X': 'X', 'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'}\n",
      "{'X': 0, 'AL': 1, 'AK': 2, 'AZ': 3, 'AR': 4, 'CA': 5, 'CO': 6, 'CT': 7, 'DE': 8, 'DC': 9, 'FL': 10, 'GA': 11, 'ID': 12, 'IL': 13, 'IN': 14, 'IA': 15, 'KS': 16, 'KY': 17, 'LA': 18, 'ME': 19, 'MD': 20, 'MA': 21, 'MI': 22, 'MN': 23, 'MS': 24, 'MO': 25, 'MT': 26, 'NE': 27, 'NV': 28, 'NH': 29, 'NJ': 30, 'NM': 31, 'NY': 32, 'NC': 33, 'ND': 34, 'OH': 35, 'OK': 36, 'OR': 37, 'PA': 38, 'RI': 39, 'SC': 40, 'SD': 41, 'TN': 42, 'TX': 43, 'UT': 44, 'VT': 45, 'VA': 46, 'WA': 47, 'WV': 48, 'WI': 49, 'WY': 50}\n",
      "['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n",
      "(5916, 8)\n",
      "output file written\n",
      "['date', 'epiweek', 'region', 'fips', 'retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n",
      "(5916, 10)\n",
      "FINISHED....\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "if date.today().weekday() != 6:\n",
    "    week_num = (date.today()-timedelta(2)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\"  + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() +timedelta((5-date.today().weekday()) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_date = (date.today() - timedelta(2)).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() + timedelta((5-date.today().weekday()) % 7 )).strftime('%Y%m%d')\n",
    "    week_end_string = (date.today() - timedelta(2)).strftime('%Y%m%d')\n",
    "\n",
    "else:\n",
    "    week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() -timedelta((date.today().weekday()-5) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() - timedelta((date.today().weekday()-5) % 7 )).strftime('%Y%m%d')\n",
    "data_path=\"./\"\n",
    "# kinsa_path= \"/Users/anikat/Downloads/kinsahealth/\"\n",
    "kinsa_path = \"./\"\n",
    "### INPUT: EPIWEEK START, END WEEK ####\n",
    "#Both the method args will be same. This is to keep last date in the ouput file to same as epiweek\n",
    "epiweek1,epiweek_date1=get_epiweek_list('202001','202053',2020)\n",
    "epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "epiweek3,epiweek_date3=get_epiweek_list('202201',year_week_num,2022)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epiweek=epiweek1+epiweek2+epiweek3\n",
    "epiweek_date=epiweek_date1+epiweek_date2+epiweek_date3\n",
    "week_save=copy.deepcopy(epiweek_date)\n",
    "### ****NOTE: for new year 2021 add another epiweek list and append with previous**** #######\n",
    "\n",
    "print(epiweek_date)\n",
    "print(len(epiweek_date))\n",
    "print(epiweek)\n",
    "# PROCESSING MOBILITY ####\n",
    "# INPUT: END_WEEK: the last epiweek this csv file contains  ####\n",
    "print('google mobility')\n",
    "start_week_m=1\n",
    "end_week_m=int(week_num) #2021, m=epiweek since data generally have value -4 days lag for current week\n",
    "mobility_state,cols_m,state_index,dic_names_to_abbv=read_mobility_test(data_path,epiweek_date,end_week_m)\n",
    "dic_names_to_abbv['United States']='X'\n",
    "state_names=list(state_index.keys())\n",
    "state_fips=read_fips_code(state_names,data_path)\n",
    "\n",
    "outputdir=data_path #\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "outfile=\"covid-hospitalization-all-state-merged_vEW\" + year_week_num+\".csv\"\n",
    "merge_data_state_test(mobility_state, cols_m, state_fips,epiweek,week_save,state_names,outputdir,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_state_test(mobility,apple,vacc,vac_delphi,cdc_hosp,flu_hosp,dex,kinsa,covidnet,hosp,excess,jhu,survey,jhu_case,hosp_new_res,\n",
    "                     cols_m,cols_a,cols_vacc,cols_vac_delphi,cols_cdc,cols_flu,cols_d,cols_k,cols_net,\n",
    "                     cols_hosp,cols_excess,cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res,\n",
    "                     state_fips,epiweek,epiweek_date,region_names,outputdir,outfilename):\n",
    "    \n",
    "    cols_common=['date','epiweek','region','fips']\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_d+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_k+cols_q+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_flu+cols_d+cols_vacc+cols_vac_delphi+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_jhu_case+cols_hosp_new_res\n",
    "    \n",
    "    print(all_cols)\n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        temp_data['fips']=[state_fips[region_names[reg]]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility[c][reg][:]\n",
    "        for c in cols_a:\n",
    "            temp_data[c]=apple[c][reg][:]\n",
    "        for c in cols_cdc:\n",
    "            temp_data[c]=cdc_hosp[c][reg][:]\n",
    "        for c in cols_flu:\n",
    "            temp_data[c]=flu_hosp[c][reg][:]\n",
    "        for c in cols_d:\n",
    "            temp_data[c]=dex[c][reg][:]\n",
    "        for c in cols_vacc:\n",
    "            temp_data[c]=vacc[c][reg][:]\n",
    "        for c in cols_vacc_delphi:\n",
    "            temp_data[c]=vacc_delphi[c][reg][:]\n",
    "        for c in cols_k:\n",
    "            temp_data[c]=kinsa[c][reg][:]\n",
    "        #for c in cols_q:\n",
    "         #   temp_data[c]=iqvia[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet[c][reg][:]\n",
    "        for c in cols_hosp:\n",
    "            temp_data[c]=hosp[c][reg][:]\n",
    "        for c in cols_excess:\n",
    "            temp_data[c]=excess[c][reg][:]\n",
    "        for c in cols_jhu:\n",
    "            temp_data[c]=jhu[c][reg][:]\n",
    "        for c in cols_survey:\n",
    "            temp_data[c]=survey[c][reg][:]\n",
    "        #for c in cols_v:\n",
    "        #    temp_data[c]=em_visit[c][reg][:]\n",
    "        for c in cols_jhu_case:\n",
    "            temp_data[c]=jhu_case[c][reg][:]\n",
    "        for c in cols_hosp_new_res:\n",
    "            temp_data[c]=hosp_new_res[c][reg][:]\n",
    "        \n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    \n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
