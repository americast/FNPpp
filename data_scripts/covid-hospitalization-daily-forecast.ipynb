{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata sources:\\n1. google mobility: https://www.google.com/covid19/mobility/\\n2. apple mobilty: https://www.apple.com/covid19/mobility\\n3. Covid ExposureIndex dex: https://github.com/COVIDExposureIndices/COVIDExposureIndices\\n4. kinsa: kinsa_pull.ipynb \\n5. fb-google survey: deplhi api\\n6. hospitalization: https://covidtracking.com/api\\n6a. positiveIncrease: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\\n6b. negaiveResults, totalRes: https://healthdata.gov/dataset/COVID-19-Diagnostic-Laboratory-Testing-PCR-Testing/j8mb-icvb\\n7. jhu deaths: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\\n8. iqvia: Alex from Jimeng\\n9. excess deaths: https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm\\n10. Emergency visits (less priority: region level): \\n#https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/07242020/covid-like-illness.html\\nhttps://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/10092020/outpatient-emergency-visits.html\\n11. covidnet: original cdc, processed data to use given by ALEX\\n12. CDC hospitalized: https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-state-timeseries\\n13. vaccine doses: https://github.com/govex/COVID-19/blob/master/data_tables/vaccine_data/us_data/time_series/vaccine_data_us_timeline.csv\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data sources:\n",
    "1. google mobility: https://www.google.com/covid19/mobility/\n",
    "2. apple mobilty: https://www.apple.com/covid19/mobility\n",
    "3. Covid ExposureIndex dex: https://github.com/COVIDExposureIndices/COVIDExposureIndices\n",
    "4. kinsa: kinsa_pull.ipynb \n",
    "5. fb-google survey: deplhi api\n",
    "6. hospitalization: https://covidtracking.com/api\n",
    "6a. positiveIncrease: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "6b. negaiveResults, totalRes: https://healthdata.gov/dataset/COVID-19-Diagnostic-Laboratory-Testing-PCR-Testing/j8mb-icvb\n",
    "7. jhu deaths: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "8. iqvia: Alex from Jimeng\n",
    "9. excess deaths: https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm\n",
    "10. Emergency visits (less priority: region level): \n",
    "#https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/07242020/covid-like-illness.html\n",
    "https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/10092020/outpatient-emergency-visits.html\n",
    "11. covidnet: original cdc, processed data to use given by ALEX\n",
    "12. CDC hospitalized: https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-state-timeseries\n",
    "13. vaccine doses: https://github.com/govex/COVID-19/blob/master/data_tables/vaccine_data/us_data/time_series/vaccine_data_us_timeline.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "from epiweeks import Week, Year\n",
    "from delphi_epidata import Epidata\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unit_test(data_dic,cols,epiweek_date,state_index,outfile):\n",
    "    state_names=list(state_index.keys())\n",
    "    all_cols=['date','region']+cols\n",
    "    out_data=pd.DataFrame(columns=all_cols)\n",
    "    for st in range(len(state_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['region']=[state_names[st]]*len(epiweek_date)\n",
    "        for c in cols:\n",
    "            temp_data[c]=data_dic[c][st][:]\n",
    "        out_data=out_data.append(temp_data,ignore_index=True)\n",
    "    out_data=out_data[all_cols]\n",
    "    print(out_data.shape)\n",
    "    out_data.to_csv(outfile,index=False)\n",
    "    print('output file written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_survey_epidata(col_name,epidata,state_index,state_names,epiweek_date):\n",
    "    week_cases=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    total_sample=0\n",
    "    for ix in range(len(epidata)):\n",
    "        row=epidata[ix]\n",
    "        name=row['geo_value'].upper()\n",
    "        w_idx=find_date_index(epiweek_date,str(row['time_value']))\n",
    "        if name == 'US' and w_idx !=-1:\n",
    "            week_cases[0][w_idx] = row['value']\n",
    "        elif name in state_names and w_idx!=-1:\n",
    "            state_id=state_index[name]\n",
    "            week_cases[state_id][w_idx]=row['value']\n",
    "    return week_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_delphi_vaccine(state_index,epiweek_date,start_week,end_week):\n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210208, Epidata.range(20210208, end_week)],'*')\n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210308, Epidata.range(20210308, end_week)],'*')\n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20211101, end_week)],'*')\n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']\n",
    "    vacc3=vacc31['epidata']#+vacc32['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc15['result'], vacc15['message'], len(vacc15['epidata']))\n",
    "    print('smoothed_wcovid_vaccinated',vacc16['result'], vacc16['message'], len(vacc16['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc24['result'], vacc24['message'], len(vacc24['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc25['result'], vacc25['message'], len(vacc25['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc31['result'], vacc31['message'], len(vacc31['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc42['result'], vacc42['message'], len(vacc42['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc52['result'], vacc52['message'], len(vacc52['epidata']))\n",
    "    #print(vacc5['epidata'][0]['value'])\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask',\n",
    "          'smoothed_wtravel_outside_state_5d','smoothed_wspent_time_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/vaccine_survey.csv\")\n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fb(state_index,epiweek_date,start_week,end_week,start_week2):\n",
    "    vacc = []\n",
    "    vacc.append([])\n",
    "    vacc.append([])\n",
    "    vacc.append([])\n",
    "    vacc.append([])\n",
    "    vacc[0].append(Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc[0].append(Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc[1].append(Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc[1].append(Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*'))\n",
    "    vacc[2].append(Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210208, Epidata.range(20210208, 20210301)],'*'))\n",
    "    vacc[2].append(Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210208, Epidata.range(20210208, 20210301)],'*'))\n",
    "    start_date = date(2021, 3, 1)\n",
    "    while start_date < date.today() + relativedelta(months=-2):\n",
    "        start = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        start_date = start_date + relativedelta(months=+2)\n",
    "        end = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        vacc[0].append(Epidata.covidcast('fb-survey', 'smoothed_wcovid_vaccinated', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[0].append(Epidata.covidcast('fb-survey', 'smoothed_wcovid_vaccinated', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[1].append(Epidata.covidcast('fb-survey', 'smoothed_wtested_positive_14d', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[1].append(Epidata.covidcast('fb-survey', 'smoothed_wtested_positive_14d', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[2].append(Epidata.covidcast('fb-survey', 'smoothed_wwearing_mask_7d', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[2].append(Epidata.covidcast('fb-survey', 'smoothed_wwearing_mask_7d', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[3].append(Epidata.covidcast('fb-survey', 'smoothed_wspent_time_indoors_1d', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        vacc[3].append(Epidata.covidcast('fb-survey', 'smoothed_wspent_time_indoors_1d', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        print(start)\n",
    "        print(end)\n",
    "    vacc[0].append(Epidata.covidcast('fb-survey', 'smoothed_wcovid_vaccinated', 'day', 'state', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[0].append(Epidata.covidcast('fb-survey', 'smoothed_wcovid_vaccinated', 'day', 'nation', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[1].append(Epidata.covidcast('fb-survey', 'smoothed_wtested_positive_14d', 'day', 'state', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[1].append(Epidata.covidcast('fb-survey', 'smoothed_wtested_positive_14d', 'day', 'nation', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[2].append(Epidata.covidcast('fb-survey', 'smoothed_wwearing_mask_7d', 'day', 'state', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[2].append(Epidata.covidcast('fb-survey', 'smoothed_wwearing_mask_7d', 'day', 'nation', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[3].append(Epidata.covidcast('fb-survey', 'smoothed_wspent_time_indoors_1d', 'day', 'state', [end, Epidata.range(end, end_week)], '*'))\n",
    "    vacc[3].append(Epidata.covidcast('fb-survey', 'smoothed_wspent_time_indoors_1d', 'day', 'nation', [end, Epidata.range(end, end_week)], '*'))\n",
    "    \n",
    "    vacc_final = []\n",
    "    vacc_final.append(vacc[0][0]['epidata'])\n",
    "    vacc_final.append(vacc[1][0]['epidata'])\n",
    "    vacc_final.append(vacc[2][0]['epidata'])\n",
    "    vacc_final.append(vacc[3][0]['epidata'])\n",
    "    \n",
    "    for i in range(len(vacc_final)):\n",
    "        for j in range(1, len(vacc[i])): \n",
    "            vacc_final[i] += vacc[i][j]['epidata']\n",
    "    \n",
    "    fb_survey = []\n",
    "    fb_survey.append([])\n",
    "    fb_survey.append([])\n",
    "    fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week2, Epidata.range(start_week2, 20200601)], '*'))\n",
    "    fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start_week2, Epidata.range(start_week2, 20200601)], '*'))\n",
    "    fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week2, Epidata.range(start_week2, 20200601)], '*'))\n",
    "    fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start_week2, Epidata.range(start_week2, 20200601)], '*'))\n",
    "    fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*'))\n",
    "    start_date = date(2020, 7, 1)\n",
    "    while start_date < date.today() + relativedelta(months=-2):\n",
    "        start = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        start_date = start_date + relativedelta(months=+2)\n",
    "        end = (int) (start_date.strftime(\"%Y%m%d\"))\n",
    "        fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start, Epidata.range(start, end)], '*'))\n",
    "        fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start, Epidata.range(start, end)], '*'))\n",
    "        print(start)\n",
    "        print(end)\n",
    "    fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_survey[0].append(Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state',[end, Epidata.range(end, end_week)], '*'))\n",
    "    fb_survey[1].append(Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation',[end, Epidata.range(end, end_week)], '*'))\n",
    "    \n",
    "    fb_survey_final = []\n",
    "    fb_survey_final.append(fb_survey[0][0]['epidata'])\n",
    "    fb_survey_final.append(fb_survey[1][0]['epidata'])\n",
    "    for i in range(len(fb_survey_final)):\n",
    "        for j in range(1, len(fb_survey[i])): \n",
    "            fb_survey_final[i] += fb_survey[i][j]['epidata']\n",
    "    \n",
    "    print(len(vacc[0]))\n",
    "    print(len(vacc[1]))\n",
    "    print(len(vacc[2]))\n",
    "    print(len(vacc[3]))\n",
    "    print(len(fb_survey[0]))\n",
    "    print(len(fb_survey[1]))\n",
    "    \n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask_7d'\n",
    "          ,'smoothed_wspent_time_indoors_1d','fb_survey_wcli','fb_survey_wili']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc_final[0],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc_final[1],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc_final[2],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc_final[3],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],fb_survey_final[0],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[5]]=read_survey_epidata(cols[5],fb_survey_final[1],state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delphi_vaccine_test_two(state_index,epiweek_date,start_week,end_week):\n",
    "    #'''\n",
    "    # The \n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210208, Epidata.range(20210208, 20210301)],'*')\n",
    "    ##vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    ##vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc11_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210208, Epidata.range(20210208, 20210301)],'*')\n",
    "    ##vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    ##vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc18=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc12_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc18_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220301, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc27=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc28=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc22_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc23_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc24_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc25_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc26_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc27_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc28_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    \n",
    "    vacc32=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc33=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc34=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc35=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc36=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc37=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc38=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc32_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc33_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc34_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc35_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc36_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc37_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc38_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    \n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc43=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc44=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc45=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc46=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    #vacc47=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc43_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc44_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc45_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc46_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    #vacc47_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc53=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc54=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc55=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc56=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc57=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210302, Epidata.range(20210302, 20210501)],'*')\n",
    "    vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc53_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc54_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc55_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc56_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20220101, Epidata.range(20220101, 20220301)],'*')\n",
    "    vacc57_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20220301, Epidata.range(20220301, end_week)],'*')\n",
    "    \n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    ##vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    ##vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    #vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    #vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']+vacc17['epidata']+vacc18['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']+vacc26['epidata']+vacc27['epidata']+vacc28['epidata']\n",
    "    vacc3=vacc31['epidata']+vacc32['epidata']+vacc33['epidata']+vacc34['epidata']+vacc35['epidata']+vacc36['epidata']+vacc37['epidata']+vacc38['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']+vacc43['epidata']+vacc44['epidata']+vacc45['epidata']+vacc46['epidata']#+vacc47['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']+vacc53['epidata']+vacc54['epidata']+vacc55['epidata']+vacc56['epidata']+vacc57['epidata']\n",
    "    \n",
    "    vacc1_us=vacc11_us['epidata']+vacc12_us['epidata']+vacc13_us['epidata']+vacc14_us['epidata']+vacc15_us['epidata']+vacc16_us['epidata']+vacc17_us['epidata']+vacc18_us['epidata']\n",
    "    vacc2_us=vacc21_us['epidata']+vacc22_us['epidata']+vacc23_us['epidata']+vacc24_us['epidata']+vacc25_us['epidata']+vacc26_us['epidata']+vacc27_us['epidata']+vacc28_us['epidata']\n",
    "    vacc3_us=vacc31_us['epidata']+vacc32_us['epidata']+vacc33_us['epidata']+vacc34_us['epidata']+vacc35_us['epidata']+vacc36_us['epidata']+vacc37_us['epidata']+vacc38_us['epidata']\n",
    "    vacc4_us=vacc41_us['epidata']+vacc42_us['epidata']+vacc43_us['epidata']+vacc44_us['epidata']+vacc45_us['epidata']+vacc46_us['epidata']#+vacc47_us['epidata']\n",
    "    vacc5_us=vacc51_us['epidata']+vacc52_us['epidata']+vacc53_us['epidata']+vacc54_us['epidata']+vacc55_us['epidata']+vacc56_us['epidata']+vacc57_us['epidata']\n",
    "    \n",
    "    vacc1_final = vacc1 + vacc1_us\n",
    "    vacc2_final = vacc2 + vacc2_us\n",
    "    vacc3_final = vacc3 + vacc3_us\n",
    "    vacc4_final = vacc4 + vacc4_us\n",
    "    vacc5_final = vacc5 + vacc5_us\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc18['result'], vacc18['message'], len(vacc18['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc28['result'], vacc28['message'], len(vacc28['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc38['result'], vacc38['message'], len(vacc38['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc46['result'], vacc46['message'], len(vacc46['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc57['result'], vacc57['message'], len(vacc57['epidata']))\n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask_7d',\n",
    "          'smoothed_wtravel_outside_state_7d','smoothed_wspent_time_indoors_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5_final,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delphi_vaccine_test(state_index,epiweek_date,start_week,end_week):\n",
    "    #'''\n",
    "    # The \n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','state',[20210208, Epidata.range(20210208, end_week)],'*')\n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','state',[20210308, Epidata.range(20210308, end_week)],'*')\n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','state',[20210302, Epidata.range(20210302, end_week)],'*')\n",
    "    \n",
    "    vacc11_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask_7d','day','nation',[20210208, Epidata.range(20210208, end_week)],'*')\n",
    "    vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_7d','day','nation',[20210308, Epidata.range(20210308, end_week)],'*')\n",
    "    vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_indoors_1d','day','nation',[20210302, Epidata.range(20210302, end_week)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc12_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \"\"\"vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\"\"\"\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']+vacc17['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']+vacc26['epidata']\n",
    "    vacc3=vacc31['epidata']#+vacc32['epidata']\n",
    "    vacc4=vacc41['epidata']#+vacc42['epidata']\n",
    "    vacc5=vacc51['epidata']#+vacc52['epidata']\n",
    "    \n",
    "    vacc1_us=vacc11_us['epidata']+vacc12_us['epidata']+vacc13_us['epidata']+vacc14_us['epidata']+vacc15_us['epidata']+vacc16_us['epidata']+vacc17_us['epidata']\n",
    "    vacc2_us=vacc21_us['epidata']+vacc22_us['epidata']+vacc23_us['epidata']+vacc24_us['epidata']+vacc25_us['epidata']+vacc26_us['epidata']\n",
    "    vacc3_us=vacc31_us['epidata']#+vacc32['epidata']\n",
    "    vacc4_us=vacc41_us['epidata']#+vacc42_us['epidata']\n",
    "    vacc5_us=vacc51_us['epidata']#+vacc52_us['epidata']\n",
    "    \n",
    "    vacc1_final = vacc1 + vacc1_us\n",
    "    vacc2_final = vacc2 + vacc2_us\n",
    "    vacc3_final = vacc3 + vacc3_us\n",
    "    vacc4_final = vacc4 + vacc4_us\n",
    "    vacc5_final = vacc5 + vacc5_us\n",
    "    \n",
    "    \"\"\"\n",
    "    print('smoothed_wcovid_vaccinated',vacc17['result'], vacc17['message'], len(vacc17['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc26['result'], vacc26['message'], len(vacc26['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc31['result'], vacc31['message'], len(vacc31['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc42['result'], vacc42['message'], len(vacc42['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc52['result'], vacc52['message'], len(vacc52['epidata']))\"\"\"\n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask',\n",
    "          'smoothed_wtravel_outside_state_5d','smoothed_wspent_time_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5_final,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2352885322.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [9]\u001b[0;36m\u001b[0m\n\u001b[0;31m    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def read_delphi(state_index, epiweek_date, start_week, end_week): \n",
    "    def read_delphi_vaccine_test(state_index,epiweek_date,start_week,end_week):\n",
    "    #'''\n",
    "    # The \n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask','day','state',[start_week, Epidata.range(start_week, end_week)],'*')\n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc11_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31_us=Epidata.covidcast('fb-survey','smoothed_wwearing_mask','day','nation',[start_week, Epidata.range(start_week, end_week)],'*')\n",
    "    vacc41_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc51_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc12_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17_us=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','nation',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    vacc22_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20210601, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26_us=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','nation',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    \n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc42_us=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52_us=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','nation',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']+vacc17['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']+vacc26['epidata']\n",
    "    vacc3=vacc31['epidata']#+vacc32['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']\n",
    "    \n",
    "    vacc1_us=vacc11_us['epidata']+vacc12_us['epidata']+vacc13_us['epidata']+vacc14_us['epidata']+vacc15_us['epidata']+vacc16_us['epidata']+vacc17_us['epidata']\n",
    "    vacc2_us=vacc21_us['epidata']+vacc22_us['epidata']+vacc23_us['epidata']+vacc24_us['epidata']+vacc25_us['epidata']+vacc26_us['epidata']\n",
    "    vacc3_us=vacc31_us['epidata']#+vacc32['epidata']\n",
    "    vacc4_us=vacc41_us['epidata']+vacc42_us['epidata']\n",
    "    vacc5_us=vacc51_us['epidata']+vacc52_us['epidata']\n",
    "    \n",
    "    vacc1_final = vacc1 + vacc1_us\n",
    "    vacc2_final = vacc2 + vacc2_us\n",
    "    vacc3_final = vacc3 + vacc3_us\n",
    "    vacc4_final = vacc4 + vacc4_us\n",
    "    vacc5_final = vacc5 + vacc5_us\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc17['result'], vacc17['message'], len(vacc17['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc26['result'], vacc26['message'], len(vacc26['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc31['result'], vacc31['message'], len(vacc31['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc42['result'], vacc42['message'], len(vacc42['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc52['result'], vacc52['message'], len(vacc52['epidata']))\n",
    "    #'''\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask',\n",
    "          'smoothed_wtravel_outside_state_5d','smoothed_wspent_time_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    #'''\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4_final,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5_final,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/vaccine_survey.csv\")\n",
    "    #'''\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_delphi_fb_google_survey(state_index,epiweek_date,start_week,end_week):\n",
    "    #fb_res_cli = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_cli1 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220101, Epidata.range(20220101, end_week)], '*')\n",
    "\n",
    "    fb_cli1=fb_res_cli1['epidata']+fb_res_cli2['epidata']\n",
    "    fb_cli2=fb_cli1+fb_res_cli3['epidata']\n",
    "    fb_cli3=fb_cli2+fb_res_cli4['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4=fb_cli3+fb_res_cli5['epidata'] \n",
    "    fb_cli5=fb_cli4+fb_res_cli6['epidata'] \n",
    "    fb_cli6=fb_cli5+fb_res_cli7['epidata'] \n",
    "    fb_cli7=fb_cli6+fb_res_cli8['epidata'] \n",
    "    fb_cli8=fb_cli7+fb_res_cli9['epidata']\n",
    "    fb_cli9=fb_cli8+fb_res_cli10['epidata']\n",
    "    fb_cli10=fb_cli8+fb_res_cli10['epidata']\n",
    "    fb_res_cli=fb_cli10+fb_res_cli12['epidata']\n",
    "\n",
    "    \n",
    "    #google_res_cli = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #fb_res_wli = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_wli1 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220101, Epidata.range(20211101, end_week)], '*')\n",
    "\n",
    "    \n",
    "    fb_wli1=fb_res_wli1['epidata']+fb_res_wli2['epidata']\n",
    "    fb_wli2=fb_wli1+fb_res_wli3['epidata']\n",
    "    fb_wli3=fb_wli2+fb_res_wli4['epidata']\n",
    "    fb_wli4=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_wli5=fb_wli4+fb_res_wli6['epidata']\n",
    "    fb_wli6=fb_wli5+fb_res_wli7['epidata']\n",
    "    fb_wli7=fb_wli6+fb_res_wli8['epidata']\n",
    "    fb_wli8=fb_wli7+fb_res_wli9['epidata']\n",
    "    fb_wli9=fb_wli8+fb_res_wli10['epidata']\n",
    "    fb_wli10=fb_wli9+fb_res_wli10['epidata']\n",
    "    fb_res_wli=fb_wli10+fb_res_wli12['epidata']\n",
    "    \n",
    "    \n",
    "    #google_res_wli = Epidata.covidcast('google-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #print('fb_cli1',fb_res_cli1['result'], fb_res_cli1['message'], len(fb_res_cli1['epidata']))\n",
    "    #print('fb_cli2',fb_res_cli2['result'], fb_res_cli2['message'], len(fb_res_cli2['epidata']))\n",
    "    #print('fb_cli3',fb_res_cli3['result'], fb_res_cli3['message'], len(fb_res_cli3['epidata']))\n",
    "    print('fb_cli4',fb_res_cli3['result'], fb_res_cli4['message'], len(fb_res_cli4['epidata']))\n",
    "    print('fb_cli5',fb_res_cli5['result'], fb_res_cli5['message'], len(fb_res_cli5['epidata']))\n",
    "    print('fb_cli6',fb_res_cli6['result'], fb_res_cli6['message'], len(fb_res_cli6['epidata']))\n",
    "    print('fb_cli8',fb_res_cli8['result'], fb_res_cli8['message'], len(fb_res_cli8['epidata']))\n",
    "    print('fb_cli9',fb_res_cli9['result'], fb_res_cli9['message'], len(fb_res_cli9['epidata']))\n",
    "    print('fb_cli11',fb_res_cli10['result'], fb_res_cli10['message'], len(fb_res_cli11['epidata']))\n",
    "    print('fb_cli12',fb_res_cli11['result'], fb_res_cli11['message'], len(fb_res_cli12['epidata']))\n",
    "\n",
    "    \n",
    "    #print(google_res_cli['result'], google_res_cli['message'], len(google_res_cli['epidata']))\n",
    "    \n",
    "    #print(fb_res_wli1['result'], fb_res_wli1['message'], len(fb_res_wli1['epidata']))\n",
    "    #print(fb_res_wli2['result'], fb_res_wli2['message'], len(fb_res_wli2['epidata']))\n",
    "    #print(fb_res_wli3['result'], fb_res_wli3['message'], len(fb_res_wli3['epidata']))\n",
    "    print('fb_wili4',fb_res_wli4['result'], fb_res_wli4['message'], len(fb_res_wli4['epidata']))\n",
    "    print('fb_wili5',fb_res_wli5['result'], fb_res_wli5['message'], len(fb_res_wli5['epidata']))\n",
    "    print('fb_wili6',fb_res_wli6['result'], fb_res_wli6['message'], len(fb_res_wli6['epidata']))\n",
    "    print('fb_wili8',fb_res_wli8['result'], fb_res_wli8['message'], len(fb_res_wli8['epidata']))\n",
    "    print('fb_wili9',fb_res_wli9['result'], fb_res_wli9['message'], len(fb_res_wli9['epidata']))\n",
    "    print('fb_wili11',fb_res_wli10['result'], fb_res_wli10['message'], len(fb_res_wli11['epidata']))\n",
    "    print('fb_wili12',fb_res_wli11['result'], fb_res_wli11['message'], len(fb_res_wli12['epidata']))\n",
    "\n",
    "    \n",
    "    print('fb_cli len',len(fb_res_cli))\n",
    "    print('fb_wli len',len(fb_res_wli))\n",
    "    #print(google_res_wli['result'], google_res_wli['message'], len(google_res_wli['epidata']))\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['fb_survey_wcli','fb_survey_wili']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    \n",
    "    #week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli,state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[1]]=read_survey_epidata(cols[1],google_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],fb_res_wli,state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[3]]=read_survey_epidata(cols[3],google_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/fb-google-survey.csv\")\n",
    "    \n",
    "    return week_cases,cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_delphi_fb_google_survey_test(state_index,epiweek_date,start_week,end_week):\n",
    "    fb_res_cli1 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_cli13 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220301, Epidata.range(20220301, end_week)], '*')\n",
    "\n",
    "    fb_res_cli1_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_cli13_us = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'nation', [20220301, Epidata.range(20220301, end_week)], '*')\n",
    "\n",
    "    #'''\n",
    "    fb_cli1=fb_res_cli1['epidata']+fb_res_cli2['epidata']\n",
    "    fb_cli2=fb_cli1+fb_res_cli3['epidata']\n",
    "    fb_cli3=fb_cli2+fb_res_cli4['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4=fb_cli3+fb_res_cli5['epidata'] \n",
    "    fb_cli5=fb_cli4+fb_res_cli6['epidata']\n",
    "    fb_cli6=fb_cli5+fb_res_cli7['epidata']\n",
    "    fb_cli7=fb_cli6+fb_res_cli8['epidata']\n",
    "    fb_cli8 = fb_cli7 + fb_res_cli9['epidata']\n",
    "    fb_cli9=fb_cli8 + fb_res_cli10['epidata']\n",
    "    fb_res_cli=fb_cli9+fb_res_cli11['epidata']+fb_res_cli12['epidata']+fb_res_cli13['epidata']\n",
    "    \n",
    "    fb_cli1_us = fb_res_cli1_us['epidata'] + fb_res_cli2_us['epidata']\n",
    "    fb_cli2_us=fb_cli1_us+fb_res_cli3_us['epidata']\n",
    "    fb_cli3_us=fb_cli2_us+fb_res_cli4_us['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4_us=fb_cli3_us+fb_res_cli5_us['epidata'] \n",
    "    fb_cli5_us=fb_cli4_us+fb_res_cli6_us['epidata']\n",
    "    fb_cli6_us=fb_cli5_us+fb_res_cli7_us['epidata']\n",
    "    fb_cli7_us=fb_cli6_us+fb_res_cli8_us['epidata']\n",
    "    fb_cli8_us = fb_cli7_us + fb_res_cli9_us['epidata']\n",
    "    fb_cli9_us=fb_cli8_us + fb_res_cli10_us['epidata']\n",
    "    fb_res_cli_us=fb_cli9_us+fb_res_cli11_us['epidata']+fb_res_cli12_us['epidata']+fb_res_cli13_us['epidata']\n",
    "    \n",
    "    fb_res_cli_final = fb_res_cli + fb_res_cli_us\n",
    "    #print(fb_res1['epidata'][0])\n",
    "    #'''\n",
    "    #google_res_cli = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    #google_res_cli_us = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'nation', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #fb_res_wli = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_wli1 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_wli13 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220301, Epidata.range(20220301, end_week)], '*')\n",
    "    \n",
    "    fb_res_wli1_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20220101, Epidata.range(20220101, 20220301)], '*')\n",
    "    fb_res_wli13_us = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'nation', [20220301, Epidata.range(20220101, end_week)], '*')\n",
    "    #'''\n",
    "    fb_wli1=fb_res_wli1['epidata']+fb_res_wli2['epidata']\n",
    "    fb_wli2=fb_wli1+fb_res_wli3['epidata']\n",
    "    fb_wli3=fb_wli2+fb_res_wli4['epidata']\n",
    "    fb_wli4=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_wli5=fb_wli4+fb_res_wli6['epidata']\n",
    "    fb_wli6=fb_wli5+fb_res_wli7['epidata']\n",
    "    fb_wli7=fb_wli6+fb_res_wli8['epidata']\n",
    "    fb_wli8=fb_wli7+fb_res_wli9['epidata']\n",
    "    fb_wli9=fb_wli8+fb_res_wli10['epidata']\n",
    "    #fb_res_wli=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_res_wli=fb_wli9+fb_res_wli11['epidata']+fb_res_wli12['epidata']+fb_res_wli13['epidata']\n",
    "    \n",
    "    fb_wli1_us=fb_res_wli1_us['epidata']+fb_res_wli2_us['epidata']\n",
    "    fb_wli2_us=fb_wli1_us+fb_res_wli3_us['epidata']\n",
    "    fb_wli3_us=fb_wli2_us+fb_res_wli4_us['epidata']\n",
    "    fb_wli4_us=fb_wli3_us+fb_res_wli5_us['epidata']\n",
    "    fb_wli5_us=fb_wli4_us+fb_res_wli6_us['epidata']\n",
    "    fb_wli6_us=fb_wli5_us+fb_res_wli7_us['epidata']\n",
    "    fb_wli7_us=fb_wli6_us+fb_res_wli8_us['epidata']\n",
    "    fb_wli8_us=fb_wli7_us+fb_res_wli9_us['epidata']\n",
    "    fb_wli9_us=fb_wli8_us+fb_res_wli10_us['epidata']\n",
    "    #fb_res_wli=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_res_wli_us=fb_wli9_us+fb_res_wli11_us['epidata']+fb_res_wli12_us['epidata']+fb_res_wli13_us['epidata']\n",
    "    \n",
    "    fb_res_wli_final = fb_res_wli + fb_res_wli_us\n",
    "    \n",
    "    #google_res_wli = Epidata.covidcast('google-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #print('fb_cli1',fb_res_cli1['result'], fb_res_cli1['message'], len(fb_res_cli1['epidata']))\n",
    "    #print('fb_cli2',fb_res_cli2['result'], fb_res_cli2['message'], len(fb_res_cli2['epidata']))\n",
    "    #print('fb_cli3',fb_res_cli3['result'], fb_res_cli3['message'], len(fb_res_cli3['epidata']))\n",
    "    print('fb_wcli4',fb_res_cli4['result'], fb_res_cli4['message'], len(fb_res_cli4['epidata']))\n",
    "    print('fb_wcli5',fb_res_cli9['result'], fb_res_cli9['message'], len(fb_res_cli9['epidata']))\n",
    "    print('fb_wcli6',fb_res_cli10['result'], fb_res_cli10['message'], len(fb_res_cli10['epidata']))\n",
    "    print('fb_wcli8',fb_res_cli11['result'], fb_res_cli11['message'], len(fb_res_cli11['epidata']))\n",
    "    print('fb_wcli9',fb_res_cli12['result'], fb_res_cli12['message'], len(fb_res_cli12['epidata']))\n",
    "    \n",
    "    #print('google_cli',google_res_cli['result'], google_res_cli['message'], len(google_res_cli['epidata']))\n",
    "    \n",
    "    #print(fb_res_wli['result'], fb_res_wli['message'], len(fb_res_wli['epidata']))\n",
    "    \n",
    "    #print('fb_wili1',fb_res_wli1['result'], fb_res_wli1['message'], len(fb_res_wli1['epidata']))\n",
    "    #print('fb_wili2',fb_res_wli2['result'], fb_res_wli2['message'], len(fb_res_wli2['epidata']))\n",
    "    #print('fb_wili3',fb_res_wli3['result'], fb_res_wli3['message'], len(fb_res_wli3['epidata']))\n",
    "    print('fb_wili4',fb_res_wli4['result'], fb_res_wli4['message'], len(fb_res_wli4['epidata']))\n",
    "    print('fb_wili5',fb_res_wli5['result'], fb_res_wli5['message'], len(fb_res_wli5['epidata']))\n",
    "    print('fb_wili10',fb_res_wli10['result'], fb_res_wli10['message'], len(fb_res_wli10['epidata']))\n",
    "    print('fb_wili11',fb_res_wli11['result'], fb_res_wli11['message'], len(fb_res_wli11['epidata']))\n",
    "    print('fb_wili12',fb_res_wli12['result'], fb_res_wli12['message'], len(fb_res_wli12['epidata']))\n",
    "    \n",
    "    print('fb_wcli len',len(fb_res_cli))\n",
    "    print('fb_wli len',len(fb_res_wli))\n",
    "    #'''\n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['fb_survey_wcli','fb_survey_wili']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #'''\n",
    "    #week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli_final,state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[1]]=read_survey_epidata(cols[1],google_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],fb_res_wli_final,state_index,state_names,epiweek_date)\n",
    "    #'''\n",
    "\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/fb-google-survey.csv\")\n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_fips_code(state_names,fips_path,abbv_to_code=True):\n",
    "    #if abbv_to_code=True; read fips with given state code (state_names)\n",
    "    #if abbv_to_code=False; read state code with given state name (state_names)\n",
    "    \n",
    "    fips=pd.read_csv(fips_path+\"other_data/fips_codes.csv\",delimiter=',',dtype={'state_code':str})\n",
    "    if abbv_to_code:\n",
    "        fips=fips[['state','state_code']].drop_duplicates().reset_index()\n",
    "    else:\n",
    "        fips=fips[['state','state_name']].drop_duplicates().reset_index()\n",
    "    \n",
    "    state_fips={}\n",
    "    for name in state_names:\n",
    "        if abbv_to_code:\n",
    "            if name=='X':\n",
    "                row='US'\n",
    "            else:\n",
    "                row= str(fips.loc[fips['state'] == name,'state_code'].iloc[0])   \n",
    "        else:\n",
    "            if name=='X':\n",
    "                row='X'\n",
    "            else:\n",
    "                row= fips.loc[fips['state_name'] == name,'state'].iloc[0]   \n",
    "        \n",
    "        state_fips[name]=row\n",
    "    \n",
    "    #print(state_fips)\n",
    "    return state_fips\n",
    "\n",
    "def find_date_index(dates,cur_date,date_string=1):\n",
    "    if date_string==1:\n",
    "        year,month,date=cur_date[:4],cur_date[4:6],cur_date[6:8]\n",
    "    elif date_string==2:\n",
    "        year,month,date=cur_date.split('-')\n",
    "    else:\n",
    "        month,date,year=cur_date.split('/')\n",
    "    \n",
    "    cdate=int(date)\n",
    "    cmonth=int(month)\n",
    "    year=int(year)\n",
    "    \n",
    "    if year==20 or year==21 or year==22:\n",
    "        stryear='20'+str(year)\n",
    "        year=int(stryear)\n",
    "    \n",
    "    for id in range(0,len(dates)):\n",
    "        y,m,d=dates[id].split('-')\n",
    "        wd,wm,wy=int(d),int(m),int(y)\n",
    "        if wm==cmonth and wd==cdate and wy==year:\n",
    "              return id\n",
    "    #print('week index not found:'+cur_date)\n",
    "    #print(cdate,cmonth,year)\n",
    "    return -1\n",
    "\n",
    "def get_epiweek_list(week_start,week_end,year):\n",
    "    def convert(x):\n",
    "        return Week.fromstring(str(x))\n",
    "    \n",
    "    wstart=convert(week_start)\n",
    "    wend=convert(week_end)\n",
    "    #print(wstart,wend)\n",
    "    week_edate_list=[]\n",
    "    week_list=[]\n",
    "    for week in Year(year).iterweeks():\n",
    "        date_time = week.enddate().strftime(\"%Y-%m-%d\")\n",
    "        #print(week,date_time)\n",
    "        if week>=wstart and week<=wend:\n",
    "            week_edate_list.append(date_time)\n",
    "            week_list.append(str(week))\n",
    "     \n",
    "    return week_list,week_edate_list  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_apple_mobility(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"applemobilitytrends.csv\",low_memory=False)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates=list(data.columns)\n",
    "    dates=dates[6:]\n",
    "    data = data.loc[data['region'].isin(state_names)]\n",
    "    #data=data.fillna(0)\n",
    "    #print(data.shape)\n",
    "    #week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    week_cases=np.empty((len(state_names),len(epiweek_date)))\n",
    "    week_cases[:][:]=np.nan\n",
    "    for ix,row in data.iterrows():\n",
    "        if row['transportation_type']=='driving':\n",
    "            if row['region'] in state_names:\n",
    "                state_id=state_index[dic_names_to_abbv[row['region']]] \n",
    "                for d in dates:\n",
    "                    w_idx=find_date_index(epiweek_date,d,date_string=2)\n",
    "                    if w_idx!=-1 and pd.isnull(row[d])==False:\n",
    "                        if np.isnan(week_cases[state_id][w_idx]):\n",
    "                            week_cases[state_id][w_idx]=0\n",
    "                        week_cases[state_id][w_idx]=float(row[d])\n",
    "    apple_dic={}\n",
    "    apple_dic['apple_mobility']=week_cases    \n",
    "    \n",
    "    unit_test(apple_dic,['apple_mobility'],epiweek_date,state_index,\"unit_test_date/apple.csv\")\n",
    "    \n",
    "    return apple_dic,['apple_mobility']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_mobility(inputdir,epiweek_date,end_day,MISSING_TOKEN=0):\n",
    "    data=pd.read_csv(inputdir+\"Global_Mobility_Report.csv\",low_memory=False)\n",
    "    data=data[data['country_region_code']=='US']\n",
    "    data=data.drop(data[data['sub_region_1'] == 'Hawaii'].index)\n",
    "    data= data[pd.isnull(data['sub_region_2'])]\n",
    "    data=data.drop(columns=['sub_region_2'])\n",
    "\n",
    "    state_names=data['sub_region_1'].drop_duplicates().values\n",
    "    state_names[0]='X' #changing nan to US national X\n",
    "    cols=data.columns\n",
    "    cols=list(cols[8:])\n",
    "    dic_names_to_abbv=read_fips_code(state_names,inputdir,abbv_to_code=False)\n",
    "    \n",
    "    state_index = {dic_names_to_abbv[state_names[i]]: i for i in range(len(state_names))} \n",
    "    #data[cols] = data[cols].fillna(MISSING_TOKEN)\n",
    "    num_states=len(state_names)\n",
    "    #print(cols)\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((num_states,len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((num_states,len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_day)!=0:\n",
    "            total_len=len(epiweek_date)-end_day\n",
    "            week_cases[c][:][-total_len:]=np.nan\n",
    "        '''\n",
    "    print(cols)\n",
    "    #'''\n",
    "    for ix,row in data.iterrows():\n",
    "        if type(row['sub_region_1']) is float:\n",
    "            state_id=0\n",
    "        else:\n",
    "            state_id=state_index[dic_names_to_abbv[row['sub_region_1']]]\n",
    "        week_id=find_date_index(epiweek_date,str(row['date']),date_string=2)\n",
    "        if week_id!=-1:\n",
    "            for c in cols:\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    if np.isnan(week_cases[c][state_id][week_id]):\n",
    "                            week_cases[c][state_id][week_id]=0\n",
    "                    week_cases[c][state_id][week_id]=row[c]\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/google-mobility.csv\")\n",
    "    #'''\n",
    "    \n",
    "    return week_cases,cols,state_index,dic_names_to_abbv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_vaccine_doses(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"vaccine_data_us_state_timeline.csv\")\n",
    "    #data=data.fillna(0)\n",
    "    #state_names=list(state_index.keys())\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    #cols=['people_total','people_total_2nd_dose']\n",
    "    cols=['Stage_One_Doses','Stage_Two_Doses']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    \n",
    "    \n",
    "    for ix,row in data.iterrows():\n",
    "        w_idx=find_date_index(epiweek_date,row['Date'],date_string=2)\n",
    "        if row['Province_State'] in state_names and w_idx!=-1 and row['Vaccine_Type']=='All':\n",
    "            #state_id=state_index[row['stabbr']] \n",
    "            state_id=state_index[dic_names_to_abbv[row['Province_State']]] \n",
    "            for c in cols:\n",
    "                val=None\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    val=float(row[c])\n",
    "                elif w_idx>0:\n",
    "                    val=week_cases[c][state_id][w_idx-1]               \n",
    "                week_cases[c][state_id][w_idx]=val\n",
    "                if np.isnan(week_cases[c][0][w_idx]): \n",
    "                    week_cases[c][0][w_idx] = 0\n",
    "                week_cases[c][0][w_idx]+=val\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/vaccine.csv\")\n",
    "    \n",
    "    return week_cases,cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_dex(inputdir,epiweek_date,state_index,start_day,end_day):\n",
    "    data=pd.read_csv(inputdir+\"state_dex.csv\",low_memory=False)\n",
    "    cols=[]\n",
    "    state_names=list(state_index.keys())\n",
    "    for c in data.columns:\n",
    "        if 'dex' in c:\n",
    "            cols.append(c)\n",
    "    \n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        week_cases[c][0][:]=0\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_day)!=0:\n",
    "            total_len=len(epiweek_date)-end_day\n",
    "            week_cases[c][:][-total_len:]=np.nan\n",
    "        '''\n",
    "    \n",
    "    for ix,row in data.iterrows():\n",
    "        w_idx=find_date_index(epiweek_date,row['date'],date_string=2)\n",
    "        if row['state'] in state_names and w_idx!=-1:\n",
    "            state_id=state_index[row['state']]\n",
    "            for c in cols:\n",
    "                if not math.isnan(row[c]):\n",
    "                    if np.isnan(week_cases[c][state_id][w_idx]):\n",
    "                        week_cases[c][state_id][w_idx]=0\n",
    "                    week_cases[c][state_id][w_idx]=float(row[c])\n",
    "                    week_cases[c][0][w_idx]+=float(row[c])\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/dex.csv\")\n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_county_cases(observed,county_name,state_name,population,onlypopu=False):\n",
    "    #print(state_name,county_name)\n",
    "    try:\n",
    "        row=population.loc[population['CTYNAME']==county_name]\n",
    "        row=row.loc[row['STNAME']==state_name]\n",
    "        popu=row['POPESTIMATE2019'].values\n",
    "        if len(popu)==0:\n",
    "            return -1\n",
    "        #print(row['CTYNAME'].values,popu)\n",
    "        if onlypopu:\n",
    "            return popu[0]\n",
    "        else:\n",
    "            return (observed*popu[0])/100\n",
    "    except KeyError:\n",
    "        print('county not found')\n",
    "        return -1\n",
    "    \n",
    "def read_kinsa(inputdir,epiweek_date,state_index,last_date,last_month,avg=1):\n",
    "    '''\n",
    "    data=pd.read_csv(inputdir+\"ili_case_counts_by_state.csv\",delimiter=',')\n",
    "    data=data[['region_name','state','date','observed_ili']]\n",
    "\n",
    "    county_names=data[['region_name']].drop_duplicates().reset_index()\n",
    "    county_names=county_names['region_name'].values\n",
    "    state_abbrv=pd.read_csv(inputdir+\"state_abbrv.csv\",delimiter=',')\n",
    "    '''\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases_state=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    '''\n",
    "    population_data=pd.read_csv(inputdir+\"co-est2019-alldata2.csv\",delimiter=',',encoding = \"ISO-8859-1\")\n",
    "    population=population_data[['STNAME','CTYNAME','POPESTIMATE2019']]\n",
    "    total=328239523\n",
    "    \n",
    "    county_index = {county_names[i]: i for i in range(len(county_names))} \n",
    "    \n",
    "    for index,row in data.iterrows():\n",
    "        state_id=state_index[row['state']]\n",
    "        year,month,date=row['date'].split('-')\n",
    "        #month,date,year=row['date'].split('/')\n",
    "        if int(month)>last_month:\n",
    "            continue\n",
    "        if int(month)==last_month and int(date)>last_date:\n",
    "            continue\n",
    "        week_id=find_date_index(epiweek_date,row['date'],date_string=2)\n",
    "        abbrv=state_abbrv.loc[state_abbrv['Code']==row['state']]\n",
    "        abbrv=abbrv['State'].values\n",
    "        observed=find_county_cases(row['observed_ili'],row['region_name'],abbrv[0],population)\n",
    "        if week_id!=-1:\n",
    "            week_cases_state[state_id][week_id]+=observed\n",
    "            week_cases_state[0][week_id]+=observed\n",
    "    \n",
    "    #kinsa_dic={}\n",
    "    #kinsa_dic['kinsa_cases']=week_cases_state\n",
    "    #unit_test(kinsa_dic,['kinsa_cases'],epiweek_date,state_index,\"unit_test_date/kinsa_rough.csv\")\n",
    "    print('data extrcation done, aggregating counties')\n",
    "    week_cases_state[0][:]=(week_cases_state[0][:]*100)/(avg*total)\n",
    "    for st_id in range(1,len(state_names)):\n",
    "        st_name=state_abbrv.loc[state_abbrv['Code']==state_names[st_id]]\n",
    "        st_name=st_name['State'].values\n",
    "        popu=find_county_cases(week_cases_state[st_id][0],st_name[0],st_name[0],population,onlypopu=True)\n",
    "        print(st_name[0],popu)\n",
    "        week_cases_state[st_id][:]=(week_cases_state[st_id][:]*100)/(avg*popu)\n",
    "    \n",
    "    '''\n",
    "    kinsa_dic={}\n",
    "    kinsa_dic['kinsa_cases']=week_cases_state\n",
    "    #unit_test(kinsa_dic,['kinsa_cases'],epiweek_date,state_index,\"unit_test_date/kinsa.csv\")\n",
    "    return kinsa_dic,['kinsa_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hosp_negative_total_data(inputdir,epiweek_date,state_index):\n",
    "    data_hosp=pd.read_csv(inputdir+\"COVID-19_PCR_Testing_Time_Series.csv\",delimiter=',')\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    cols=['cdc_negativeIncr','cdc_positiveIncr','cdc_total_resultsIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)),np.nan)\n",
    "    \n",
    "    for index,row in data_hosp.iterrows():\n",
    "        if row['overall_outcome']=='Negative':\n",
    "            if row['state'] in state_index.keys():\n",
    "                state_id=state_index[row['state']]\n",
    "                date=row['date']\n",
    "                week_id=find_date_index(epiweek_date,date.replace('/','-'),date_string=2)\n",
    "                week_cases[cols[0]][state_id][week_id]=float(row['new_results_reported'])\n",
    "                week_cases[cols[1]][state_id][week_id]=float(row['total_results_reported'])\n",
    "                if np.isnan(week_cases[cols[0]][0][week_id]): \n",
    "                    week_cases[cols[0]][0][week_id] = 0\n",
    "                    week_cases[cols[1]][0][week_id] = 0\n",
    "                week_cases[cols[0]][0][week_id]+=float(row['new_results_reported'])\n",
    "                week_cases[cols[1]][0][week_id]+=float(row['total_results_reported'])\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/hosp_neg_ttl.csv\") \n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hosp_negative_total_data_test(inputdir,epiweek_date,state_index):\n",
    "    data_hosp=pd.read_csv(inputdir+\"COVID-19_PCR_Testing_Time_Series.csv\",delimiter=',')\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    cols=['cdc_negativeIncr','cdc_positiveIncr', 'cdc_total_resultsIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)),np.nan)\n",
    "    \n",
    "    for index,row in data_hosp.iterrows():\n",
    "        if row['state'] in state_index.keys():\n",
    "            if row['overall_outcome']=='Negative':\n",
    "                test_type = cols[0]\n",
    "            elif row['overall_outcome'] == 'Positive': \n",
    "                test_type = cols[1]\n",
    "            else:\n",
    "                test_type = \"NA\"\n",
    "            state_id=state_index[row['state']]\n",
    "            date=row['date']\n",
    "            week_id=find_date_index(epiweek_date,date.replace('/','-'),date_string=2)\n",
    "            if test_type != \"NA\": \n",
    "#                 print(week_cases)[state_id][week_id]\n",
    "                week_cases[test_type][state_id][week_id]=float(row['new_results_reported'])\n",
    "                if np.isnan(week_cases[test_type][0][week_id]): \n",
    "                    week_cases[test_type][0][week_id] = 0\n",
    "                week_cases[test_type][0][week_id]+=float(row['new_results_reported'])\n",
    "            if np.isnan(week_cases[cols[2]][state_id][week_id]): \n",
    "                week_cases[cols[2]][state_id][week_id] = 0\n",
    "            if np.isnan(week_cases[cols[2]][0][week_id]):\n",
    "                week_cases[cols[2]][0][week_id] = 0\n",
    "            week_cases[cols[2]][state_id][week_id]+=float(row['new_results_reported'])\n",
    "            week_cases[cols[2]][0][week_id]+=float(row['new_results_reported'])\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/hosp_neg_ttl.csv\") \n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_jhu_cases(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"time_series_covid19_confirmed_US.csv\")\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates_list=list(data.columns)\n",
    "    dates_list=dates_list[11:]\n",
    "    #print(state_names)\n",
    "    #print(dates_list)\n",
    "    #not_added_rows=['Diamond Princess','Grand Princess','Northern Mariana Islands','Guam','Hawaii',\n",
    "                   # 'Puerto Rico','Virgin Islands','American Samoa']\n",
    "    not_added_rows=[]\n",
    "    week_cases={}\n",
    "    cols=['positiveIncr_cumulative','positiveIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)),np.nan)\n",
    "    \n",
    "    data2 = data.groupby(['Province_State']).sum()\n",
    "    for ix, row in data2.iterrows():\n",
    "        name=ix\n",
    "        if name in state_names:\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                        week_cases[cols[0]][state_id][w_idx] = 0\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]):\n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    #print(name,date,row[date])\n",
    "                    week_cases[cols[0]][state_id][w_idx]+=int(row[date])\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "        elif name not in not_added_rows: #if not state_names still adding them for national\n",
    "            #print('state name not added:'+name)\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]):\n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "    \n",
    "    \n",
    "    #count incidence for the national+states\n",
    "    #count incidence for the national+states\n",
    "    for state_id in range(len(state_names)):\n",
    "        if state_id == 51: \n",
    "            continue\n",
    "        index = 0\n",
    "        while np.isnan(week_cases[cols[0]][state_id][index]):\n",
    "            index += 1\n",
    "        week_cases[cols[1]][state_id][index]=int(week_cases[cols[0]][state_id][index])\n",
    "        for w_idx in range(index + 1,len(epiweek_date)):\n",
    "            if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                continue\n",
    "            week_cases[cols[1]][state_id][w_idx]=abs(int(week_cases[cols[0]][state_id][w_idx])-int(week_cases[cols[0]][state_id][w_idx-1]))         \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/jhu-cases.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hosp_cases_nat_state(data_national,data_state,epiweek_date,week_save,state_index,cols,state_error,epiweek_end):\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    \n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    #processing national cases\n",
    "    nat_id=state_index['X']\n",
    "    nat_hosp_incr=np.zeros(len(epiweek_date))\n",
    "    for index,row in data_national.iterrows():\n",
    "        week_id=find_date_index(week_save,str(row['date']),date_string=1)\n",
    "        for c in range(len(cols)): #if next1,next2 consider then do cols-4\n",
    "            week_cases[cols[c]][nat_id][week_id]+=row[cols[c]]\n",
    "    \n",
    "    #processing state cases\n",
    "    for index,row in data_state.iterrows():\n",
    "        state_id=state_index[row['states']]\n",
    "        cur_date=int(row['date'])\n",
    "        week_id=find_date_index(week_save,str(cur_date))\n",
    "        if week_id!=-1:\n",
    "            for c in range(len(cols)): #if next1,next2 consider then do cols-4\n",
    "                if cols[c]=='hospitalizedIncrease':\n",
    "                    if row['states'] in state_error:\n",
    "                        week_cases[cols[c]][state_id][week_id]=max(0,row['hospitalizedCurrently'])\n",
    "                    else:\n",
    "                        week_cases[cols[c]][state_id][week_id]=max(0,row[cols[c]])\n",
    "                        nat_hosp_incr[week_id]+=max(0,row[cols[c]])\n",
    "                else:\n",
    "                    week_cases[cols[c]][state_id][week_id]=max(0,row[cols[c]])\n",
    "    \n",
    "    #for states with no hospitalze cumulative using formula week[t]=hosp_cur[t]-(week[t-1]/2)\n",
    "    c='hospitalizedIncrease'\n",
    "    temp_data=pd.read_csv(\"unit_test/hospitalization.csv\")\n",
    "    \n",
    "    for s in state_error:\n",
    "        st_idx=state_index[s]\n",
    "        region_hosp=temp_data.loc[temp_data['region']==s]\n",
    "        hosp_weekly=region_hosp['hospitalizedIncrease'].values\n",
    "        #print('hosp_weekly:',len(hosp_weekly))\n",
    "        #print(hosp_weekly)\n",
    "        hsp_incr=np.zeros(len(epiweek_date))\n",
    "        hsp_incr[0]=week_cases[c][st_idx][0]\n",
    "        nat_hosp_incr[0]+=week_cases[c][st_idx][0]\n",
    "        for w in range(1,len(epiweek_date)):\n",
    "            cur_date=epiweek_date[w]\n",
    "            e_idx=get_epiweek_index(cur_date,'202001',epiweek_end) #change/edit to work it for year>2020\n",
    "            #hsp_incr[w]=max(0,week_cases[c][st_idx][w]-float(hsp_incr[w-1])/2) #7 days before\n",
    "            if e_idx!=-1:\n",
    "                hsp_incr[w-6:w+1]=hosp_weekly[e_idx-1]\n",
    "                nat_hosp_incr[w-6:w+1]+=(hosp_weekly[e_idx-1]/7)\n",
    "            #else:\n",
    "             #   hsp_incr[w]=hsp_incr[w-1]\n",
    "            #else:\n",
    "             #   hsp_incr[w]=max(0,week_cases[c][st_idx][w]-float(week_cases[c][st_idx][w-1])) #7 days not passed yet\n",
    "        week_cases[c][st_idx]=hsp_incr/7\n",
    "    \n",
    "    c='recovered'\n",
    "    rec_nat=np.zeros(len(epiweek_date))\n",
    "    for s in state_names:\n",
    "        st_idx=state_index[s]\n",
    "        rec_incr=np.zeros(len(epiweek_date))\n",
    "        rec_incr[0]=week_cases[c][st_idx][0]\n",
    "        rec_nat[0]+=week_cases[c][st_idx][0]\n",
    "        for w in range(1,len(epiweek_date)):\n",
    "            rec_incr[w]=week_cases[c][st_idx][w]-week_cases[c][st_idx][w-1]\n",
    "            rec_nat[w]+=max(rec_incr[w],0)\n",
    "\n",
    "        week_cases[c][st_idx]=rec_incr\n",
    "    week_cases[c][nat_id]=rec_nat\n",
    "    np.savetxt(\"unit_test_date/hos_nat_aggregated.csv\", nat_hosp_incr, fmt='%.4f')\n",
    "    return week_cases\n",
    "\n",
    "def read_hospitalization(input_national,input_state,epiweek_date,week_save,state_index,state_error,ew_end):\n",
    "    nat_data_path=\"us-daily-hospitalizations.csv\"\n",
    "    state_data_path=\"states-daily-hospitalizations.csv\"\n",
    "    nat_data=pd.read_csv(input_national+nat_data_path,delimiter=',')\n",
    "    state_data=pd.read_csv(input_state+state_data_path,delimiter=',')\n",
    "    state_data=state_data.rename(columns={\"state\": \"states\"})\n",
    "    \n",
    "    columns=['date','states','hospitalizedCurrently','onVentilatorCurrently','positiveIncrease','negativeIncrease',\n",
    "             'totalTestResultsIncrease','inIcuCurrently','recovered','deathIncrease','hospitalizedIncrease']\n",
    "    rows_to_drop=['GU','AS','HI','PR', 'MP','VI']\n",
    "    \n",
    "    nat_data_filter=nat_data[columns]\n",
    "    state_data_filter=state_data[columns]\n",
    "    \n",
    "    nat_data_filter=nat_data_filter.fillna(0)\n",
    "    state_data_filter=state_data_filter.fillna(0)\n",
    "    \n",
    "    index_to_remove=[]\n",
    "    for index, row in state_data_filter.iterrows():\n",
    "        #print(row['Province/State'])\n",
    "        if row['states'] in rows_to_drop:\n",
    "            index_to_remove.append(index)\n",
    "\n",
    "    state_data_filter=state_data_filter.drop(index=index_to_remove).reset_index()\n",
    "    #print(state_data_filter['states'].drop_duplicates())\n",
    "    #cols_for_hosp=['positiveIncrease','negativeIncrease','totalTestResultsIncrease','onVentilatorCurrently',\n",
    "     #              'inIcuCurrently','deathIncrease','recovered','hospitalizedIncrease','h_next1','h_next2',\n",
    "      #             'd_next1','d_next2']\n",
    "    cols_for_hosp=['positiveIncrease','negativeIncrease','totalTestResultsIncrease','onVentilatorCurrently',\n",
    "                   'inIcuCurrently','deathIncrease','recovered','hospitalizedIncrease']\n",
    "    \n",
    "    week_cases=hosp_cases_nat_state(nat_data_filter,state_data_filter,epiweek_date,week_save,state_index,cols_for_hosp,state_error,ew_end)\n",
    "    \n",
    "    unit_test(week_cases,cols_for_hosp,epiweek_date,state_index,\"unit_test_date/hospitalization_date.csv\")\n",
    "    return week_cases,cols_for_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_jhu_death(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"time_series_covid19_deaths_US.csv\")\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates_list=list(data.columns)\n",
    "    dates_list=dates_list[12:]\n",
    "    #print(state_names)\n",
    "    #print(dates_list)\n",
    "    #not_added_rows=['Diamond Princess','Grand Princess','Northern Mariana Islands','Guam','Hawaii',\n",
    "                   # 'Puerto Rico','Virgin Islands','American Samoa']\n",
    "    not_added_rows=[]\n",
    "    week_cases={}\n",
    "    cols=['death_jhu_cumulative','death_jhu_incidence']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full((len(state_names),len(epiweek_date)), np.nan)\n",
    "    \n",
    "    data2 = data.groupby(['Province_State']).sum()\n",
    "    for ix, row in data2.iterrows():\n",
    "        name=ix\n",
    "        if name in state_names:\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    #print(name,date,row[date])\n",
    "                    if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                         week_cases[cols[0]][state_id][w_idx] = 0\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]): \n",
    "                         week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][state_id][w_idx]+=int(row[date])\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "        elif name not in not_added_rows: #if not state_names still adding them for national\n",
    "            #print('state name not added:'+name)\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    if np.isnan(week_cases[cols[0]][0][w_idx]): \n",
    "                        week_cases[cols[0]][0][w_idx] = 0\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "    \n",
    "    \n",
    "    #count incidence for the national+states\n",
    "    for state_id in range(len(state_names)):\n",
    "        if state_id == 51: \n",
    "            continue\n",
    "        index = 0\n",
    "        while np.isnan(week_cases[cols[0]][state_id][index]):\n",
    "            index += 1\n",
    "        week_cases[cols[1]][state_id][index]=int(week_cases[cols[0]][state_id][index])\n",
    "        for w_idx in range(index+1,len(epiweek_date)):\n",
    "            if np.isnan(week_cases[cols[0]][state_id][w_idx]): \n",
    "                continue\n",
    "            week_cases[cols[1]][state_id][w_idx]=abs(int(week_cases[cols[0]][state_id][w_idx])-int(week_cases[cols[0]][state_id][w_idx-1]))\n",
    "             \n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/jhu-death.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_covidnet(data_covidnet,week_len,start,end,step,weekly_rate,region): #region='X'\n",
    "    covid=np.empty(week_len)\n",
    "    covid[:]=np.nan\n",
    "    data_f=data_covidnet.loc[data_covidnet['CATCHMENT']==region]\n",
    "    #data_f=data[data['AGE CATEGORY']=='Overall'].reset_index()\n",
    "    for index,row in data_f.iterrows():\n",
    "        mmr_week=int(row['MMWR-WEEK'])\n",
    "        year=int(row['MMWR-YEAR'])\n",
    "        if row['AGE CATEGORY']=='Overall' and row['SEX']=='Overall' and row['RACE']=='Overall':\n",
    "            if year==2020:\n",
    "                if mmr_week>=start and mmr_week<=53:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "            elif year==2021:\n",
    "                if mmr_week<=52:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "            elif year==2022:\n",
    "                if mmr_week<=end:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[95+step+mmr_week]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[95+step+mmr_week]=float(row[weekly_rate])\n",
    "    return covid\n",
    "\n",
    "def read_covidnet_data(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week,step,num_epiweek):\n",
    "    #data_covidnet=pd.read_csv(inputdir+\"COVID-NET_Processed.csv\",delimiter=',')\n",
    "    if date.today().weekday() != 6:\n",
    "        week_num = (date.today()-timedelta(days=2)).strftime(\"%U\")\n",
    "        year_week_num = \"2022\" + week_num\n",
    "    else:\n",
    "        week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "        year_week_num = \"2022\" + week_num\n",
    "        \n",
    "    file_name = \"COVID-NET_v\"+year_week_num + \".csv\"\n",
    "    data_covidnet=pd.read_csv(file_name,delimiter=',')\n",
    "    columns=list(data_covidnet.columns)\n",
    "    \n",
    "    dic_names_to_abbv['Entire Network']='X'\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    #state_names=list(state_index.keys())\n",
    "    #print(columns)\n",
    "    weekly_rate='WEEKLY RATE'\n",
    "    if 'WEEKLY RATE' in columns:\n",
    "        data_covidnet=data_covidnet[['CATCHMENT','NETWORK','MMWR-YEAR','MMWR-WEEK','AGE CATEGORY','SEX','RACE','WEEKLY RATE']]\n",
    "    else:\n",
    "        data_covidnet=data_covidnet[['CATCHMENT','NETWORK','MMWR-YEAR','MMWR-WEEK','AGE CATEGORY','SEX','RACE','WEEKLY RATE ']]\n",
    "        weekly_rate='WEEKLY RATE '\n",
    "    \n",
    "    week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #for st in state_index.keys():\n",
    "    for state in state_names:\n",
    "        if state=='United States' or state=='X':\n",
    "            continue\n",
    "        st=dic_names_to_abbv[state]\n",
    "        #print(state,state_index[st])\n",
    "        covidnet_week=read_covidnet(data_covidnet,num_epiweek,start_week,end_week,step,weekly_rate,region=state)\n",
    "        for week in range(0,num_epiweek):\n",
    "            start,end=map_epiweek_to_date(week+1,epiweek_date,num_epiweek,week_string=False,year=2022)\n",
    "            week_cases[state_index[st]][start:end+1]=[covidnet_week[week]]*(end-start+1)\n",
    "    \n",
    "    covidnet_dic={}\n",
    "    covidnet_dic['covidnet']=week_cases\n",
    "    unit_test(covidnet_dic,['covidnet'],epiweek_date,state_index,\"unit_test_date/covidnet.csv\")\n",
    "    return covidnet_dic,['covidnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_epiweek_index(cur_date,start_week,end_week,year=2022):\n",
    "    #print('epiweek_index',cur_date)\n",
    "    week_num = date.today().strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    epiweek1,epiweek_date1=get_epiweek_list(start_week,'202053',2020)\n",
    "    epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "    epiweek3,epiweek_date3=get_epiweek_list('202201',year_week_num,2022)\n",
    "    #epiweek=epiweek1+epiweek2\n",
    "    #epiweek_date=epiweek_date1+epiweek_date2\n",
    "    for d in range(0,len(epiweek_date1)):\n",
    "        if cur_date==epiweek_date1[d]:\n",
    "            return int(epiweek1[d][4:])\n",
    "    \n",
    "    for d in range(0,len(epiweek_date2)):\n",
    "        if cur_date==epiweek_date2[d]:\n",
    "            return int(epiweek2[d][4:])+53\n",
    "    for d in range(0, len(epiweek_date3)):\n",
    "        if cur_date==epiweek_date3[d]:\n",
    "            return int(epiweek3[d][4:])+105\n",
    "    \n",
    "    return -1\n",
    "            \n",
    "def map_epiweek_to_date(week,epiweek_date,num_epiweek,week_string=True,year=2022):\n",
    "    if week_string:\n",
    "        stryear=int(week[:4])\n",
    "        week=int(week[4:])\n",
    "        if stryear>2020:\n",
    "            week+=53\n",
    "    if year==2020:\n",
    "        end_week=str(year)+str(num_epiweek)\n",
    "    else:\n",
    "        pos=num_epiweek%106+1\n",
    "        end_week=str(year)+str(pos)\n",
    "    #start_week=str(year)+'01'\n",
    "    start_week='202001'\n",
    "    epiweek1, week_dates1=get_epiweek_list('202001','202053',2020)\n",
    "    epiweek2,week_dates2=[],[]\n",
    "    epiweek2, week_dates2=get_epiweek_list('202101','202152',2021)\n",
    "    epiweek3, week_dates3=get_epiweek_list('202201', end_week, year)\n",
    "    \n",
    "    epiweek=epiweek1+epiweek2+epiweek3\n",
    "    week_dates=week_dates1+week_dates2+week_dates3\n",
    "    if week-2<0:\n",
    "        #week_date_start_str=str(year)+'-01-01' #2020-01-01, 2021-01-01\n",
    "        week_date_start_str='2020-01-01' #2020-01-01, 2021-01-01\n",
    "        week_date_start_obj = datetime.strptime(week_date_start_str, '%Y-%m-%d')\n",
    "    else:\n",
    "        week_date_start_str=week_dates[week-2]\n",
    "        week_date_start_obj = datetime.strptime(week_date_start_str, '%Y-%m-%d')+timedelta(days=1)\n",
    "    \n",
    "    week_date_end_str=week_dates[week-1]\n",
    "    start_idx=-1\n",
    "    end_idx=-1\n",
    "    \n",
    "    week_date_end_obj = datetime.strptime(week_date_end_str, '%Y-%m-%d')\n",
    "    \n",
    "    for d in range(0,len(epiweek_date)):\n",
    "        cur_date_obj=datetime.strptime(epiweek_date[d], '%Y-%m-%d')\n",
    "        if cur_date_obj>=week_date_start_obj and cur_date_obj<week_date_end_obj and start_idx==-1:\n",
    "            start_idx=d\n",
    "        elif cur_date_obj==week_date_end_obj:\n",
    "            end_idx=d\n",
    "    \n",
    "    return start_idx,end_idx \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_iqvia(inputdir,epiweek_date,state_index,num_epiweek):\n",
    "    data=pd.read_csv(inputdir+\"iqvia_Processed.csv\")\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "\n",
    "    cols=list(data.columns)\n",
    "    cols=cols[4:]\n",
    "    print(cols)\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        state_id=state_index[row['region']]\n",
    "        week=str(row['epiweek'])\n",
    "        start,end=map_epiweek_to_date(week,epiweek_date,num_epiweek)\n",
    "        for c in cols:\n",
    "            #week_cases[c][state_id][start_week-10:end_week-start_week]=group[c]\n",
    "            week_cases[c][state_id][start:end+1]=float(row[c])\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/iqvia.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_cdc_hosp(inputdir,epiweek_date,state_index,start_day,end_day):\n",
    "    data=pd.read_csv(inputdir+\"COVID-19_Reported_Timeseries.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"reported_hospital_timeseries.csv\")\n",
    "    \n",
    "    #data=data.fillna(0)\n",
    "    state_index['PR'] = 51\n",
    "    state_index['VI'] = 52\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    #cols=list(data.columns)\n",
    "    #cols=cols[2:]\n",
    "    cols=['cdc_hospitalized']\n",
    "    \n",
    "    cols_to_check=['previous_day_admission_adult_covid_confirmed','previous_day_admission_pediatric_covid_confirmed']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    week_cases[c][:][:]=np.nan\n",
    "    week_cases[c][0][:]=0\n",
    "    for index,row in data.iterrows():\n",
    "        if row['state'] in state_index.keys():\n",
    "            state_id=state_index[row['state']]\n",
    "        else:\n",
    "            continue\n",
    "        date=str(row['date'])\n",
    "        week_id=find_date_index(epiweek_date,date.replace('/','-'),date_string=2)\n",
    "        if week_id!=-1:\n",
    "            ttl=0\n",
    "            flag_is_not_nan=False\n",
    "            for c in cols_to_check: \n",
    "                if pd.isnull(row[c])==False:\n",
    "                    ttl+=float(row[c])\n",
    "                    flag_is_not_nan=True\n",
    "            if flag_is_not_nan:\n",
    "                week_cases[cols[0]][state_id][week_id]=ttl\n",
    "                week_cases[cols[0]][0][week_id]+=ttl\n",
    "                    \n",
    "    \n",
    "    '''\n",
    "    missing_days=len(epiweek_date)-end_day\n",
    "    for s in range(len(state_names)):\n",
    "        for c in cols:\n",
    "            week_cases[c][s][-missing_days:]=np.nan #considering data 2 weeks lag\n",
    "    '''\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/cdc_hosp.csv\") \n",
    "    del state_index['PR']\n",
    "    del state_index['VI']\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_excess_death(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week,num_epiweek,this_month,this_year=2020):\n",
    "    data=pd.read_csv(inputdir+\"Excess_Deaths_COVID-19.csv\")\n",
    "    #cols_death=['Observed Number','Excess Higher Estimate']\n",
    "    cols_death=['Observed Number','Excess Estimate'] \n",
    "#     out_cols = ['Observed Numberv2','Excess Estimatev2']\n",
    "    cols=['Week Ending Date','State']+cols_death\n",
    "    data=data[cols]\n",
    "    data[cols]=data[cols].fillna(0)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    week_cases={}\n",
    "    for c in cols_death:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        week=row['Week Ending Date']\n",
    "        y,m,d=week.split('-')\n",
    "        cm,cd,cy=int(m),int(d),int(y)\n",
    "        name=row['State']\n",
    "        if name in state_names and cy>=this_year:# and cm<=this_month:\n",
    "            cur_date=y+'-'+m+'-'+d\n",
    "            week=get_epiweek_index(cur_date,start_week,end_week)\n",
    "            start,end=map_epiweek_to_date(week,epiweek_date,num_epiweek,week_string=False,year=2022)\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            #print(week,start,end)\n",
    "            for c in cols_death:\n",
    "                week_cases[c][state_id][start:end+1]+=int(row[c])\n",
    "                week_cases[c][0][start:end+1]=week_cases[c][0][start:end+1]+int(row[c])\n",
    "     \n",
    "    ##ADD NAN VALUES TO THE LAST 1 WEEK\n",
    "    for s in range(len(state_names)):\n",
    "        for c in cols_death:\n",
    "            week_cases[c][s]/=3\n",
    "            week_cases[c][s][-14:]=np.nan\n",
    "    \n",
    "    \n",
    "    unit_test(week_cases,cols_death,epiweek_date,state_index,\"unit_test_date/excess-death.csv\")\n",
    "    return week_cases,cols_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_emergency(inputdir,epiweek_date,state_index,start_week,end_week):\n",
    "    #data=pd.read_csv(inputdir+\"emergency-visits.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"covid-like-illness.csv\")\n",
    "    data=pd.read_csv(inputdir+\"covid-like-illness-v202040.csv\")\n",
    "    cols=['Number of Facilities Reporting','CLI Percent of Total Visits']\n",
    "    data=data[data['week']>=start_week]\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    \n",
    "    \n",
    "    region_map={'X':0,'Region 1':1,'Region 2':2, 'Region 3':3,'Region 4':4,'Region 5':5,'Region 6':6,\n",
    "               'Region 7':7,'Region 8':8,'Region 9':9,'Region 10':10}\n",
    "\n",
    "    file = open(inputdir+\"other_data/hhs_regions_abbv.txt\", 'r') \n",
    "    Lines = file.readlines() \n",
    "    state_hhs_map={}\n",
    "    #### mapping each state to a hhs region ###\n",
    "    state_hhs_map[0]=0 # setting national value\n",
    "    for line in Lines:\n",
    "        regions=line.strip().split(',')\n",
    "        reg_id=int(regions[0])\n",
    "        for j in range(1,len(regions)):\n",
    "            if state_index.get(regions[j],-1)!=-1:\n",
    "                state_id=state_index[regions[j]]\n",
    "                state_hhs_map[state_id]=reg_id\n",
    "            else:\n",
    "                print('state not found '+regions[j])\n",
    "    #print(state_hhs_map)\n",
    "    num_epiweeks=end_week-start_week+1\n",
    "    for ix,row in data.iterrows():\n",
    "        reg_id=region_map[row['region']]\n",
    "        week=str(row['Week'])\n",
    "        year=int(week[:4])\n",
    "        w_idx=int(week[4:])\n",
    "        for st in range(len(state_names)):\n",
    "            if state_hhs_map[st]==reg_id:\n",
    "                for c in cols:\n",
    "                    reporting=row[c]\n",
    "                    if c=='Number of Facilities Reporting':\n",
    "                        reporting=int(reporting.replace(',',''))\n",
    "                    #print(state_names[st],w_idx,reporting)\n",
    "                    start,end=map_epiweek_to_date(week,epiweek_date,num_epiweeks)\n",
    "                    week_cases[c][st][start:end+1]=reporting\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/emergency.csv\")\n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def merge_data_state(mobility,apple,cdc_hosp,vacc,covidnet,excess,jhu,survey,jhu_case,hosp_new_res,\n",
    "                     cols_m,cols_a,cols_cdc,cols_vacc,cols_net,cols_excess,\n",
    "                     cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res, symptom, cols_symptom,\n",
    "                     state_fips,epiweek,epiweek_date,region_names,outputdir,outfilename):\n",
    "    \n",
    "    cols_common=['date','epiweek','region','fips']\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_k+cols_q+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_vacc+cols_net+cols_excess+cols_jhu+cols_survey+cols_jhu_case+cols_hosp_new_res\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_d+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    print(all_cols)\n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        temp_data['fips']=[state_fips[region_names[reg]]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility[c][reg][:]\n",
    "        for c in cols_a:\n",
    "            temp_data[c]=apple[c][reg][:]\n",
    "        for c in cols_cdc:\n",
    "            if reg == 0: \n",
    "                cdc_hosp[c][reg][0:96] = np.nan\n",
    "                print(cdc_hosp[c][reg][0:96])\n",
    "            temp_data[c]=cdc_hosp[c][reg][:]   \n",
    "        #for c in cols_d:\n",
    "        #    temp_data[c]=dex[c][reg][:]\n",
    "        for c in cols_vacc:\n",
    "            temp_data[c]=vacc[c][reg][:]\n",
    "        #for c in cols_vac_delphi:\n",
    "        #    temp_data[c]=vac_delphi[c][reg][:]\n",
    "        #for c in cols_k:\n",
    "        #    temp_data[c]=kinsa[c][reg][:]\n",
    "        #for c in cols_q:\n",
    "         #   temp_data[c]=iqvia[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet[c][reg][:]\n",
    "        #for c in cols_hosp:\n",
    "        #    temp_data[c]=hosp[c][reg][:]\n",
    "        for c in cols_excess:\n",
    "            temp_data[c]=excess[c][reg][:]\n",
    "        for c in cols_jhu:\n",
    "            temp_data[c]=jhu[c][reg][:]\n",
    "        for c in cols_survey:\n",
    "            temp_data[c]=survey[c][reg][:]\n",
    "        #for c in cols_v:\n",
    "            #temp_data[c]=em_visit[c][reg][:]\n",
    "        for c in cols_jhu_case:\n",
    "            temp_data[c]=jhu_case[c][reg][:]\n",
    "        for c in cols_hosp_new_res:\n",
    "            temp_data[c]=hosp_new_res[c][reg][:]\n",
    "        for c in cols_symptom:\n",
    "            temp_data[c] = symptom[c][reg][:]\n",
    "        \n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    \n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_state_test(mobility,cols_m,state_fips,epiweek,epiweek_date,region_names,outputdir,outfilename):\n",
    "    cols_common=['date','epiweek','region','fips']\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_k+cols_q+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    all_cols=cols_common+cols_m\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_d+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    print(all_cols)\n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        temp_data['fips']=[state_fips[region_names[reg]]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility[c][reg][:]\n",
    "        \"\"\"    \n",
    "        for c in cols_a:\n",
    "            temp_data[c]=apple[c][reg][:]\n",
    "        for c in cols_cdc:\n",
    "            temp_data[c]=cdc_hosp[c][reg][:]\n",
    "        for c in cols_d:\n",
    "            temp_data[c]=dex[c][reg][:]\n",
    "        for c in cols_vacc:\n",
    "            temp_data[c]=vacc[c][reg][:]\n",
    "        for c in cols_vac_delphi:\n",
    "            temp_data[c]=vac_delphi[c][reg][:]\n",
    "        for c in cols_k:\n",
    "            temp_data[c]=kinsa[c][reg][:]\n",
    "        #for c in cols_q:\n",
    "         #   temp_data[c]=iqvia[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet[c][reg][:]\n",
    "        for c in cols_hosp:\n",
    "            temp_data[c]=hosp[c][reg][:]\n",
    "        for c in cols_excess:\n",
    "            temp_data[c]=excess[c][reg][:]\n",
    "        for c in cols_jhu:\n",
    "            temp_data[c]=jhu[c][reg][:]\n",
    "        for c in cols_survey:\n",
    "            temp_data[c]=survey[c][reg][:]\n",
    "        #for c in cols_v:\n",
    "            #temp_data[c]=em_visit[c][reg][:]\n",
    "        for c in cols_jhu_case:\n",
    "            temp_data[c]=jhu_case[c][reg][:]\n",
    "        for c in cols_hosp_new_res:\n",
    "            temp_data[c]=hosp_new_res[c][reg][:]\n",
    "        \"\"\"\n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    \n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_google_symptoms(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv('https://storage.googleapis.com/covid19-open-data/v3/google-search-trends.csv')\n",
    "    print('data')\n",
    "    arr = data['location_key'].unique()\n",
    "    arr = [i for i in arr if (i.count('_') == 1 and 'US' in i and 'HI' not in i) or i == 'US']\n",
    "    columns = ['date','location_key','search_trends_fever','search_trends_low_grade_fever', 'search_trends_cough', 'search_trends_sore_throat',\n",
    "        'search_trends_headache', 'search_trends_fatigue', 'search_trends_vomiting', 'search_trends_diarrhea', 'search_trends_shortness_of_breath',\n",
    "        'search_trends_chest_pain', 'search_trends_dizziness', 'search_trends_confusion', 'search_trends_generalized_tonicclonic_seizure','search_trends_weakness']\n",
    "    data = data[columns]\n",
    "    data = data[data['location_key'].isin(arr)]\n",
    "    data['location_key'] = data['location_key'].apply(lambda x: \"X\" if (x == \"US\") else x[3:5])\n",
    "    print(data)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    num_states = len(state_names)\n",
    "    #print(cols)\n",
    "    cols = columns[2:]\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((num_states,len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((num_states,len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_day)!=0:\n",
    "            total_len=len(epiweek_date)-end_day\n",
    "            week_cases[c][:][-total_len:]=np.nan\n",
    "        '''\n",
    "    print(cols)\n",
    "    #'''\n",
    "    for ix,row in data.iterrows():\n",
    "        state_id=state_index[row['location_key']]\n",
    "        week_id=find_date_index(epiweek_date,str(row['date']),date_string=2)\n",
    "        if week_id!=-1:\n",
    "            for c in cols:\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    if np.isnan(week_cases[c][state_id][week_id]):\n",
    "                            week_cases[c][state_id][week_id]=0\n",
    "                    week_cases[c][state_id][week_id]=row[c]\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/google-symptoms.csv\")\n",
    "    #'''\n",
    "    \n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202244\n",
      "1035\n",
      "google mobility\n",
      "2022-10-28\n",
      "['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52785, 8)\n",
      "output file written\n",
      "google symptoms\n",
      "data\n",
      "               date location_key  search_trends_fever  \\\n",
      "12818    2020-01-01            X                 4.62   \n",
      "12819    2020-01-02            X                 4.74   \n",
      "12820    2020-01-03            X                 4.68   \n",
      "12821    2020-01-04            X                 4.69   \n",
      "12822    2020-01-05            X                 4.60   \n",
      "...             ...          ...                  ...   \n",
      "2693518  2022-09-08           WY                 3.06   \n",
      "2693519  2022-09-09           WY                 2.87   \n",
      "2693520  2022-09-10           WY                 2.84   \n",
      "2693521  2022-09-11           WY                 2.87   \n",
      "2693522  2022-09-12           WY                 2.38   \n",
      "\n",
      "         search_trends_low_grade_fever  search_trends_cough  \\\n",
      "12818                             0.22                 9.75   \n",
      "12819                             0.22                10.30   \n",
      "12820                             0.23                10.15   \n",
      "12821                             0.23                 9.97   \n",
      "12822                             0.22                 9.49   \n",
      "...                                ...                  ...   \n",
      "2693518                            NaN                 4.04   \n",
      "2693519                            NaN                 4.38   \n",
      "2693520                            NaN                 4.19   \n",
      "2693521                            NaN                 4.27   \n",
      "2693522                            NaN                 4.13   \n",
      "\n",
      "         search_trends_sore_throat  search_trends_headache  \\\n",
      "12818                         2.81                    4.94   \n",
      "12819                         2.87                    4.39   \n",
      "12820                         2.84                    4.27   \n",
      "12821                         2.79                    4.39   \n",
      "12822                         2.66                    4.30   \n",
      "...                            ...                     ...   \n",
      "2693518                       1.41                    3.21   \n",
      "2693519                       1.75                    3.04   \n",
      "2693520                       1.47                    3.39   \n",
      "2693521                       1.86                    3.39   \n",
      "2693522                       2.02                    3.47   \n",
      "\n",
      "         search_trends_fatigue  search_trends_vomiting  \\\n",
      "12818                     4.24                    4.00   \n",
      "12819                     4.56                    3.46   \n",
      "12820                     4.42                    3.28   \n",
      "12821                     4.37                    3.26   \n",
      "12822                     4.51                    3.22   \n",
      "...                        ...                     ...   \n",
      "2693518                   4.50                    2.29   \n",
      "2693519                   3.29                    2.38   \n",
      "2693520                   3.22                    2.04   \n",
      "2693521                   4.00                    1.96   \n",
      "2693522                   4.12                    2.76   \n",
      "\n",
      "         search_trends_diarrhea  search_trends_shortness_of_breath  \\\n",
      "12818                      4.48                               0.71   \n",
      "12819                      4.33                               0.79   \n",
      "12820                      4.25                               0.75   \n",
      "12821                      4.34                               0.71   \n",
      "12822                      4.29                               0.70   \n",
      "...                         ...                                ...   \n",
      "2693518                    3.27                               0.71   \n",
      "2693519                    3.52                               0.51   \n",
      "2693520                    3.22                               0.82   \n",
      "2693521                    3.24                               0.69   \n",
      "2693522                    3.91                               0.71   \n",
      "\n",
      "         search_trends_chest_pain  search_trends_dizziness  \\\n",
      "12818                        1.37                     1.88   \n",
      "12819                        1.48                     1.63   \n",
      "12820                        1.42                     1.57   \n",
      "12821                        1.41                     1.58   \n",
      "12822                        1.37                     1.58   \n",
      "...                           ...                      ...   \n",
      "2693518                      1.10                     1.63   \n",
      "2693519                      1.10                     1.34   \n",
      "2693520                      1.07                     1.51   \n",
      "2693521                      1.08                     1.95   \n",
      "2693522                      1.26                     1.59   \n",
      "\n",
      "         search_trends_confusion  \\\n",
      "12818                       0.21   \n",
      "12819                       0.22   \n",
      "12820                       0.23   \n",
      "12821                       0.21   \n",
      "12822                       0.21   \n",
      "...                          ...   \n",
      "2693518                      NaN   \n",
      "2693519                      NaN   \n",
      "2693520                      NaN   \n",
      "2693521                      NaN   \n",
      "2693522                      NaN   \n",
      "\n",
      "         search_trends_generalized_tonicclonic_seizure  \\\n",
      "12818                                               NaN   \n",
      "12819                                               NaN   \n",
      "12820                                               NaN   \n",
      "12821                                               NaN   \n",
      "12822                                               NaN   \n",
      "...                                                 ...   \n",
      "2693518                                             NaN   \n",
      "2693519                                             NaN   \n",
      "2693520                                             NaN   \n",
      "2693521                                             NaN   \n",
      "2693522                                             NaN   \n",
      "\n",
      "         search_trends_weakness  \n",
      "12818                      0.32  \n",
      "12819                      0.37  \n",
      "12820                      0.36  \n",
      "12821                      0.34  \n",
      "12822                      0.34  \n",
      "...                         ...  \n",
      "2693518                    0.62  \n",
      "2693519                     NaN  \n",
      "2693520                     NaN  \n",
      "2693521                     NaN  \n",
      "2693522                     NaN  \n",
      "\n",
      "[50286 rows x 16 columns]\n",
      "['search_trends_fever', 'search_trends_low_grade_fever', 'search_trends_cough', 'search_trends_sore_throat', 'search_trends_headache', 'search_trends_fatigue', 'search_trends_vomiting', 'search_trends_diarrhea', 'search_trends_shortness_of_breath', 'search_trends_chest_pain', 'search_trends_dizziness', 'search_trends_confusion', 'search_trends_generalized_tonicclonic_seizure', 'search_trends_weakness']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52785, 16)\n",
      "output file written\n",
      "['search_trends_fever', 'search_trends_low_grade_fever', 'search_trends_cough', 'search_trends_sore_throat', 'search_trends_headache', 'search_trends_fatigue', 'search_trends_vomiting', 'search_trends_diarrhea', 'search_trends_shortness_of_breath', 'search_trends_chest_pain', 'search_trends_dizziness', 'search_trends_confusion', 'search_trends_generalized_tonicclonic_seizure', 'search_trends_weakness']\n",
      "JHU-cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1109535848.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  data2 = data.groupby(['Province_State']).sum()\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52785, 4)\n",
      "output file written\n",
      "hosp-neg-total result\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n",
      "/var/folders/8d/yc9nnvjx07j3ds1jzwshhn580000gn/T/ipykernel_35905/1379066168.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_data=out_data.append(temp_data,ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52785, 5)\n",
      "output file written\n",
      "FB-GOOGLE\n",
      "20210301\n",
      "20210501\n",
      "20210501\n",
      "20210701\n",
      "20210701\n",
      "20210901\n",
      "20210901\n",
      "20211101\n",
      "20211101\n",
      "20220101\n",
      "20220101\n",
      "20220301\n",
      "20220301\n",
      "20220501\n",
      "20220501\n",
      "20220701\n",
      "20220701\n",
      "20220901\n",
      "20220901\n",
      "20221101\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'epidata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m start_week2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20200307\u001b[39m\n\u001b[1;32m     66\u001b[0m end_week\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(week_end_string) \u001b[38;5;66;03m#yyyymmdd\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m survey, cols_survey \u001b[38;5;241m=\u001b[39m \u001b[43mread_fb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepiweek_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_week\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_week\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_week2\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#survey,cols_survey=read_delphi_fb_google_survey_test(state_index,epiweek_date,start_week,end_week)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mprint('delphi vaccine survey')\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03mstart_week=20210101\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03mvacc_delphi,cols_vacc_delphi=read_delphi_vaccine_test_two(state_index,epiweek_date,start_week,end_week)\"\"\"\u001b[39;00m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mread_fb\u001b[0;34m(state_index, epiweek_date, start_week, end_week, start_week2)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vacc_final)):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vacc[i])): \n\u001b[0;32m---> 45\u001b[0m         vacc_final[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mvacc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepidata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     47\u001b[0m fb_survey \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m fb_survey\u001b[38;5;241m.\u001b[39mappend([])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'epidata'"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path=\"./\"\n",
    "kinsa_path= \"./\"\n",
    "\n",
    "if date.today().weekday() != 6:\n",
    "    week_num = (date.today()-timedelta(2)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\"  + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() +timedelta((5-date.today().weekday()) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_date = (date.today() - timedelta(2)).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() + timedelta((5-date.today().weekday()) % 7 )).strftime('%Y%m%d')\n",
    "    week_end_string = (date.today() - timedelta(2)).strftime('%Y%m%d')\n",
    "else:\n",
    "    week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() -timedelta((date.today().weekday()-5) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() - timedelta((date.today().weekday()-5) % 7 )).strftime('%Y%m%d')\n",
    "\n",
    "epiweek_date_obj=pd.date_range(start='2020-01-01', end=week_end_date) #update date as this epiweek yyyy-mm-dd\n",
    "epiweek_date=[date_obj.strftime('%Y-%m-%d') for date_obj in epiweek_date_obj]\n",
    "week_save=[date_obj.strftime('%Y-%m-%d') for date_obj in epiweek_date_obj]\n",
    "\n",
    "num_epiweek=105+int(week_num) #total epiweeks for 2022: 53+52+current_epiweek#update total num of epiweeks\n",
    "\n",
    "epiweek_list1,epiweek_date_list1=get_epiweek_list('202001','202053',2020) #update end epiweek as current epiweek\n",
    "epiweek_list2,epiweek_date_list2=get_epiweek_list('202101','202152',2021) #update end epiweek as current epiweek\n",
    "epiweek_list3,epiweek_date_list3=get_epiweek_list('202201',year_week_num,2022)\n",
    "\n",
    "epiweek_list=epiweek_list1+epiweek_list2+epiweek_list3\n",
    "epiweek_date_list=epiweek_date_list1+epiweek_date_list2+epiweek_date_list3\n",
    "\n",
    "epiweek=np.array([0 for i in range(len(epiweek_date))])\n",
    "#print(len(epiweek))\n",
    "for week in range(1,num_epiweek+1):\n",
    "    st,ed=map_epiweek_to_date(week,epiweek_date,num_epiweek,week_string=False)\n",
    "    #print(week,st,ed)\n",
    "    epiweek[st:ed+1]=epiweek_list[week-1]\n",
    "\n",
    "print(len(epiweek_date))\n",
    "#print(epiweek)\n",
    "#print(epiweek_date)\n",
    "#print(week_save)\n",
    "\n",
    "print('google mobility')\n",
    "end_day=len(epiweek_date)-4 #usually m=ewdate-4, since current data does not have value for this week\n",
    "print(epiweek_date[end_day])\n",
    "mobility_state,cols_m,state_index,dic_names_to_abbv=read_mobility(data_path,epiweek_date,end_day)\n",
    "dic_names_to_abbv['United States']='X'\n",
    "\n",
    "\n",
    "print('google symptoms')\n",
    "symptom, cols_symptom = read_google_symptoms(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "print(cols_symptom)\n",
    "\n",
    "print('JHU-cases')\n",
    "jhu_cases,cols_jhu_case=read_jhu_cases(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "\n",
    "print('hosp-neg-total result')\n",
    "hosp_new_res,cols_hosp_new_res=hosp_negative_total_data_test(data_path,epiweek_date,state_index)\n",
    "\n",
    "\n",
    "print('FB-GOOGLE')\n",
    "start_week=20210101\n",
    "start_week2 = 20200307\n",
    "end_week=int(week_end_string) #yyyymmdd\n",
    "survey, cols_survey = read_fb(state_index,epiweek_date,start_week,end_week,start_week2) \n",
    "\n",
    "#survey,cols_survey=read_delphi_fb_google_survey_test(state_index,epiweek_date,start_week,end_week)\n",
    "\"\"\"\n",
    "print('delphi vaccine survey')\n",
    "start_week=20210101\n",
    "start_week2 = 20200307\n",
    "end_week=int(week_end_string) #yyyymmdd\n",
    "\n",
    "vacc_delphi,cols_vacc_delphi=read_delphi_vaccine_test_two(state_index,epiweek_date,start_week,end_week)\"\"\"\n",
    "\n",
    "print('vaccine doses')\n",
    "vacc,cols_vacc=read_vaccine_doses(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "print('CDC hospitalization')\n",
    "start_day=3\n",
    "end_day=len(epiweek_date)-2 #change the value 14 if its is more/less\n",
    "#print(epiweek_date[start_day],epiweek_date[end_day])\n",
    "cdc_hosp,cols_cdc=read_cdc_hosp(data_path,epiweek_date,state_index,start_day,end_day)\n",
    "\n",
    "print('apple mobility')\n",
    "apple_mobility,cols_a=read_apple_mobility(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "print('JHU death')\n",
    "jhu_death,cols_jhu=read_jhu_death(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "\"\"\"\n",
    "#print('iqvia')\n",
    "#change start, end week based on data and epiweek_date. current data has value since epiweek 10-17\n",
    "#num_epiweek=34#total epiweek-1\n",
    "#iqvia_state,cols_q=read_iqvia(data_path,epiweek_date,state_index,num_epiweek)\"\"\"\n",
    "\n",
    "print('covidnet')\n",
    "step=9 #if epiweek starts from 10 then step=0, if epiweek starts from 1 step=9 (10-epiweek_start)\n",
    "start_week_n=10\n",
    "end_week_n=int(week_num) #change to current epiweek (1,...) since next week\n",
    "num_epiweek=105+int(week_num) #total epiweeks\n",
    "data_covidnet,cols_net= read_covidnet_data(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_n,end_week_n,step,num_epiweek)\n",
    "\n",
    "print('excess death')\n",
    "start_week_e='202001'\n",
    "end_week_e= year_week_num #current epiweek\n",
    "this_year=2020 #NEVER change this year, keep it always 2020, as all data started from 2020\n",
    "this_month=1 #latest epiweek month in excess-death data\n",
    "num_epiweek=105+int(week_num) #total epiweeks\n",
    "excess_death,cols_excess=read_excess_death(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_e,end_week_e,num_epiweek,this_month,this_year)\n",
    "\n",
    "\"\"\"\n",
    "####DONOT CHANGE THESE 3, they stopped update\n",
    "print('covid exposure index:dex')\n",
    "start_day=20\n",
    "end_day=len(epiweek_date)-42 #1 week 1 day lag\n",
    "print(epiweek_date[start_day],epiweek_date[end_day])\n",
    "dex,cols_d=read_dex(data_path,epiweek_date,state_index,start_day,end_day)\n",
    "\n",
    "print('hospitalization')\n",
    "last_date='2021-03-07' #yyyy-mm-dd: change to original epiweek date if pulled after Sat, else keep it as yesterday date\n",
    "#states needs hosp current 2020-12-26 \n",
    "state_error=['CA','DC','TX','IL','LA','PA','MI','MO','NC','NV','DE'] #'NJ', 'WA', 'NE'\n",
    "ew_end='202110' #the last epiweek in string\n",
    "data_hosp,cols_hosp=read_hospitalization(data_path,data_path,epiweek_date,week_save,state_index,state_error,ew_end)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print('emergency-visits')\n",
    "start_week_v=202001\n",
    "end_week_v=202105 #current epiweek\n",
    "em_visit,cols_v=read_emergency(data_path,epiweek_date,state_index,start_week_v,end_week_v)\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print('kinsa')\n",
    "last_date=10 #Aug 8\n",
    "last_month=10\n",
    "kinsa_state,cols_k=read_kinsa(kinsa_path,epiweek_date,state_index,last_date,last_month)\"\"\"\n",
    "\n",
    "state_names=list(state_index.keys())\n",
    "state_fips=read_fips_code(state_names,data_path)\n",
    "\n",
    "#'''\n",
    "#cdc_hosp={}\n",
    "#cols_cdc=\"\"\n",
    "\n",
    "print('merging all state..')\n",
    "#Change outputdir and outfilename with the path and name of out file\n",
    "outputdir=data_path #\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "outfile=\"covid-hospitalization-daily-all-state-merged_vEW\"+ year_week_num+\".csv\"\n",
    "merge_data_state(mobility_state,apple_mobility,cdc_hosp,vacc,data_covidnet,excess_death,\n",
    "                 jhu_death,survey,jhu_cases,hosp_new_res,\n",
    "                 cols_m,cols_a,cols_cdc,cols_vacc,cols_net,\n",
    "                 cols_excess,cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res,symptom,cols_symptom,\n",
    "                 state_fips,epiweek,week_save,state_names,outputdir,outfile)\n",
    "\"\"\"merge_data_state(mobility_state,apple_mobility,cdc_hosp,vacc,vacc_delphi,dex,kinsa_state,data_covidnet,data_hosp,excess_death,\n",
    "                 jhu_death,survey,jhu_cases,hosp_new_res,\n",
    "                 cols_m,cols_a,cols_cdc,cols_vacc,cols_vacc_delphi,cols_d,cols_k,cols_net,\n",
    "                 cols_hosp,cols_excess,cols_jhu,cols_survey,cols_jhu_case,cols_hosp_new_res,\n",
    "                 state_fips,epiweek,week_save,state_names,outputdir,outfile)\"\"\"\n",
    "\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': 'X', 'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY', 'United States': 'X'}\n",
      "{'X': 0, 'AL': 1, 'AK': 2, 'AZ': 3, 'AR': 4, 'CA': 5, 'CO': 6, 'CT': 7, 'DE': 8, 'DC': 9, 'FL': 10, 'GA': 11, 'ID': 12, 'IL': 13, 'IN': 14, 'IA': 15, 'KS': 16, 'KY': 17, 'LA': 18, 'ME': 19, 'MD': 20, 'MA': 21, 'MI': 22, 'MN': 23, 'MS': 24, 'MO': 25, 'MT': 26, 'NE': 27, 'NV': 28, 'NH': 29, 'NJ': 30, 'NM': 31, 'NY': 32, 'NC': 33, 'ND': 34, 'OH': 35, 'OK': 36, 'OR': 37, 'PA': 38, 'RI': 39, 'SC': 40, 'SD': 41, 'TN': 42, 'TX': 43, 'UT': 44, 'VT': 45, 'VA': 46, 'WA': 47, 'WV': 48, 'WI': 49, 'WY': 50}\n"
     ]
    }
   ],
   "source": [
    "print(dic_names_to_abbv)\n",
    "print(state_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cdc_hosp_weekly(inputdir,epiweek_date,state_index,end_week):\n",
    "    data=pd.read_csv(inputdir+\"COVID-19_Reported_Timeseries.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"reported_hospital_timeseries.csv\")\n",
    "    \n",
    "    #data=data.fillna(0)\n",
    "    state_index['PR'] = 51\n",
    "    state_index['VI'] = 52\n",
    "    state_names=list(state_index.keys())\n",
    "    flu_week_cases={}\n",
    "    #cols_d=list(data.columns)\n",
    "    #print(cols_d)\n",
    "    #cols=cols[2:]\n",
    "    flu_cols=['cdc_flu_hosp']\n",
    "    \n",
    "    flu_cols_to_check=['previous_day_admission_influenza_confirmed']\n",
    "    for c in flu_cols:\n",
    "        flu_week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "    flu_week_cases[c][:][:]=np.nan\n",
    "    flu_week_cases[c][0][:]=0\n",
    "    \n",
    "    # shift one up\n",
    "    data['datetime'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values(by=['datetime'])\n",
    "    data['previous_day_admission_influenza_confirmed'] = data.groupby('state')['previous_day_admission_influenza_confirmed'].shift(-1)\n",
    "    data.reset_index()\n",
    "    \n",
    "    # data['previous_day_admission_influenza_confirmed'] = data.groupby('state')['previous_day_admission_influenza_confirmed'].shift(-1)\n",
    "    # data['previous_day_admission_influenza_confirmed'] = data['previous_day_admission_influenza_confirmed'].shift(-1)\n",
    "\n",
    "    for index,row in data.iterrows():\n",
    "        if row['state'] in state_index.keys():\n",
    "            state_id=state_index[row['state']]\n",
    "        else:\n",
    "            continue\n",
    "        date=str(row['date'])\n",
    "        week_id=find_week_index(epiweek_date,date.replace('/','-'),date_string=False)\n",
    "        # flu_date = str(datetime.strptime(date.replace('/','-'), '%Y-%m-%d') - timedelta(days=1))\n",
    "        # flu_date = flu_date[:10]\n",
    "        # flu_week_id = find_week_index(epiweek_date, flu_date, date_string=False)\n",
    "        if week_id!=-1:\n",
    "            # same for flu hosp\n",
    "            ttl=0\n",
    "            flag_is_not_nan=False\n",
    "            for c in flu_cols_to_check: \n",
    "                if pd.isnull(row[c])==False:\n",
    "                    ttl+=float(row[c])\n",
    "                    flag_is_not_nan=True\n",
    "            if flag_is_not_nan:\n",
    "                if np.isnan(flu_week_cases[flu_cols[0]][state_id][week_id]):\n",
    "                    flu_week_cases[flu_cols[0]][state_id][week_id]=0\n",
    "                flu_week_cases[flu_cols[0]][state_id][week_id]+=ttl\n",
    "                flu_week_cases[flu_cols[0]][0][week_id]+=ttl\n",
    "            else:\n",
    "                flu_week_cases[flu_cols[0]][state_id][week_id]+=0\n",
    "                \n",
    "            \n",
    "                    \n",
    "    '''\n",
    "    week_cases[c][0]=np.zeros(len(epiweek_date))\n",
    "    for s in range(1,len(state_names)):\n",
    "        for c in cols:\n",
    "            week_cases[c][0]+=week_cases[c][s]\n",
    "            #week_cases[c][s][-1]=np.nan #considering data 2 weeks lag\n",
    "            #week_cases[c][s][-2]=np.nan\n",
    "    '''\n",
    "    #unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test/cdc_hosp.csv\") \n",
    "    del state_index['PR']\n",
    "    del state_index['VI']\n",
    "    return flu_week_cases,flu_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_week_index(week,cur_date,date_string=True,strsplit='-'):\n",
    "    if date_string:\n",
    "        year,month,date=cur_date[:4],cur_date[4:6],cur_date[6:8]\n",
    "    else:\n",
    "        if strsplit=='-':\n",
    "            year,month,date=cur_date.split(strsplit)\n",
    "        elif strsplit=='/':\n",
    "            month,date,year=cur_date.split(strsplit)\n",
    "    \n",
    "    cdate=int(date)\n",
    "    cmonth=int(month)\n",
    "    year=int(year)\n",
    "    \n",
    "    if year==20 or year==21 or year == 22:\n",
    "        stryear='20'+str(year)\n",
    "        year=int(stryear)\n",
    "        \n",
    "    for id in range(0,len(week)):\n",
    "        y,m,d=week[id].split('-')\n",
    "        wd,wm,wy=int(d),int(m),int(y)\n",
    "        if wm==cmonth:\n",
    "          #if wm==12:\n",
    "           #   print(wm,wd,wy,id+1,len(week))\n",
    "          if cdate>wd and wy==year and (id+1)<len(week):\n",
    "              yn,mn,dn=week[id+1].split('-')\n",
    "              wmn=int(mn)\n",
    "              if wmn==(cmonth%12)+1:\n",
    "                  return id+1\n",
    "          elif cdate<=wd and wy==year:\n",
    "              return id\n",
    "    print('week index not found:'+cur_date)\n",
    "    print(cdate,cmonth,year)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate weekly from daily \n",
    "daily_csv = pd.read_csv(\"covid-hospitalization-daily-all-state-merged_vEW202223.csv\")\n",
    "mean_df = daily_csv.groupby(by=['epiweek','region'],as_index=False, sort=False).mean()\n",
    "sum_df = daily_csv.groupby(by=['epiweek','region'],as_index=False, sort=False).sum(min_count=1)\n",
    "last_df = daily_csv.groupby(by=['epiweek','region'],as_index=False, sort=False).last()\n",
    "\n",
    "weekly_df = pd.DataFrame()\n",
    "mean_key = ['retail_and_recreation_percent_change_from_baseline',\n",
    "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "       'parks_percent_change_from_baseline',\n",
    "       'transit_stations_percent_change_from_baseline',\n",
    "       'workplaces_percent_change_from_baseline',\n",
    "       'residential_percent_change_from_baseline', 'apple_mobility','smoothed_wcovid_vaccinated', 'smoothed_wtested_positive_14d',\n",
    "       'smoothed_wwearing_mask_7d','smoothed_wspent_time_indoors_1d','fb_survey_wcli', 'fb_survey_wili']\n",
    "\n",
    "sum_key = ['cdc_hospitalized', 'death_jhu_incidence',\n",
    "       'positiveIncr', 'cdc_negativeIncr', 'cdc_positiveIncr',\n",
    "       'cdc_total_resultsIncr']\n",
    "\n",
    "last_key = ['Stage_One_Doses', 'Stage_Two_Doses','covidnet', 'Observed Number','Excess Estimate',\n",
    "            'death_jhu_cumulative','positiveIncr_cumulative']\n",
    "for ix, row in sum_df.iterrows(): \n",
    "    add_dict = {}\n",
    "    add_dict['epiweek'] = sum_df['epiweek'][ix]\n",
    "    add_dict['region'] = sum_df['region'][ix]\n",
    "    for i in mean_key: \n",
    "        add_dict[i] = mean_df[i][ix]\n",
    "    for i in sum_key: \n",
    "        add_dict[i] = sum_df[i][ix]\n",
    "    for i in last_key: \n",
    "        add_dict[i] = last_df[i][ix]\n",
    "    weekly_df = weekly_df.append(add_dict, ignore_index = True)\n",
    "\n",
    "    \n",
    "weekly_df = weekly_df.reindex(columns=['epiweek', 'region',\n",
    "       'retail_and_recreation_percent_change_from_baseline',\n",
    "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "       'parks_percent_change_from_baseline',\n",
    "       'transit_stations_percent_change_from_baseline',\n",
    "       'workplaces_percent_change_from_baseline',\n",
    "       'residential_percent_change_from_baseline', 'apple_mobility',\n",
    "       'cdc_hospitalized', 'Stage_One_Doses', 'Stage_Two_Doses',\n",
    "       'smoothed_wcovid_vaccinated', 'smoothed_wtested_positive_14d',\n",
    "       'smoothed_wwearing_mask_7d',\n",
    "       'smoothed_wspent_time_indoors_1d', 'covidnet', 'Observed Number',\n",
    "       'Excess Estimate', 'death_jhu_cumulative', 'death_jhu_incidence',\n",
    "       'fb_survey_wcli', 'fb_survey_wili', 'positiveIncr_cumulative',\n",
    "       'positiveIncr', 'cdc_negativeIncr', 'cdc_positiveIncr',\n",
    "       'cdc_total_resultsIncr'])\n",
    "weekly_df['epiweek'] = weekly_df['epiweek'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiweek1,epiweek_date1=get_epiweek_list('202001','202053',2020)\n",
    "epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "epiweek3,epiweek_date3=get_epiweek_list('202201',year_week_num,2022)\n",
    "\n",
    "epiweek=epiweek1+epiweek2+epiweek3\n",
    "epiweek_date=epiweek_date1+epiweek_date2+epiweek_date3\n",
    "week_save=copy.deepcopy(epiweek_date)\n",
    "end_week=int(week_num) #2021\n",
    "flu_hosp,cols_flu=read_cdc_hosp_weekly(data_path,epiweek_date,state_index,end_week)\n",
    "\n",
    "cols_common=['date','epiweek','region','fips']\n",
    "all_cols = cols_common+cols_flu\n",
    "final_data=pd.DataFrame(columns=all_cols)\n",
    "for reg in range(len(state_names)):\n",
    "    temp_data=pd.DataFrame(columns=all_cols)\n",
    "    temp_data['date']=week_save\n",
    "    temp_data['epiweek']=epiweek\n",
    "    temp_data['region']=[state_names[reg]]*len(epiweek_date)\n",
    "    temp_data['fips']=[state_fips[state_names[reg]]]*len(epiweek_date)\n",
    "    for c in cols_flu:\n",
    "        if reg == 0: \n",
    "            flu_hosp[c][reg][0:41] = np.nan\n",
    "        temp_data[c]=flu_hosp[c][reg][:]\n",
    "    temp_data=temp_data[all_cols]\n",
    "    final_data=final_data.append(temp_data,ignore_index=True)\n",
    "final_data=final_data[all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir=data_path\n",
    "outfile=\"covid-hospitalization-all-state-merged_vEW\"+ year_week_num+\".csv\"\n",
    "weekly_df = weekly_df.join(final_data['cdc_flu_hosp'])\n",
    "weekly_df = weekly_df.reindex(columns=['epiweek', 'region',\n",
    "       'retail_and_recreation_percent_change_from_baseline',\n",
    "       'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "       'parks_percent_change_from_baseline',\n",
    "       'transit_stations_percent_change_from_baseline',\n",
    "       'workplaces_percent_change_from_baseline',\n",
    "       'residential_percent_change_from_baseline', 'apple_mobility',\n",
    "       'cdc_hospitalized', 'cdc_flu_hosp','Stage_One_Doses', 'Stage_Two_Doses',\n",
    "       'smoothed_wcovid_vaccinated', 'smoothed_wtested_positive_14d',\n",
    "       'smoothed_wwearing_mask_7d',\n",
    "       'smoothed_wspent_time_indoors_1d', 'covidnet', 'Observed Number',\n",
    "       'Excess Estimate', 'death_jhu_cumulative', 'death_jhu_incidence',\n",
    "       'fb_survey_wcli', 'fb_survey_wili', 'positiveIncr_cumulative',\n",
    "       'positiveIncr', 'cdc_negativeIncr', 'cdc_positiveIncr',\n",
    "       'cdc_total_resultsIncr'])\n",
    "weekly_df['epiweek'] = weekly_df['epiweek'].astype('int')\n",
    "weekly_df.to_csv(outputdir+outfile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array([1.0,2.0,3.0])\n",
    "b=np.zeros(4)\n",
    "b[0:2]=a[0]\n",
    "epi= [[element]*7 for element in a]\n",
    "#b=str(a)\n",
    "print(b)\n",
    "\n",
    "epiweek,epiweek_date=get_epiweek_list('202001','202023',2020)\n",
    "#print(epiweek_date)\n",
    "#print(epiweek)\n",
    "week_obj = datetime.strptime(epiweek_date[1], '%Y-%m-%d')\n",
    "\n",
    "dates=pd.date_range(start='2020-01-01', end='2020-06-13')\n",
    "str_dates=[date_obj.strftime('%Y-%m-%d') for date_obj in dates]\n",
    "print(str_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vaccination = Epidata.smoothed_covid_vaccinated('fb-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "start=20210101\n",
    "vacc1=Epidata.covidcast('fb-survey','smoothed_covid_vaccinated','day','state',[20200120, Epidata.range(20200120, 20210206)],'*')\n",
    "vacc2=Epidata.covidcast('fb-survey','smoothed_tested_positive_14d','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "vacc3=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "vacc4=Epidata.covidcast('fb-survey','smoothed_travel_outside_state_5d','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "vacc5=Epidata.covidcast('fb-survey','smoothed_spent_time_1d','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "print(vacc1.keys())\n",
    "print(vacc2.keys())\n",
    "print(vacc3.keys())\n",
    "print(vacc4.keys())\n",
    "print(vacc5.keys())\n",
    "print(len(vacc1['epidata']))\n",
    "'''\n",
    "print('smoothed_covid_vaccinated',vacc1['result'], vacc1['message'], len(vacc1['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc2['result'], vacc2['message'], len(vacc2['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc3['result'], vacc3['message'], len(vacc3['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc4['result'], vacc4['message'], len(vacc4['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc5['result'], vacc5['message'], len(vacc5['epidata']))\n",
    "\n",
    "print(vacc1['epidata'][0])\n",
    "print(vacc2['epidata'][0])\n",
    "print(vacc3['epidata'][0])\n",
    "print(vacc4['epidata'][0])\n",
    "print(vacc5['epidata'][0])\n",
    "#print(vacc5['epidata'][0]['sample_size'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
