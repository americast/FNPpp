{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata sources:\\n1. google mobility: https://www.google.com/covid19/mobility/\\n2. apple mobilty: https://www.apple.com/covid19/mobility\\n3. Covid ExposureIndex dex: https://github.com/COVIDExposureIndices/COVIDExposureIndices\\n4. kinsa: kinsa_pull.ipynb \\n5. fb-google survey: deplhi api\\n6. hospitalization: https://covidtracking.com/api\\n6a. positiveIncrease: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\\n6b. negaiveResults, totalRes: https://healthdata.gov/dataset/COVID-19-Diagnostic-Laboratory-Testing-PCR-Testing/j8mb-icvb\\n7. jhu deaths: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\\n8. iqvia: Alex from Jimeng\\n9. excess deaths: https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm\\n10. Emergency visits (less priority: region level): \\n#https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/07242020/covid-like-illness.html\\nhttps://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/10092020/outpatient-emergency-visits.html\\n11. covidnet: original cdc, processed data to use given by ALEX\\n12. CDC hospitalized: https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-state-timeseries\\n13. vaccine doses: https://github.com/govex/COVID-19/blob/master/data_tables/vaccine_data/us_data/time_series/vaccine_data_us_timeline.csv\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data sources:\n",
    "1. google mobility: https://www.google.com/covid19/mobility/\n",
    "2. apple mobilty: https://www.apple.com/covid19/mobility\n",
    "3. Covid ExposureIndex dex: https://github.com/COVIDExposureIndices/COVIDExposureIndices\n",
    "4. kinsa: kinsa_pull.ipynb \n",
    "5. fb-google survey: deplhi api\n",
    "6. hospitalization: https://covidtracking.com/api\n",
    "6a. positiveIncrease: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "6b. negaiveResults, totalRes: https://healthdata.gov/dataset/COVID-19-Diagnostic-Laboratory-Testing-PCR-Testing/j8mb-icvb\n",
    "7. jhu deaths: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "8. iqvia: Alex from Jimeng\n",
    "9. excess deaths: https://www.cdc.gov/nchs/nvss/vsrr/covid19/excess_deaths.htm\n",
    "10. Emergency visits (less priority: region level): \n",
    "#https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/07242020/covid-like-illness.html\n",
    "https://www.cdc.gov/coronavirus/2019-ncov/covid-data/covidview/10092020/outpatient-emergency-visits.html\n",
    "11. covidnet: original cdc, processed data to use given by ALEX\n",
    "12. CDC hospitalized: https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-state-timeseries\n",
    "13. vaccine doses: https://github.com/govex/COVID-19/blob/master/data_tables/vaccine_data/us_data/time_series/vaccine_data_us_timeline.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "from epiweeks import Week, Year\n",
    "from delphi_epidata import Epidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unit_test(data_dic,cols,epiweek_date,state_index,outfile):\n",
    "    state_names=list(state_index.keys())\n",
    "    all_cols=['date','region']+cols\n",
    "    out_data=pd.DataFrame(columns=all_cols)\n",
    "    for st in range(len(state_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['region']=[state_names[st]]*len(epiweek_date)\n",
    "        for c in cols:\n",
    "            temp_data[c]=data_dic[c][st][:]\n",
    "        out_data=out_data.append(temp_data,ignore_index=True)\n",
    "    out_data=out_data[all_cols]\n",
    "    print(out_data.shape)\n",
    "    out_data.to_csv(outfile,index=False)\n",
    "    print('output file written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_survey_epidata(col_name,epidata,state_index,state_names,epiweek_date):\n",
    "    week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    total_sample=0\n",
    "    for ix in range(len(epidata)):\n",
    "        row=epidata[ix]\n",
    "        name=row['geo_value'].upper()\n",
    "        w_idx=find_date_index(epiweek_date,str(row['time_value']))\n",
    "        if name in state_names and w_idx!=-1:\n",
    "            state_id=state_index[name]\n",
    "            week_cases[state_id][w_idx]=row['value']\n",
    "            week_cases[0][w_idx]+=(row['value']/100)*row['sample_size']\n",
    "            total_sample+=row['sample_size']\n",
    "    \n",
    "    #national\n",
    "    week_cases[0]=week_cases[0]*100/total_sample\n",
    "    \n",
    "    return week_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_delphi_vaccine(state_index,epiweek_date,start_week,end_week):\n",
    "    vacc11=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc21=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc31=Epidata.covidcast('fb-survey','smoothed_wwearing_mask','day','state',[start_week, Epidata.range(start_week, end_week)],'*')\n",
    "    vacc41=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    vacc51=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[start_week, Epidata.range(start_week, 20210301)],'*')\n",
    "    \n",
    "    vacc12=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210301, Epidata.range(20210301, 20210501)],'*')\n",
    "    vacc13=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210501, Epidata.range(20210501, 20210701)],'*')\n",
    "    vacc14=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210701, Epidata.range(20210701, 20210901)],'*')\n",
    "    vacc15=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc16=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc17=Epidata.covidcast('fb-survey','smoothed_wcovid_vaccinated','day','state',[20220101, Epidata.range(20211101, end_week)],'*')\n",
    "    \n",
    "    vacc22=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210301, Epidata.range(20210301, 20210601)],'*')\n",
    "    vacc23=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210601, Epidata.range(20210601, 20210901)],'*')\n",
    "    vacc24=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20210901, Epidata.range(20210901, 20211101)],'*')\n",
    "    vacc25=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20211101, Epidata.range(20211101, 20220101)],'*')\n",
    "    vacc26=Epidata.covidcast('fb-survey','smoothed_wtested_positive_14d','day','state',[20220101, Epidata.range(20220101, end_week)],'*')\n",
    "    #vacc32=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc42=Epidata.covidcast('fb-survey','smoothed_wtravel_outside_state_5d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    vacc52=Epidata.covidcast('fb-survey','smoothed_wspent_time_1d','day','state',[20210301, Epidata.range(20210301, end_week)],'*')\n",
    "    \n",
    "    vacc1=vacc11['epidata']+vacc12['epidata']+vacc13['epidata']+vacc14['epidata']+vacc15['epidata']+vacc16['epidata']\n",
    "    vacc2=vacc21['epidata']+vacc22['epidata']+vacc23['epidata']+vacc24['epidata']+vacc25['epidata']\n",
    "    vacc3=vacc31['epidata']#+vacc32['epidata']\n",
    "    vacc4=vacc41['epidata']+vacc42['epidata']\n",
    "    vacc5=vacc51['epidata']+vacc52['epidata']\n",
    "    \n",
    "    print('smoothed_wcovid_vaccinated',vacc15['result'], vacc15['message'], len(vacc15['epidata']))\n",
    "    print('smoothed_wcovid_vaccinated',vacc16['result'], vacc16['message'], len(vacc16['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc24['result'], vacc24['message'], len(vacc24['epidata']))\n",
    "    print('smoothed_wtested_positive_14d',vacc25['result'], vacc25['message'], len(vacc25['epidata']))\n",
    "    print('smoothed_wwearing_mask',vacc31['result'], vacc31['message'], len(vacc31['epidata']))\n",
    "    print('smoothed_wtravel_outside_state_5d',vacc42['result'], vacc42['message'], len(vacc42['epidata']))\n",
    "    print('smoothed_wspent_time_1d',vacc52['result'], vacc52['message'], len(vacc52['epidata']))\n",
    "    #print(vacc5['epidata'][0]['value'])\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['smoothed_wcovid_vaccinated','smoothed_wtested_positive_14d','smoothed_wwearing_mask',\n",
    "          'smoothed_wtravel_outside_state_5d','smoothed_wspent_time_1d']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],vacc1,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],vacc2,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],vacc3,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[3]]=read_survey_epidata(cols[3],vacc4,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[4]]=read_survey_epidata(cols[4],vacc5,state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/vaccine_survey.csv\")\n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_delphi_fb_google_survey(state_index,epiweek_date,start_week,end_week):\n",
    "    #fb_res_cli = Epidata.covidcast('fb-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_cli1 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_cli2 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_cli3 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_cli4 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_cli5 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_cli6 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_cli7 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_cli8 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_cli9 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_cli10 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_cli11 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_cli12 = Epidata.covidcast('fb-survey', 'raw_wcli', 'day', 'state', [20220101, Epidata.range(20220101, end_week)], '*')\n",
    "\n",
    "    fb_cli1=fb_res_cli1['epidata']+fb_res_cli2['epidata']\n",
    "    fb_cli2=fb_cli1+fb_res_cli3['epidata']\n",
    "    fb_cli3=fb_cli2+fb_res_cli4['epidata']\n",
    "    #fb_res_cli=fb_cli3+fb_res_cli5['epidata']\n",
    "    fb_cli4=fb_cli3+fb_res_cli5['epidata'] \n",
    "    fb_cli5=fb_cli4+fb_res_cli6['epidata'] \n",
    "    fb_cli6=fb_cli5+fb_res_cli7['epidata'] \n",
    "    fb_cli7=fb_cli6+fb_res_cli8['epidata'] \n",
    "    fb_cli8=fb_cli7+fb_res_cli9['epidata']\n",
    "    fb_cli9=fb_cli8+fb_res_cli10['epidata']\n",
    "    fb_cli10=fb_cli8+fb_res_cli10['epidata']\n",
    "    fb_res_cli=fb_cli10+fb_res_cli12['epidata']\n",
    "\n",
    "    \n",
    "    google_res_cli = Epidata.covidcast('google-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #fb_res_wli = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    fb_res_wli1 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "    fb_res_wli2 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200601, Epidata.range(20200601, 20200701)], '*')\n",
    "    fb_res_wli3 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200701, Epidata.range(20200701, 20200901)], '*')\n",
    "    fb_res_wli4 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20200901, Epidata.range(20200901, 20201101)], '*')\n",
    "    fb_res_wli5 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20201101, Epidata.range(20201101, 20210101)], '*')\n",
    "    fb_res_wli6 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210101, Epidata.range(20210101, 20210301)], '*')\n",
    "    fb_res_wli7 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210301, Epidata.range(20210301, 20210501)], '*')\n",
    "    fb_res_wli8 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210501, Epidata.range(20210501, 20210701)], '*')\n",
    "    fb_res_wli9 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210701, Epidata.range(20210701, 20210901)], '*')\n",
    "    fb_res_wli10 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20210901, Epidata.range(20210901, 20211101)], '*')\n",
    "    fb_res_wli11 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20211101, Epidata.range(20211101, 20220101)], '*')\n",
    "    fb_res_wli12 = Epidata.covidcast('fb-survey', 'raw_wili', 'day', 'state', [20220101, Epidata.range(20211101, end_week)], '*')\n",
    "\n",
    "    \n",
    "    fb_wli1=fb_res_wli1['epidata']+fb_res_wli2['epidata']\n",
    "    fb_wli2=fb_wli1+fb_res_wli3['epidata']\n",
    "    fb_wli3=fb_wli2+fb_res_wli4['epidata']\n",
    "    fb_wli4=fb_wli3+fb_res_wli5['epidata']\n",
    "    fb_wli5=fb_wli4+fb_res_wli6['epidata']\n",
    "    fb_wli6=fb_wli5+fb_res_wli7['epidata']\n",
    "    fb_wli7=fb_wli6+fb_res_wli8['epidata']\n",
    "    fb_wli8=fb_wli7+fb_res_wli9['epidata']\n",
    "    fb_wli9=fb_wli8+fb_res_wli10['epidata']\n",
    "    fb_wli10=fb_wli9+fb_res_wli10['epidata']\n",
    "    fb_res_wli=fb_wli10+fb_res_wli12['epidata']\n",
    "    \n",
    "    \n",
    "    #google_res_wli = Epidata.covidcast('google-survey', 'raw_wili', 'day', 'state', [start_week, Epidata.range(start_week, end_week)], '*')\n",
    "    \n",
    "    #print('fb_cli1',fb_res_cli1['result'], fb_res_cli1['message'], len(fb_res_cli1['epidata']))\n",
    "    #print('fb_cli2',fb_res_cli2['result'], fb_res_cli2['message'], len(fb_res_cli2['epidata']))\n",
    "    #print('fb_cli3',fb_res_cli3['result'], fb_res_cli3['message'], len(fb_res_cli3['epidata']))\n",
    "    print('fb_cli4',fb_res_cli3['result'], fb_res_cli4['message'], len(fb_res_cli4['epidata']))\n",
    "    print('fb_cli5',fb_res_cli5['result'], fb_res_cli5['message'], len(fb_res_cli5['epidata']))\n",
    "    print('fb_cli6',fb_res_cli6['result'], fb_res_cli6['message'], len(fb_res_cli6['epidata']))\n",
    "    print('fb_cli8',fb_res_cli8['result'], fb_res_cli8['message'], len(fb_res_cli8['epidata']))\n",
    "    print('fb_cli9',fb_res_cli9['result'], fb_res_cli9['message'], len(fb_res_cli9['epidata']))\n",
    "    print('fb_cli11',fb_res_cli10['result'], fb_res_cli10['message'], len(fb_res_cli11['epidata']))\n",
    "    print('fb_cli12',fb_res_cli11['result'], fb_res_cli11['message'], len(fb_res_cli12['epidata']))\n",
    "\n",
    "    \n",
    "    print(google_res_cli['result'], google_res_cli['message'], len(google_res_cli['epidata']))\n",
    "    \n",
    "    #print(fb_res_wli1['result'], fb_res_wli1['message'], len(fb_res_wli1['epidata']))\n",
    "    #print(fb_res_wli2['result'], fb_res_wli2['message'], len(fb_res_wli2['epidata']))\n",
    "    #print(fb_res_wli3['result'], fb_res_wli3['message'], len(fb_res_wli3['epidata']))\n",
    "    print('fb_wili4',fb_res_wli4['result'], fb_res_wli4['message'], len(fb_res_wli4['epidata']))\n",
    "    print('fb_wili5',fb_res_wli5['result'], fb_res_wli5['message'], len(fb_res_wli5['epidata']))\n",
    "    print('fb_wili6',fb_res_wli6['result'], fb_res_wli6['message'], len(fb_res_wli6['epidata']))\n",
    "    print('fb_wili8',fb_res_wli8['result'], fb_res_wli8['message'], len(fb_res_wli8['epidata']))\n",
    "    print('fb_wili9',fb_res_wli9['result'], fb_res_wli9['message'], len(fb_res_wli9['epidata']))\n",
    "    print('fb_wili11',fb_res_wli10['result'], fb_res_wli10['message'], len(fb_res_wli11['epidata']))\n",
    "    print('fb_wili12',fb_res_wli11['result'], fb_res_wli11['message'], len(fb_res_wli12['epidata']))\n",
    "\n",
    "    \n",
    "    print('fb_cli len',len(fb_res_cli))\n",
    "    print('fb_wli len',len(fb_res_wli))\n",
    "    #print(google_res_wli['result'], google_res_wli['message'], len(google_res_wli['epidata']))\n",
    "    \n",
    "    state_names=list(state_index.keys())\n",
    "    cols=['fb_survey_wcli','google_survey_cli','fb_survey_wili']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    #week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[0]]=read_survey_epidata(cols[0],fb_res_cli,state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[1]]=read_survey_epidata(cols[1],google_res_cli['epidata'],state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    week_cases[cols[2]]=read_survey_epidata(cols[2],fb_res_wli,state_index,state_names,epiweek_date)\n",
    "    #week_cases[cols[3]]=read_survey_epidata(cols[3],google_res_wli['epidata'],state_index,state_names,epiweek_date)\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/fb-google-survey.csv\")\n",
    "    \n",
    "    return week_cases,cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_fips_code(state_names,fips_path,abbv_to_code=True):\n",
    "    #if abbv_to_code=True; read fips with given state code (state_names)\n",
    "    #if abbv_to_code=False; read state code with given state name (state_names)\n",
    "    \n",
    "    fips=pd.read_csv(fips_path+\"other_data/fips_codes.csv\",delimiter=',',dtype={'state_code':str})\n",
    "    if abbv_to_code:\n",
    "        fips=fips[['state','state_code']].drop_duplicates().reset_index()\n",
    "    else:\n",
    "        fips=fips[['state','state_name']].drop_duplicates().reset_index()\n",
    "    \n",
    "    state_fips={}\n",
    "    for name in state_names:\n",
    "        if abbv_to_code:\n",
    "            if name=='X':\n",
    "                row='US'\n",
    "            else:\n",
    "                row= str(fips.loc[fips['state'] == name,'state_code'].iloc[0])   \n",
    "        else:\n",
    "            if name=='X':\n",
    "                row='X'\n",
    "            else:\n",
    "                row= fips.loc[fips['state_name'] == name,'state'].iloc[0]   \n",
    "        \n",
    "        state_fips[name]=row\n",
    "    \n",
    "    #print(state_fips)\n",
    "    return state_fips\n",
    "\n",
    "def find_date_index(dates,cur_date,date_string=1):\n",
    "    if date_string==1:\n",
    "        year,month,date=cur_date[:4],cur_date[4:6],cur_date[6:8]\n",
    "    elif date_string==2:\n",
    "        year,month,date=cur_date.split('-')\n",
    "    else:\n",
    "        month,date,year=cur_date.split('/')\n",
    "    \n",
    "    cdate=int(date)\n",
    "    cmonth=int(month)\n",
    "    year=int(year)\n",
    "    \n",
    "    if year==20 or year==21 or year==22:\n",
    "        stryear='20'+str(year)\n",
    "        year=int(stryear)\n",
    "    \n",
    "    for id in range(0,len(dates)):\n",
    "        y,m,d=dates[id].split('-')\n",
    "        wd,wm,wy=int(d),int(m),int(y)\n",
    "        if wm==cmonth and wd==cdate and wy==year:\n",
    "              return id\n",
    "    #print('week index not found:'+cur_date)\n",
    "    #print(cdate,cmonth,year)\n",
    "    return -1\n",
    "\n",
    "def get_epiweek_list(week_start,week_end,year):\n",
    "    def convert(x):\n",
    "        return Week.fromstring(str(x))\n",
    "    \n",
    "    wstart=convert(week_start)\n",
    "    wend=convert(week_end)\n",
    "    #print(wstart,wend)\n",
    "    week_edate_list=[]\n",
    "    week_list=[]\n",
    "    for week in Year(year).iterweeks():\n",
    "        date_time = week.enddate().strftime(\"%Y-%m-%d\")\n",
    "        #print(week,date_time)\n",
    "        if week>=wstart and week<=wend:\n",
    "            week_edate_list.append(date_time)\n",
    "            week_list.append(str(week))\n",
    "     \n",
    "    return week_list,week_edate_list  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_apple_mobility(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"applemobilitytrends.csv\",low_memory=False)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates=list(data.columns)\n",
    "    dates=dates[6:]\n",
    "    data = data.loc[data['region'].isin(state_names)]\n",
    "    #data=data.fillna(0)\n",
    "    #print(data.shape)\n",
    "    #week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    week_cases=np.empty((len(state_names),len(epiweek_date)))\n",
    "    week_cases[:][:]=np.nan\n",
    "    for ix,row in data.iterrows():\n",
    "        if row['transportation_type']=='driving':\n",
    "            if row['region'] in state_names:\n",
    "                state_id=state_index[dic_names_to_abbv[row['region']]] \n",
    "                for d in dates:\n",
    "                    w_idx=find_date_index(epiweek_date,d,date_string=2)\n",
    "                    if w_idx!=-1 and pd.isnull(row[d])==False:\n",
    "                        if np.isnan(week_cases[state_id][w_idx]):\n",
    "                            week_cases[state_id][w_idx]=0\n",
    "                        week_cases[state_id][w_idx]=float(row[d])\n",
    "    apple_dic={}\n",
    "    apple_dic['apple_mobility']=week_cases    \n",
    "    \n",
    "    unit_test(apple_dic,['apple_mobility'],epiweek_date,state_index,\"unit_test_date/apple.csv\")\n",
    "    \n",
    "    return apple_dic,['apple_mobility']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_mobility(inputdir,epiweek_date,end_day,MISSING_TOKEN=0):\n",
    "    data=pd.read_csv(inputdir+\"Global_Mobility_Report.csv\",low_memory=False)\n",
    "    data=data[data['country_region_code']=='US']\n",
    "    data=data.drop(data[data['sub_region_1'] == 'Hawaii'].index)\n",
    "    data=data.drop(columns=['sub_region_2'])\n",
    "\n",
    "    state_names=data['sub_region_1'].drop_duplicates().values\n",
    "    state_names[0]='X' #changing nan to US national X\n",
    "    cols=data.columns\n",
    "    cols=list(cols[8:])\n",
    "    dic_names_to_abbv=read_fips_code(state_names,inputdir,abbv_to_code=False)\n",
    "    \n",
    "    state_index = {dic_names_to_abbv[state_names[i]]: i for i in range(len(state_names))} \n",
    "    #data[cols] = data[cols].fillna(MISSING_TOKEN)\n",
    "    num_states=len(state_names)\n",
    "    #print(cols)\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((num_states,len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((num_states,len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_day)!=0:\n",
    "            total_len=len(epiweek_date)-end_day\n",
    "            week_cases[c][:][-total_len:]=np.nan\n",
    "        '''\n",
    "    print(cols)\n",
    "    #'''\n",
    "    for ix,row in data.iterrows():\n",
    "        if type(row['sub_region_1']) is float:\n",
    "            state_id=0\n",
    "        else:\n",
    "            state_id=state_index[dic_names_to_abbv[row['sub_region_1']]]\n",
    "        week_id=find_date_index(epiweek_date,str(row['date']),date_string=2)\n",
    "        if week_id!=-1:\n",
    "            for c in cols:\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    if np.isnan(week_cases[c][state_id][week_id]):\n",
    "                            week_cases[c][state_id][week_id]=0\n",
    "                    week_cases[c][state_id][week_id]=row[c]\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/google-mobility.csv\")\n",
    "    #'''\n",
    "    \n",
    "    return week_cases,cols,state_index,dic_names_to_abbv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_vaccine_doses(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"vaccine_data_us_state_timeline.csv\")\n",
    "    #data=data.fillna(0)\n",
    "    #state_names=list(state_index.keys())\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    #cols=['people_total','people_total_2nd_dose']\n",
    "    cols=['Stage_One_Doses','Stage_Two_Doses']\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for ix,row in data.iterrows():\n",
    "        w_idx=find_date_index(epiweek_date,row['Date'],date_string=2)\n",
    "        if row['Province_State'] in state_names and w_idx!=-1 and row['Vaccine_Type']=='All':\n",
    "            #state_id=state_index[row['stabbr']] \n",
    "            state_id=state_index[dic_names_to_abbv[row['Province_State']]] \n",
    "            for c in cols:\n",
    "                val=None\n",
    "                if pd.isnull(row[c])==False:\n",
    "                    val=float(row[c])\n",
    "                elif w_idx>0:\n",
    "                    val=week_cases[c][state_id][w_idx-1]               \n",
    "                week_cases[c][state_id][w_idx]=val\n",
    "                week_cases[c][0][w_idx]+=val\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/vaccine.csv\")\n",
    "    \n",
    "    return week_cases,cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_dex(inputdir,epiweek_date,state_index,start_day,end_day):\n",
    "    data=pd.read_csv(inputdir+\"state_dex.csv\",low_memory=False)\n",
    "    cols=[]\n",
    "    state_names=list(state_index.keys())\n",
    "    for c in data.columns:\n",
    "        if 'dex' in c:\n",
    "            cols.append(c)\n",
    "    \n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "        week_cases[c][:][:]=np.nan\n",
    "        week_cases[c][0][:]=0\n",
    "        '''\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "        if (len(epiweek_date)-end_day)!=0:\n",
    "            total_len=len(epiweek_date)-end_day\n",
    "            week_cases[c][:][-total_len:]=np.nan\n",
    "        '''\n",
    "    \n",
    "    for ix,row in data.iterrows():\n",
    "        w_idx=find_date_index(epiweek_date,row['date'],date_string=2)\n",
    "        if row['state'] in state_names and w_idx!=-1:\n",
    "            state_id=state_index[row['state']]\n",
    "            for c in cols:\n",
    "                if not math.isnan(row[c]):\n",
    "                    if np.isnan(week_cases[c][state_id][w_idx]):\n",
    "                        week_cases[c][state_id][w_idx]=0\n",
    "                    week_cases[c][state_id][w_idx]=float(row[c])\n",
    "                    week_cases[c][0][w_idx]+=float(row[c])\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/dex.csv\")\n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_county_cases(observed,county_name,state_name,population,onlypopu=False):\n",
    "    #print(state_name,county_name)\n",
    "    try:\n",
    "        row=population.loc[population['CTYNAME']==county_name]\n",
    "        row=row.loc[row['STNAME']==state_name]\n",
    "        popu=row['POPESTIMATE2019'].values\n",
    "        if len(popu)==0:\n",
    "            return -1\n",
    "        #print(row['CTYNAME'].values,popu)\n",
    "        if onlypopu:\n",
    "            return popu[0]\n",
    "        else:\n",
    "            return (observed*popu[0])/100\n",
    "    except KeyError:\n",
    "        print('county not found')\n",
    "        return -1\n",
    "    \n",
    "def read_kinsa(inputdir,epiweek_date,state_index,last_date,last_month,avg=1):\n",
    "    '''\n",
    "    data=pd.read_csv(inputdir+\"ili_case_counts_by_state.csv\",delimiter=',')\n",
    "    data=data[['region_name','state','date','observed_ili']]\n",
    "\n",
    "    county_names=data[['region_name']].drop_duplicates().reset_index()\n",
    "    county_names=county_names['region_name'].values\n",
    "    state_abbrv=pd.read_csv(inputdir+\"state_abbrv.csv\",delimiter=',')\n",
    "    '''\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases_state=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    '''\n",
    "    population_data=pd.read_csv(inputdir+\"co-est2019-alldata2.csv\",delimiter=',',encoding = \"ISO-8859-1\")\n",
    "    population=population_data[['STNAME','CTYNAME','POPESTIMATE2019']]\n",
    "    total=328239523\n",
    "    \n",
    "    county_index = {county_names[i]: i for i in range(len(county_names))} \n",
    "    \n",
    "    for index,row in data.iterrows():\n",
    "        state_id=state_index[row['state']]\n",
    "        year,month,date=row['date'].split('-')\n",
    "        #month,date,year=row['date'].split('/')\n",
    "        if int(month)>last_month:\n",
    "            continue\n",
    "        if int(month)==last_month and int(date)>last_date:\n",
    "            continue\n",
    "        week_id=find_date_index(epiweek_date,row['date'],date_string=2)\n",
    "        abbrv=state_abbrv.loc[state_abbrv['Code']==row['state']]\n",
    "        abbrv=abbrv['State'].values\n",
    "        observed=find_county_cases(row['observed_ili'],row['region_name'],abbrv[0],population)\n",
    "        if week_id!=-1:\n",
    "            week_cases_state[state_id][week_id]+=observed\n",
    "            week_cases_state[0][week_id]+=observed\n",
    "    \n",
    "    #kinsa_dic={}\n",
    "    #kinsa_dic['kinsa_cases']=week_cases_state\n",
    "    #unit_test(kinsa_dic,['kinsa_cases'],epiweek_date,state_index,\"unit_test_date/kinsa_rough.csv\")\n",
    "    print('data extrcation done, aggregating counties')\n",
    "    week_cases_state[0][:]=(week_cases_state[0][:]*100)/(avg*total)\n",
    "    for st_id in range(1,len(state_names)):\n",
    "        st_name=state_abbrv.loc[state_abbrv['Code']==state_names[st_id]]\n",
    "        st_name=st_name['State'].values\n",
    "        popu=find_county_cases(week_cases_state[st_id][0],st_name[0],st_name[0],population,onlypopu=True)\n",
    "        print(st_name[0],popu)\n",
    "        week_cases_state[st_id][:]=(week_cases_state[st_id][:]*100)/(avg*popu)\n",
    "    \n",
    "    '''\n",
    "    kinsa_dic={}\n",
    "    kinsa_dic['kinsa_cases']=week_cases_state\n",
    "    #unit_test(kinsa_dic,['kinsa_cases'],epiweek_date,state_index,\"unit_test_date/kinsa.csv\")\n",
    "    return kinsa_dic,['kinsa_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hosp_negative_total_data(inputdir,epiweek_date,state_index):\n",
    "    data_hosp=pd.read_csv(inputdir+\"COVID-19_PCR_Testing_Time_Series.csv\",delimiter=',')\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    cols=['negativeIncr','total_resultsIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for index,row in data_hosp.iterrows():\n",
    "        if row['overall_outcome']=='Negative':\n",
    "            if row['state'] in state_index.keys():\n",
    "                state_id=state_index[row['state']]\n",
    "                date=row['date']\n",
    "                week_id=find_date_index(epiweek_date,date.replace('/','-'),date_string=2)\n",
    "                week_cases[cols[0]][state_id][week_id]=float(row['new_results_reported'])\n",
    "                week_cases[cols[1]][state_id][week_id]=float(row['total_results_reported'])\n",
    "            \n",
    "                week_cases[cols[0]][0][week_id]+=float(row['new_results_reported'])\n",
    "                week_cases[cols[1]][0][week_id]+=float(row['total_results_reported'])\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/hosp_neg_ttl.csv\") \n",
    "    \n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_jhu_cases(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"time_series_covid19_confirmed_US.csv\")\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates_list=list(data.columns)\n",
    "    dates_list=dates_list[11:]\n",
    "    #print(state_names)\n",
    "    #print(dates_list)\n",
    "    #not_added_rows=['Diamond Princess','Grand Princess','Northern Mariana Islands','Guam','Hawaii',\n",
    "                   # 'Puerto Rico','Virgin Islands','American Samoa']\n",
    "    not_added_rows=[]\n",
    "    week_cases={}\n",
    "    cols=['positiveIncr_cumulative','positiveIncr']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        name=row['Province_State']\n",
    "        if name in state_names:\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    #print(name,date,row[date])\n",
    "                    week_cases[cols[0]][state_id][w_idx]+=int(row[date])\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "        elif name not in not_added_rows: #if not state_names still adding them for national\n",
    "            #print('state name not added:'+name)\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "    \n",
    "    \n",
    "    #count incidence for the national+states\n",
    "    #count incidence for the national+states\n",
    "    for state_id in range(len(state_names)):\n",
    "        week_cases[cols[1]][state_id][0]=int(week_cases[cols[0]][state_id][0])\n",
    "        for w_idx in range(1,len(epiweek_date)):\n",
    "            week_cases[cols[1]][state_id][w_idx]=abs(int(week_cases[cols[0]][state_id][w_idx])-int(week_cases[cols[0]][state_id][w_idx-1]))         \n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/jhu-cases.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hosp_cases_nat_state(data_national,data_state,epiweek_date,week_save,state_index,cols,state_error,epiweek_end):\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    \n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    #processing national cases\n",
    "    nat_id=state_index['X']\n",
    "    nat_hosp_incr=np.zeros(len(epiweek_date))\n",
    "    for index,row in data_national.iterrows():\n",
    "        week_id=find_date_index(week_save,str(row['date']),date_string=1)\n",
    "        for c in range(len(cols)): #if next1,next2 consider then do cols-4\n",
    "            week_cases[cols[c]][nat_id][week_id]+=row[cols[c]]\n",
    "    \n",
    "    #processing state cases\n",
    "    for index,row in data_state.iterrows():\n",
    "        state_id=state_index[row['states']]\n",
    "        cur_date=int(row['date'])\n",
    "        week_id=find_date_index(week_save,str(cur_date))\n",
    "        if week_id!=-1:\n",
    "            for c in range(len(cols)): #if next1,next2 consider then do cols-4\n",
    "                if cols[c]=='hospitalizedIncrease':\n",
    "                    if row['states'] in state_error:\n",
    "                        week_cases[cols[c]][state_id][week_id]=max(0,row['hospitalizedCurrently'])\n",
    "                    else:\n",
    "                        week_cases[cols[c]][state_id][week_id]=max(0,row[cols[c]])\n",
    "                        nat_hosp_incr[week_id]+=max(0,row[cols[c]])\n",
    "                else:\n",
    "                    week_cases[cols[c]][state_id][week_id]=max(0,row[cols[c]])\n",
    "    \n",
    "    #for states with no hospitalze cumulative using formula week[t]=hosp_cur[t]-(week[t-1]/2)\n",
    "    c='hospitalizedIncrease'\n",
    "    temp_data=pd.read_csv(\"unit_test/hospitalization.csv\")\n",
    "    \n",
    "    for s in state_error:\n",
    "        st_idx=state_index[s]\n",
    "        region_hosp=temp_data.loc[temp_data['region']==s]\n",
    "        hosp_weekly=region_hosp['hospitalizedIncrease'].values\n",
    "        #print('hosp_weekly:',len(hosp_weekly))\n",
    "        #print(hosp_weekly)\n",
    "        hsp_incr=np.zeros(len(epiweek_date))\n",
    "        hsp_incr[0]=week_cases[c][st_idx][0]\n",
    "        nat_hosp_incr[0]+=week_cases[c][st_idx][0]\n",
    "        for w in range(1,len(epiweek_date)):\n",
    "            cur_date=epiweek_date[w]\n",
    "            e_idx=get_epiweek_index(cur_date,'202001',epiweek_end) #change/edit to work it for year>2020\n",
    "            #hsp_incr[w]=max(0,week_cases[c][st_idx][w]-float(hsp_incr[w-1])/2) #7 days before\n",
    "            if e_idx!=-1:\n",
    "                hsp_incr[w-6:w+1]=hosp_weekly[e_idx-1]\n",
    "                nat_hosp_incr[w-6:w+1]+=(hosp_weekly[e_idx-1]/7)\n",
    "            #else:\n",
    "             #   hsp_incr[w]=hsp_incr[w-1]\n",
    "            #else:\n",
    "             #   hsp_incr[w]=max(0,week_cases[c][st_idx][w]-float(week_cases[c][st_idx][w-1])) #7 days not passed yet\n",
    "        week_cases[c][st_idx]=hsp_incr/7\n",
    "    \n",
    "    c='recovered'\n",
    "    rec_nat=np.zeros(len(epiweek_date))\n",
    "    for s in state_names:\n",
    "        st_idx=state_index[s]\n",
    "        rec_incr=np.zeros(len(epiweek_date))\n",
    "        rec_incr[0]=week_cases[c][st_idx][0]\n",
    "        rec_nat[0]+=week_cases[c][st_idx][0]\n",
    "        for w in range(1,len(epiweek_date)):\n",
    "            rec_incr[w]=week_cases[c][st_idx][w]-week_cases[c][st_idx][w-1]\n",
    "            rec_nat[w]+=max(rec_incr[w],0)\n",
    "\n",
    "        week_cases[c][st_idx]=rec_incr\n",
    "    week_cases[c][nat_id]=rec_nat\n",
    "    np.savetxt(\"unit_test_date/hos_nat_aggregated.csv\", nat_hosp_incr, fmt='%.4f')\n",
    "    return week_cases\n",
    "\n",
    "def read_hospitalization(input_national,input_state,epiweek_date,week_save,state_index,state_error,ew_end):\n",
    "    nat_data_path=\"us-daily-hospitalizations.csv\"\n",
    "    state_data_path=\"states-daily-hospitalizations.csv\"\n",
    "    nat_data=pd.read_csv(input_national+nat_data_path,delimiter=',')\n",
    "    state_data=pd.read_csv(input_state+state_data_path,delimiter=',')\n",
    "    state_data=state_data.rename(columns={\"state\": \"states\"})\n",
    "    \n",
    "    columns=['date','states','hospitalizedCurrently','onVentilatorCurrently','positiveIncrease','negativeIncrease',\n",
    "             'totalTestResultsIncrease','inIcuCurrently','recovered','deathIncrease','hospitalizedIncrease']\n",
    "    rows_to_drop=['GU','AS','HI','PR', 'MP','VI']\n",
    "    \n",
    "    nat_data_filter=nat_data[columns]\n",
    "    state_data_filter=state_data[columns]\n",
    "    \n",
    "    nat_data_filter=nat_data_filter.fillna(0)\n",
    "    state_data_filter=state_data_filter.fillna(0)\n",
    "    \n",
    "    index_to_remove=[]\n",
    "    for index, row in state_data_filter.iterrows():\n",
    "        #print(row['Province/State'])\n",
    "        if row['states'] in rows_to_drop:\n",
    "            index_to_remove.append(index)\n",
    "\n",
    "    state_data_filter=state_data_filter.drop(index=index_to_remove).reset_index()\n",
    "    #print(state_data_filter['states'].drop_duplicates())\n",
    "    #cols_for_hosp=['positiveIncrease','negativeIncrease','totalTestResultsIncrease','onVentilatorCurrently',\n",
    "     #              'inIcuCurrently','deathIncrease','recovered','hospitalizedIncrease','h_next1','h_next2',\n",
    "      #             'd_next1','d_next2']\n",
    "    cols_for_hosp=['positiveIncrease','negativeIncrease','totalTestResultsIncrease','onVentilatorCurrently',\n",
    "                   'inIcuCurrently','deathIncrease','recovered','hospitalizedIncrease']\n",
    "    \n",
    "    week_cases=hosp_cases_nat_state(nat_data_filter,state_data_filter,epiweek_date,week_save,state_index,cols_for_hosp,state_error,ew_end)\n",
    "    \n",
    "    unit_test(week_cases,cols_for_hosp,epiweek_date,state_index,\"unit_test_date/hospitalization_date.csv\")\n",
    "    return week_cases,cols_for_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_jhu_death(inputdir,epiweek_date,state_index,dic_names_to_abbv):\n",
    "    data=pd.read_csv(inputdir+\"time_series_covid19_deaths_US.csv\")\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    dates_list=list(data.columns)\n",
    "    dates_list=dates_list[12:]\n",
    "    #print(state_names)\n",
    "    #print(dates_list)\n",
    "    #not_added_rows=['Diamond Princess','Grand Princess','Northern Mariana Islands','Guam','Hawaii',\n",
    "                   # 'Puerto Rico','Virgin Islands','American Samoa']\n",
    "    not_added_rows=[]\n",
    "    week_cases={}\n",
    "    cols=['death_jhu_cumulative','death_jhu_incidence']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        name=row['Province_State']\n",
    "        if name in state_names:\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    #print(name,date,row[date])\n",
    "                    week_cases[cols[0]][state_id][w_idx]+=int(row[date])\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "        elif name not in not_added_rows: #if not state_names still adding them for national\n",
    "            #print('state name not added:'+name)\n",
    "            for date in dates_list:\n",
    "                w_idx=find_date_index(epiweek_date,date,date_string=3)\n",
    "                if w_idx!=-1:\n",
    "                    week_cases[cols[0]][0][w_idx]+=int(row[date])\n",
    "    \n",
    "    \n",
    "    #count incidence for the national+states\n",
    "    for state_id in range(len(state_names)):\n",
    "        week_cases[cols[1]][state_id][0]=int(week_cases[cols[0]][state_id][0])\n",
    "        for w_idx in range(1,len(epiweek_date)):\n",
    "            week_cases[cols[1]][state_id][w_idx]=abs(int(week_cases[cols[0]][state_id][w_idx])-int(week_cases[cols[0]][state_id][w_idx-1]))\n",
    "             \n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/jhu-death.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_covidnet(data_covidnet,week_len,start,end,step,weekly_rate,region): #region='X'\n",
    "    covid=np.empty(week_len)\n",
    "    covid[:]=np.nan\n",
    "    data_f=data_covidnet.loc[data_covidnet['CATCHMENT']==region]\n",
    "    #data_f=data[data['AGE CATEGORY']=='Overall'].reset_index()\n",
    "    for index,row in data_f.iterrows():\n",
    "        mmr_week=int(row['MMWR-WEEK'])\n",
    "        year=int(row['MMWR-YEAR'])\n",
    "        if row['AGE CATEGORY']=='Overall' and row['SEX']=='Overall' and row['RACE']=='Overall':\n",
    "            if year==2020:\n",
    "                if mmr_week>=start and mmr_week<=53:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[mmr_week-10+step]=float(row[weekly_rate])\n",
    "            elif year==2021:\n",
    "                if mmr_week<=end:\n",
    "                    if region=='Entire Network':\n",
    "                        if row['NETWORK']=='COVID-NET':\n",
    "                            covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "                    else:\n",
    "                        covid[43+step+mmr_week]=float(row[weekly_rate])\n",
    "    return covid\n",
    "\n",
    "def read_covidnet_data(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week,step,num_epiweek):\n",
    "    #data_covidnet=pd.read_csv(inputdir+\"COVID-NET_Processed.csv\",delimiter=',')\n",
    "    if date.today().weekday() != 6:\n",
    "        week_num = (date.today()-timedelta(days=2)).strftime(\"%U\")\n",
    "        year_week_num = \"2022\" + week_num\n",
    "    else:\n",
    "        week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "        year_week_num = \"2022\" + week_num\n",
    "        \n",
    "    file_name = \"COVID-NET_v\"+year_week_num + \".csv\"\n",
    "    data_covidnet=pd.read_csv(file_name,delimiter=',')\n",
    "    columns=list(data_covidnet.columns)\n",
    "    \n",
    "    dic_names_to_abbv['Entire Network']='X'\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    #state_names=list(state_index.keys())\n",
    "    #print(columns)\n",
    "    weekly_rate='WEEKLY RATE'\n",
    "    if 'WEEKLY RATE' in columns:\n",
    "        data_covidnet=data_covidnet[['CATCHMENT','NETWORK','MMWR-YEAR','MMWR-WEEK','AGE CATEGORY','SEX','RACE','WEEKLY RATE']]\n",
    "    else:\n",
    "        data_covidnet=data_covidnet[['CATCHMENT','NETWORK','MMWR-YEAR','MMWR-WEEK','AGE CATEGORY','SEX','RACE','WEEKLY RATE ']]\n",
    "        weekly_rate='WEEKLY RATE '\n",
    "    \n",
    "    week_cases=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    #for st in state_index.keys():\n",
    "    for state in state_names:\n",
    "        if state=='United States' or state=='X':\n",
    "            continue\n",
    "        st=dic_names_to_abbv[state]\n",
    "        #print(state,state_index[st])\n",
    "        covidnet_week=read_covidnet(data_covidnet,num_epiweek,start_week,end_week,step,weekly_rate,region=state)\n",
    "        for week in range(0,num_epiweek):\n",
    "            start,end=map_epiweek_to_date(week+1,epiweek_date,num_epiweek,week_string=False,year=2022)\n",
    "            week_cases[state_index[st]][start:end+1]=[covidnet_week[week]]*(end-start+1)\n",
    "    \n",
    "    covidnet_dic={}\n",
    "    covidnet_dic['covidnet']=week_cases\n",
    "    unit_test(covidnet_dic,['covidnet'],epiweek_date,state_index,\"unit_test_date/covidnet.csv\")\n",
    "    return covidnet_dic,['covidnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_epiweek_index(cur_date,start_week,end_week,year=2022):\n",
    "    #print('epiweek_index',cur_date)\n",
    "    week_num = date.today().strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    epiweek1,epiweek_date1=get_epiweek_list(start_week,'202053',2020)\n",
    "    epiweek2,epiweek_date2=get_epiweek_list('202101','202152',2021)\n",
    "    epiweek3,epiweek_date3=get_epiweek_list('202201',year_week_num,2022)\n",
    "    #epiweek=epiweek1+epiweek2\n",
    "    #epiweek_date=epiweek_date1+epiweek_date2\n",
    "    for d in range(0,len(epiweek_date1)):\n",
    "        if cur_date==epiweek_date1[d]:\n",
    "            return int(epiweek1[d][4:])\n",
    "    \n",
    "    for d in range(0,len(epiweek_date2)):\n",
    "        if cur_date==epiweek_date2[d]:\n",
    "            return int(epiweek2[d][4:])+53\n",
    "    for d in range(0, len(epiweek_date3)):\n",
    "        if cur_date==epiweek_date3[d]:\n",
    "            return int(epiweek3[d][4:])+105\n",
    "    \n",
    "    return -1\n",
    "            \n",
    "def map_epiweek_to_date(week,epiweek_date,num_epiweek,week_string=True,year=2022):\n",
    "    if week_string:\n",
    "        stryear=int(week[:4])\n",
    "        week=int(week[4:])\n",
    "        if stryear>2020:\n",
    "            week+=53\n",
    "    if year==2020:\n",
    "        end_week=str(year)+str(num_epiweek)\n",
    "    else:\n",
    "        pos=num_epiweek%106+1\n",
    "        end_week=str(year)+str(pos)\n",
    "    #start_week=str(year)+'01'\n",
    "    start_week='202001'\n",
    "    epiweek1, week_dates1=get_epiweek_list('202001','202053',2020)\n",
    "    epiweek2,week_dates2=[],[]\n",
    "    epiweek2, week_dates2=get_epiweek_list('202101','202152',2021)\n",
    "    epiweek3, week_dates3=get_epiweek_list('202201', end_week, year)\n",
    "    \n",
    "    epiweek=epiweek1+epiweek2+epiweek3\n",
    "    week_dates=week_dates1+week_dates2+week_dates3\n",
    "    if week-2<0:\n",
    "        #week_date_start_str=str(year)+'-01-01' #2020-01-01, 2021-01-01\n",
    "        week_date_start_str='2020-01-01' #2020-01-01, 2021-01-01\n",
    "        week_date_start_obj = datetime.strptime(week_date_start_str, '%Y-%m-%d')\n",
    "    else:\n",
    "        week_date_start_str=week_dates[week-2]\n",
    "        week_date_start_obj = datetime.strptime(week_date_start_str, '%Y-%m-%d')+timedelta(days=1)\n",
    "    \n",
    "    week_date_end_str=week_dates[week-1]\n",
    "    start_idx=-1\n",
    "    end_idx=-1\n",
    "    \n",
    "    week_date_end_obj = datetime.strptime(week_date_end_str, '%Y-%m-%d')\n",
    "    \n",
    "    for d in range(0,len(epiweek_date)):\n",
    "        cur_date_obj=datetime.strptime(epiweek_date[d], '%Y-%m-%d')\n",
    "        if cur_date_obj>=week_date_start_obj and cur_date_obj<week_date_end_obj and start_idx==-1:\n",
    "            start_idx=d\n",
    "        elif cur_date_obj==week_date_end_obj:\n",
    "            end_idx=d\n",
    "    \n",
    "    return start_idx,end_idx \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_iqvia(inputdir,epiweek_date,state_index,num_epiweek):\n",
    "    data=pd.read_csv(inputdir+\"iqvia_Processed.csv\")\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "\n",
    "    cols=list(data.columns)\n",
    "    cols=cols[4:]\n",
    "    print(cols)\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        state_id=state_index[row['region']]\n",
    "        week=str(row['epiweek'])\n",
    "        start,end=map_epiweek_to_date(week,epiweek_date,num_epiweek)\n",
    "        for c in cols:\n",
    "            #week_cases[c][state_id][start_week-10:end_week-start_week]=group[c]\n",
    "            week_cases[c][state_id][start:end+1]=float(row[c])\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/iqvia.csv\")\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_cdc_hosp(inputdir,epiweek_date,state_index,start_day,end_day):\n",
    "    data=pd.read_csv(inputdir+\"COVID-19_Reported_Timeseries.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"reported_hospital_timeseries.csv\")\n",
    "    \n",
    "    #data=data.fillna(0)\n",
    "    state_index['PR'] = 51\n",
    "    state_index['VI'] = 52\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    #cols=list(data.columns)\n",
    "    #cols=cols[2:]\n",
    "    cols=['cdc_hospitalized']\n",
    "    \n",
    "    cols_to_check=['previous_day_admission_adult_covid_confirmed','previous_day_admission_pediatric_covid_confirmed']\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.empty((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    week_cases[c][:][:]=np.nan\n",
    "    week_cases[c][0][:]=0\n",
    "    for index,row in data.iterrows():\n",
    "        if row['state'] in state_index.keys():\n",
    "            state_id=state_index[row['state']]\n",
    "        else:\n",
    "            continue\n",
    "        date=str(row['date'])\n",
    "        week_id=find_date_index(epiweek_date,date.replace('/','-'),date_string=2)\n",
    "        if week_id!=-1:\n",
    "            ttl=0\n",
    "            flag_is_not_nan=False\n",
    "            for c in cols_to_check: \n",
    "                if pd.isnull(row[c])==False:\n",
    "                    ttl+=float(row[c])\n",
    "                    flag_is_not_nan=True\n",
    "            if flag_is_not_nan:\n",
    "                week_cases[cols[0]][state_id][week_id]=ttl\n",
    "                week_cases[cols[0]][0][week_id]+=ttl\n",
    "                    \n",
    "    \n",
    "    '''\n",
    "    missing_days=len(epiweek_date)-end_day\n",
    "    for s in range(len(state_names)):\n",
    "        for c in cols:\n",
    "            week_cases[c][s][-missing_days:]=np.nan #considering data 2 weeks lag\n",
    "    '''\n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/cdc_hosp.csv\") \n",
    "    del state_index['PR']\n",
    "    del state_index['VI']\n",
    "    return week_cases,cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_excess_death(inputdir,epiweek_date,state_index,dic_names_to_abbv,start_week,end_week,num_epiweek,this_month,this_year=2020):\n",
    "    data=pd.read_csv(inputdir+\"Excess_Deaths_COVID-19.csv\")\n",
    "    #cols_death=['Observed Number','Excess Higher Estimate']\n",
    "    cols_death=['Observed Number','Excess Estimate'] \n",
    "#     out_cols = ['Observed Numberv2','Excess Estimatev2']\n",
    "    cols=['Week Ending Date','State']+cols_death\n",
    "    data=data[cols]\n",
    "    data[cols]=data[cols].fillna(0)\n",
    "    state_names=list(dic_names_to_abbv.keys())\n",
    "    week_cases={}\n",
    "    for c in cols_death:\n",
    "        week_cases[c]=np.zeros((len(state_names),len(epiweek_date)))\n",
    "    \n",
    "    for ix, row in data.iterrows():\n",
    "        week=row['Week Ending Date']\n",
    "        y,m,d=week.split('-')\n",
    "        cm,cd,cy=int(m),int(d),int(y)\n",
    "        name=row['State']\n",
    "        if name in state_names and cy>=this_year:# and cm<=this_month:\n",
    "            cur_date=y+'-'+m+'-'+d\n",
    "            week=get_epiweek_index(cur_date,start_week,end_week)\n",
    "            start,end=map_epiweek_to_date(week,epiweek_date,num_epiweek,week_string=False,year=2022)\n",
    "            state_id=state_index[dic_names_to_abbv[name]]\n",
    "            #print(week,start,end)\n",
    "            for c in cols_death:\n",
    "                week_cases[c][state_id][start:end+1]+=int(row[c])\n",
    "                week_cases[c][0][start:end+1]=week_cases[c][0][start:end+1]+int(row[c])\n",
    "     \n",
    "    ##ADD NAN VALUES TO THE LAST 1 WEEK\n",
    "    for s in range(len(state_names)):\n",
    "        for c in cols_death:\n",
    "            week_cases[c][s]/=3\n",
    "            week_cases[c][s][-14:]=np.nan\n",
    "    \n",
    "    \n",
    "    unit_test(week_cases,cols_death,epiweek_date,state_index,\"unit_test_date/excess-death.csv\")\n",
    "    return week_cases,cols_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_emergency(inputdir,epiweek_date,state_index,start_week,end_week):\n",
    "    #data=pd.read_csv(inputdir+\"emergency-visits.csv\")\n",
    "    #data=pd.read_csv(inputdir+\"covid-like-illness.csv\")\n",
    "    data=pd.read_csv(inputdir+\"covid-like-illness-v202040.csv\")\n",
    "    cols=['Number of Facilities Reporting','CLI Percent of Total Visits']\n",
    "    data=data[data['Week']>=start_week]\n",
    "    state_names=list(state_index.keys())\n",
    "    week_cases={}\n",
    "    for c in cols:\n",
    "        week_cases[c]=np.full([len(state_names),len(epiweek_date)],np.nan)\n",
    "    \n",
    "    \n",
    "    region_map={'X':0,'Region 1':1,'Region 2':2, 'Region 3':3,'Region 4':4,'Region 5':5,'Region 6':6,\n",
    "               'Region 7':7,'Region 8':8,'Region 9':9,'Region 10':10}\n",
    "\n",
    "    file = open(inputdir+\"other_data/hhs_regions_abbv.txt\", 'r') \n",
    "    Lines = file.readlines() \n",
    "    state_hhs_map={}\n",
    "    #### mapping each state to a hhs region ###\n",
    "    state_hhs_map[0]=0 # setting national value\n",
    "    for line in Lines:\n",
    "        regions=line.strip().split(',')\n",
    "        reg_id=int(regions[0])\n",
    "        for j in range(1,len(regions)):\n",
    "            if state_index.get(regions[j],-1)!=-1:\n",
    "                state_id=state_index[regions[j]]\n",
    "                state_hhs_map[state_id]=reg_id\n",
    "            else:\n",
    "                print('state not found '+regions[j])\n",
    "    #print(state_hhs_map)\n",
    "    num_epiweeks=end_week-start_week+1\n",
    "    for ix,row in data.iterrows():\n",
    "        reg_id=region_map[row['region']]\n",
    "        week=str(row['Week'])\n",
    "        year=int(week[:4])\n",
    "        w_idx=int(week[4:])\n",
    "        for st in range(len(state_names)):\n",
    "            if state_hhs_map[st]==reg_id:\n",
    "                for c in cols:\n",
    "                    reporting=row[c]\n",
    "                    if c=='Number of Facilities Reporting':\n",
    "                        reporting=int(reporting.replace(',',''))\n",
    "                    #print(state_names[st],w_idx,reporting)\n",
    "                    start,end=map_epiweek_to_date(week,epiweek_date,num_epiweeks)\n",
    "                    week_cases[c][st][start:end+1]=reporting\n",
    "    \n",
    "    unit_test(week_cases,cols,epiweek_date,state_index,\"unit_test_date/emergency.csv\")\n",
    "    return week_cases,cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def merge_data_state(mobility,apple,cdc_hosp,vacc,vac_delphi,dex,kinsa,covidnet,hosp,excess,jhu,survey,em_visit,jhu_case,hosp_new_res,\n",
    "                     cols_m,cols_a,cols_cdc,cols_vacc,cols_vac_delphi,cols_d,cols_k,cols_net,cols_hosp,cols_excess,\n",
    "                     cols_jhu,cols_survey,cols_v,cols_jhu_case,cols_hosp_new_res,\n",
    "                     state_fips,epiweek,epiweek_date,region_names,outputdir,outfilename):\n",
    "    \n",
    "    \n",
    "    cols_common=['date','epiweek','region','fips']\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_k+cols_q+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    all_cols=cols_common+cols_m+cols_a+cols_cdc+cols_d+cols_vacc+cols_vac_delphi+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v+cols_jhu_case+cols_hosp_new_res\n",
    "    #all_cols=cols_common+cols_m+cols_a+cols_d+cols_k+cols_net+cols_hosp+cols_excess+cols_jhu+cols_survey+cols_v\n",
    "    print(all_cols)\n",
    "    final_data=pd.DataFrame(columns=all_cols)\n",
    "    for reg in range(len(region_names)):\n",
    "        temp_data=pd.DataFrame(columns=all_cols)\n",
    "        temp_data['date']=epiweek_date\n",
    "        temp_data['epiweek']=epiweek\n",
    "        temp_data['region']=[region_names[reg]]*len(epiweek_date)\n",
    "        temp_data['fips']=[state_fips[region_names[reg]]]*len(epiweek_date)\n",
    "        for c in cols_m:\n",
    "            temp_data[c]=mobility[c][reg][:]\n",
    "        for c in cols_a:\n",
    "            temp_data[c]=apple[c][reg][:]\n",
    "        for c in cols_cdc:\n",
    "            temp_data[c]=cdc_hosp[c][reg][:]\n",
    "        for c in cols_d:\n",
    "            temp_data[c]=dex[c][reg][:]\n",
    "        for c in cols_vacc:\n",
    "            temp_data[c]=vacc[c][reg][:]\n",
    "        for c in cols_vac_delphi:\n",
    "            temp_data[c]=vac_delphi[c][reg][:]\n",
    "        for c in cols_k:\n",
    "            temp_data[c]=kinsa[c][reg][:]\n",
    "        #for c in cols_q:\n",
    "         #   temp_data[c]=iqvia[c][reg][:]\n",
    "        for c in cols_net:\n",
    "            temp_data[c]=covidnet[c][reg][:]\n",
    "        for c in cols_hosp:\n",
    "            temp_data[c]=hosp[c][reg][:]\n",
    "        for c in cols_excess:\n",
    "            temp_data[c]=excess[c][reg][:]\n",
    "        for c in cols_jhu:\n",
    "            temp_data[c]=jhu[c][reg][:]\n",
    "        for c in cols_survey:\n",
    "            temp_data[c]=survey[c][reg][:]\n",
    "        for c in cols_v:\n",
    "            temp_data[c]=em_visit[c][reg][:]\n",
    "        for c in cols_jhu_case:\n",
    "            temp_data[c]=jhu_case[c][reg][:]\n",
    "        for c in cols_hosp_new_res:\n",
    "            temp_data[c]=hosp_new_res[c][reg][:]\n",
    "        \n",
    "        temp_data=temp_data[all_cols]\n",
    "        final_data=final_data.append(temp_data,ignore_index=True)\n",
    "    \n",
    "    final_data=final_data[all_cols]\n",
    "    print(final_data.shape)\n",
    "    final_data.to_csv(outputdir+outfilename,index=False)\n",
    "    \n",
    "    print('FINISHED....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202204\n",
      "760\n",
      "google mobility\n",
      "2022-01-26\n",
      "['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n",
      "(38760, 8)\n",
      "output file written\n",
      "JHU-cases\n",
      "(38760, 4)\n",
      "output file written\n",
      "hosp-neg-total result\n",
      "(38760, 4)\n",
      "output file written\n",
      "FB-GOOGLE\n",
      "fb_cli4 1 success 3017\n",
      "fb_cli5 1 success 3021\n",
      "fb_cli6 1 success 2949\n",
      "fb_cli8 1 success 2687\n",
      "fb_cli9 1 success 2830\n",
      "fb_cli11 1 success 2631\n",
      "fb_cli12 1 success 1275\n",
      "1 success 1734\n",
      "fb_wili4 1 success 3017\n",
      "fb_wili5 1 success 3021\n",
      "fb_wili6 1 success 2949\n",
      "fb_wili8 1 success 2687\n",
      "fb_wili9 1 success 2830\n",
      "fb_wili11 1 success 2631\n",
      "fb_wili12 1 success 3650\n",
      "fb_cli len 29088\n",
      "fb_wli len 34203\n",
      "(38760, 5)\n",
      "output file written\n",
      "delphi vaccine survey\n",
      "smoothed_wcovid_vaccinated 1 success 3162\n",
      "smoothed_wcovid_vaccinated 1 success 3162\n",
      "smoothed_wtested_positive_14d 1 success 2782\n",
      "smoothed_wtested_positive_14d 1 success 2722\n",
      "smoothed_wwearing_mask 1 success 2509\n",
      "smoothed_wtravel_outside_state_5d 1 success 515\n",
      "smoothed_wspent_time_1d 1 success 526\n",
      "(38760, 7)\n",
      "output file written\n",
      "vaccine doses\n",
      "(38760, 4)\n",
      "output file written\n",
      "CDC hospitalization\n",
      "(38760, 3)\n",
      "output file written\n",
      "apple mobility\n",
      "(38760, 3)\n",
      "output file written\n",
      "JHU death\n",
      "(38760, 4)\n",
      "output file written\n",
      "covidnet\n",
      "(38760, 3)\n",
      "output file written\n",
      "excess death\n",
      "(38760, 4)\n",
      "output file written\n",
      "covid exposure index:dex\n",
      "2020-01-21 2021-12-19\n",
      "(38760, 28)\n",
      "output file written\n",
      "hospitalization\n",
      "(38760, 10)\n",
      "output file written\n",
      "emergency-visits\n",
      "state not found PR\n",
      "state not found VI\n",
      "state not found HI\n",
      "state not found AS\n",
      "state not found MP\n",
      "state not found FM\n",
      "state not found GU\n",
      "state not found MH\n",
      "state not found RP\n",
      "(38760, 4)\n",
      "output file written\n",
      "kinsa\n",
      "merging all state..\n",
      "['date', 'epiweek', 'region', 'fips', 'retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline', 'apple_mobility', 'cdc_hospitalized', 'dex', 'dex_a', 'dex_income_1', 'dex_income_1_a', 'dex_income_2', 'dex_income_2_a', 'dex_income_3', 'dex_income_3_a', 'dex_income_4', 'dex_income_4_a', 'dex_education_1', 'dex_education_1_a', 'dex_education_2', 'dex_education_2_a', 'dex_education_3', 'dex_education_3_a', 'dex_education_4', 'dex_education_4_a', 'dex_race_asian', 'dex_race_asian_a', 'dex_race_black', 'dex_race_black_a', 'dex_race_hispanic', 'dex_race_hispanic_a', 'dex_race_white', 'dex_race_white_a', 'Stage_One_Doses', 'Stage_Two_Doses', 'smoothed_wcovid_vaccinated', 'smoothed_wtested_positive_14d', 'smoothed_wwearing_mask', 'smoothed_wtravel_outside_state_5d', 'smoothed_wspent_time_1d', 'kinsa_cases', 'covidnet', 'positiveIncrease', 'negativeIncrease', 'totalTestResultsIncrease', 'onVentilatorCurrently', 'inIcuCurrently', 'deathIncrease', 'recovered', 'hospitalizedIncrease', 'Observed Number', 'Excess Estimate', 'death_jhu_cumulative', 'death_jhu_incidence', 'fb_survey_wcli', 'google_survey_cli', 'fb_survey_wili', 'Number of Facilities Reporting', 'CLI Percent of Total Visits', 'positiveIncr_cumulative', 'positiveIncr', 'negativeIncr', 'total_resultsIncr']\n",
      "(38760, 68)\n",
      "FINISHED....\n"
     ]
    }
   ],
   "source": [
    "data_path=\"./\"\n",
    "kinsa_path= \"./\"\n",
    "\n",
    "if date.today().weekday() != 6:\n",
    "    week_num = (date.today()-timedelta(2)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\"  + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() +timedelta((5-date.today().weekday()) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_date = (date.today() - timedelta(2)).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() + timedelta((5-date.today().weekday()) % 7 )).strftime('%Y%m%d')\n",
    "    week_end_string = (date.today() - timedelta(2)).strftime('%Y%m%d')\n",
    "else:\n",
    "    week_num = (date.today()-timedelta(days=1)).strftime(\"%U\")\n",
    "    year_week_num = \"2022\" + week_num\n",
    "    print(year_week_num)\n",
    "    week_end_date = (date.today() -timedelta((date.today().weekday()-5) % 7 )).strftime('%Y-%m-%d')\n",
    "    week_end_string = (date.today() - timedelta((date.today().weekday()-5) % 7 )).strftime('%Y%m%d')\n",
    "\n",
    "epiweek_date_obj=pd.date_range(start='2020-01-01', end=week_end_date) #update date as this epiweek yyyy-mm-dd\n",
    "epiweek_date=[date_obj.strftime('%Y-%m-%d') for date_obj in epiweek_date_obj]\n",
    "week_save=[date_obj.strftime('%Y-%m-%d') for date_obj in epiweek_date_obj]\n",
    "\n",
    "num_epiweek=105+int(week_num) #total epiweeks for 2022: 53+52+current_epiweek#update total num of epiweeks\n",
    "\n",
    "epiweek_list1,epiweek_date_list1=get_epiweek_list('202001','202053',2020) #update end epiweek as current epiweek\n",
    "epiweek_list2,epiweek_date_list2=get_epiweek_list('202101','202152',2021) #update end epiweek as current epiweek\n",
    "epiweek_list3,epiweek_date_list3=get_epiweek_list('202201',year_week_num,2022)\n",
    "\n",
    "epiweek_list=epiweek_list1+epiweek_list2+epiweek_list3\n",
    "epiweek_date_list=epiweek_date_list1+epiweek_date_list2+epiweek_date_list3\n",
    "\n",
    "epiweek=np.array([0 for i in range(len(epiweek_date))])\n",
    "#print(len(epiweek))\n",
    "for week in range(1,num_epiweek+1):\n",
    "    st,ed=map_epiweek_to_date(week,epiweek_date,num_epiweek,week_string=False)\n",
    "    #print(week,st,ed)\n",
    "    epiweek[st:ed+1]=epiweek_list[week-1]\n",
    "\n",
    "print(len(epiweek_date))\n",
    "#print(epiweek)\n",
    "#print(epiweek_date)\n",
    "#print(week_save)\n",
    "\n",
    "print('google mobility')\n",
    "end_day=len(epiweek_date)-4 #usually m=ewdate-4, since current data does not have value for this week\n",
    "print(epiweek_date[end_day])\n",
    "mobility_state,cols_m,state_index,dic_names_to_abbv=read_mobility(data_path,epiweek_date,end_day)\n",
    "dic_names_to_abbv['United States']='X'\n",
    "\n",
    "print('JHU-cases')\n",
    "jhu_cases,cols_jhu_case=read_jhu_cases(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "print('hosp-neg-total result')\n",
    "hosp_new_res,cols_hosp_new_res=hosp_negative_total_data(data_path,epiweek_date,state_index)\n",
    "\n",
    "print('FB-GOOGLE')\n",
    "start_week=20200307\n",
    "end_week=int(week_end_string) #yyyymmdd\n",
    "survey,cols_survey=read_delphi_fb_google_survey(state_index,epiweek_date,start_week,end_week)\n",
    "\n",
    "print('delphi vaccine survey')\n",
    "start_week=20210101\n",
    "end_week=int(week_end_string) #yyyymmdd\n",
    "\n",
    "vacc_delphi,cols_vacc_delphi=read_delphi_vaccine(state_index,epiweek_date,start_week,end_week)\n",
    "\n",
    "print('vaccine doses')\n",
    "vacc,cols_vacc=read_vaccine_doses(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "print('CDC hospitalization')\n",
    "start_day=3\n",
    "end_day=len(epiweek_date)-2 #change the value 14 if its is more/less\n",
    "#print(epiweek_date[start_day],epiweek_date[end_day])\n",
    "cdc_hosp,cols_cdc=read_cdc_hosp(data_path,epiweek_date,state_index,start_day,end_day)\n",
    "\n",
    "print('apple mobility')\n",
    "apple_mobility,cols_a=read_apple_mobility(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "print('JHU death')\n",
    "jhu_death,cols_jhu=read_jhu_death(data_path,epiweek_date,state_index,dic_names_to_abbv)\n",
    "\n",
    "#print('iqvia')\n",
    "#change start, end week based on data and epiweek_date. current data has value since epiweek 10-17\n",
    "#num_epiweek=34#total epiweek-1\n",
    "#iqvia_state,cols_q=read_iqvia(data_path,epiweek_date,state_index,num_epiweek)\n",
    "\n",
    "print('covidnet')\n",
    "step=9 #if epiweek starts from 10 then step=0, if epiweek starts from 1 step=9 (10-epiweek_start)\n",
    "start_week_n=10\n",
    "end_week_n=3 #change to current epiweek (1,...) since next week\n",
    "num_epiweek=105+int(week_num) #total epiweeks\n",
    "data_covidnet,cols_net= read_covidnet_data(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_n,end_week_n,step,num_epiweek)\n",
    "\n",
    "print('excess death')\n",
    "start_week_e='202001'\n",
    "end_week_e= year_week_num #current epiweek\n",
    "this_year=2020 #NEVER change this year, keep it always 2020, as all data started from 2020\n",
    "this_month=1 #latest epiweek month in excess-death data\n",
    "num_epiweek=105+int(week_num) #total epiweeks\n",
    "excess_death,cols_excess=read_excess_death(data_path,epiweek_date,state_index,dic_names_to_abbv,start_week_e,end_week_e,num_epiweek,this_month,this_year)\n",
    "\n",
    "####DONOT CHANGE THESE 3, they stopped update\n",
    "print('covid exposure index:dex')\n",
    "start_day=20\n",
    "end_day=len(epiweek_date)-42 #1 week 1 day lag\n",
    "print(epiweek_date[start_day],epiweek_date[end_day])\n",
    "dex,cols_d=read_dex(data_path,epiweek_date,state_index,start_day,end_day)\n",
    "\n",
    "print('hospitalization')\n",
    "last_date='2021-03-07' #yyyy-mm-dd: change to original epiweek date if pulled after Sat, else keep it as yesterday date\n",
    "#states needs hosp current 2020-12-26 \n",
    "state_error=['CA','DC','TX','IL','LA','PA','MI','MO','NC','NV','DE'] #'NJ', 'WA', 'NE'\n",
    "ew_end='202110' #the last epiweek in string\n",
    "data_hosp,cols_hosp=read_hospitalization(data_path,data_path,epiweek_date,week_save,state_index,state_error,ew_end)\n",
    "\n",
    "print('emergency-visits')\n",
    "start_week_v=202001\n",
    "end_week_v=202105 #current epiweek\n",
    "em_visit,cols_v=read_emergency(data_path,epiweek_date,state_index,start_week_v,end_week_v)\n",
    "\n",
    "print('kinsa')\n",
    "last_date=10 #Aug 8\n",
    "last_month=10\n",
    "kinsa_state,cols_k=read_kinsa(kinsa_path,epiweek_date,state_index,last_date,last_month)\n",
    "state_names=list(state_index.keys())\n",
    "state_fips=read_fips_code(state_names,data_path)\n",
    "\n",
    "#'''\n",
    "#cdc_hosp={}\n",
    "#cols_cdc=\"\"\n",
    "print('merging all state..')\n",
    "#Change outputdir and outfilename with the path and name of out file\n",
    "outputdir=data_path #\"/Users/anikat/Downloads/covid-hospitalization-data/\"\n",
    "outfile=\"covid-hospitalization-daily-all-state-merged_vEW\"+ year_week_num+\".csv\"\n",
    "merge_data_state(mobility_state,apple_mobility,cdc_hosp,vacc,vacc_delphi,dex,kinsa_state,data_covidnet,data_hosp,excess_death,\n",
    "                 jhu_death,survey,em_visit,jhu_cases,hosp_new_res,\n",
    "                 cols_m,cols_a,cols_cdc,cols_vacc,cols_vacc_delphi,cols_d,cols_k,cols_net,\n",
    "                 cols_hosp,cols_excess,cols_jhu,cols_survey,cols_v,cols_jhu_case,cols_hosp_new_res,\n",
    "                 state_fips,epiweek,week_save,state_names,outputdir,outfile)\n",
    "\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array([1.0,2.0,3.0])\n",
    "b=np.zeros(4)\n",
    "b[0:2]=a[0]\n",
    "epi= [[element]*7 for element in a]\n",
    "#b=str(a)\n",
    "print(b)\n",
    "\n",
    "epiweek,epiweek_date=get_epiweek_list('202001','202023',2020)\n",
    "#print(epiweek_date)\n",
    "#print(epiweek)\n",
    "week_obj = datetime.strptime(epiweek_date[1], '%Y-%m-%d')\n",
    "\n",
    "dates=pd.date_range(start='2020-01-01', end='2020-06-13')\n",
    "str_dates=[date_obj.strftime('%Y-%m-%d') for date_obj in dates]\n",
    "print(str_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vaccination = Epidata.smoothed_covid_vaccinated('fb-survey', 'raw_cli', 'day', 'state', [start_week, Epidata.range(start_week, 20200601)], '*')\n",
    "start=20210101\n",
    "vacc1=Epidata.covidcast('fb-survey','smoothed_covid_vaccinated','day','state',[20200120, Epidata.range(20200120, 20210206)],'*')\n",
    "vacc2=Epidata.covidcast('fb-survey','smoothed_tested_positive_14d','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "vacc3=Epidata.covidcast('fb-survey','smoothed_wearing_mask','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "vacc4=Epidata.covidcast('fb-survey','smoothed_travel_outside_state_5d','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "vacc5=Epidata.covidcast('fb-survey','smoothed_spent_time_1d','day','state',[start, Epidata.range(start, 20210206)],'*')\n",
    "print(vacc1.keys())\n",
    "print(vacc2.keys())\n",
    "print(vacc3.keys())\n",
    "print(vacc4.keys())\n",
    "print(vacc5.keys())\n",
    "print(len(vacc1['epidata']))\n",
    "'''\n",
    "print('smoothed_covid_vaccinated',vacc1['result'], vacc1['message'], len(vacc1['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc2['result'], vacc2['message'], len(vacc2['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc3['result'], vacc3['message'], len(vacc3['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc4['result'], vacc4['message'], len(vacc4['epidata']))\n",
    "print('smoothed_covid_vaccinated',vacc5['result'], vacc5['message'], len(vacc5['epidata']))\n",
    "\n",
    "print(vacc1['epidata'][0])\n",
    "print(vacc2['epidata'][0])\n",
    "print(vacc3['epidata'][0])\n",
    "print(vacc4['epidata'][0])\n",
    "print(vacc5['epidata'][0])\n",
    "#print(vacc5['epidata'][0]['sample_size'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
